---
title: "Comparing_models"
output: html_document
date: "2023-09-18"
---
#Loading data
```{r}
library(readr)
library(plyr)
library(dplyr)
library(forcats)
library(lme4)
library(glmnet)
library(optimx)
library(broom.mixed)

library(car)
library(stargazer)
library(texreg)
library(xtable)
library(splitstackshape)
library(scales)

library(Hmisc)
library(lmerTest)
library(e1071)
library(ggplot2)
```

```{r}
df_nonmerged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Non_Merged/Sample/temp/Sample_15000_manual.csv")
df_merged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Merged/pr_merged_final_April_2023.csv")
df_comp <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/pr_final_April_2023.csv")
df_TSE <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Reza's Dataset/TSE paper/2020-TSE-Developers-Perceptible-Ethnicity-and-PR-evaluation-main/Dataset/pull_requests.csv")


```

```{r}
#df_noneth_nonmerged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Non_Merged/Sample/Sample_9000_manual.csv")
#df_merged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Merged/pr_merged_final_April_2023.csv")

df_10000_sample <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Non_Merged/Sample/Sample_10000_new_manual.csv")
```


```{r}
df_TSE <- df_TSE %>% distinct(pr_id, .keep_all = TRUE)

df_nonmerged <- df_nonmerged %>% distinct(pr_id, .keep_all = TRUE)

df_noneth_nonmerged <- df_noneth_nonmerged %>% distinct(pr_id, .keep_all = TRUE)
```

```{r}
df_nonmerged <- left_join(df_nonmerged, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch), by= "pr_id", all.y = TRUE)
#df_noneth_nonmerged <- left_join(df_noneth_nonmerged, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch), by= "pr_id", all.y = TRUE)
df_10000_sample <- left_join(df_10000_sample, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch), by= "pr_id", all.y = TRUE)
```

```{r}
df_merged <- left_join(df_merged, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch)
, by= "pr_id", all.y = TRUE)

df_comp <- left_join(df_comp, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch) , by= "pr_id", all.y = TRUE)
```

```{r}
df_eth_nonmerged <- anti_join(df_nonmerged, df_noneth_nonmerged, by = "pr_id" )

```

```{r}
length(unique(df_10000_sample$repo_id))
```

```{r}

```

### Dropping the columns (depricated)

```{r}
df_nonmerged <- df_nonmerged %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, closer_id, comments, created_at, closed_at))


df_merged <- df_merged %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, comments, created_at, closed_at))


df_comp <- df_comp %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, comments, created_at, closed_at))

```

```{r}
df_comp <- df_comp %>%
  select(-c(closer_id))
```

# Building the model in rejected categories(Depricated)

for one rejected category against all the other categories. here for testing we are going to use \## Encoding the manual analysis label and factoring the rest

```{r}
# Create a copy of df_nonmerged
df_nonmerged_factor <- df_nonmerged

# Define encoding for 'manual_analysis' column
encoding <- c(
  'Quality' = 0, 'Successful' = 0, 'Unnecessary' = 1, 'No Reason' = 0,
  'Resolved' = 0, 'Replaced' = 0, 'Duplicate' = 0, 'Stale' = 0,
  'Merge Conflict' = 0, 'Chaotic' = 0, 'Not PR' = 0, 'No Comment' = 0
)

df_nonmerged_factor$manual_analysis <- as.integer(factor(df_nonmerged_factor$manual_analysis, levels = names(encoding)))
df_nonmerged_factor$manual_analysis <- encoding[df_nonmerged_factor$manual_analysis]

df_nonmerged_factor$status<-factor(df_nonmerged_factor$status,levels=c("not-merged","merged"))

df_nonmerged_factor$repo_pr_tenure_mnth<-as.integer(df_nonmerged_factor$repo_pr_tenure_mnth)
df_nonmerged_factor$repo_pr_tenure_mnth<-scale(log(df_nonmerged_factor$repo_pr_tenure_mnth +1))
df_nonmerged_factor$repo_pr_popularity<-as.integer(df_nonmerged_factor$repo_pr_popularity)
df_nonmerged_factor$repo_pr_popularity<-scale(log(df_nonmerged_factor$repo_pr_popularity +1))
df_nonmerged_factor$repo_pr_team_size<-as.integer(df_nonmerged_factor$repo_pr_team_size)
df_nonmerged_factor$repo_pr_team_size<-scale(log(df_nonmerged_factor$repo_pr_team_size +1))
df_nonmerged_factor$perc_external_contribs<-as.integer(df_nonmerged_factor$perc_external_contribs)
df_nonmerged_factor$perc_external_contribs<-scale(log(df_nonmerged_factor$perc_external_contribs +1))

df_nonmerged_factor$closer_country <- factor(df_nonmerged_factor$closer_country)                                    
df_nonmerged_factor$author_country <- factor(df_nonmerged_factor$author_country)                                    
df_nonmerged_factor$author_continent <- factor(df_nonmerged_factor$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_nonmerged_factor$prs_experience<-as.integer(df_nonmerged_factor$prs_experience)
df_nonmerged_factor$prs_experience<-scale(log(df_nonmerged_factor$prs_experience +1))
df_nonmerged_factor$prs_succ_rate<-as.integer(df_nonmerged_factor$prs_succ_rate)
df_nonmerged_factor$prs_succ_rate<-scale(log(df_nonmerged_factor$prs_succ_rate +1))
df_nonmerged_factor$prs_main_team_member<-factor(df_nonmerged_factor$prs_main_team_member,levels=c(0,1))
df_nonmerged_factor$prs_popularity<-as.integer(df_nonmerged_factor$prs_popularity)
df_nonmerged_factor$prs_popularity<-scale(log(df_nonmerged_factor$prs_popularity +1))
df_nonmerged_factor$prs_tenure_mnth<-as.integer(df_nonmerged_factor$prs_tenure_mnth)
df_nonmerged_factor$prs_tenure_mnth<-scale(log(df_nonmerged_factor$prs_tenure_mnth +1))
df_nonmerged_factor$comments_counts<-as.integer(df_nonmerged_factor$comments_counts)
df_nonmerged_factor$comments_counts<-scale(log(df_nonmerged_factor$comments_counts +1))
df_nonmerged_factor$commit_counts<-as.integer(df_nonmerged_factor$commit_counts)
df_nonmerged_factor$commit_counts<-scale(log(df_nonmerged_factor$commit_counts +1))
df_nonmerged_factor$prs_watched_repo<-factor(df_nonmerged_factor$prs_watched_repo,levels=c(0,1))
df_nonmerged_factor$prs_followed_pri<-factor(df_nonmerged_factor$prs_followed_pri,levels=c(0,1))
df_nonmerged_factor$same_eth<-factor(df_nonmerged_factor$same_eth,levels=c(0,1))
df_nonmerged_factor$same_country<-factor(df_nonmerged_factor$same_country,levels=c(0,1))
df_nonmerged_factor$intra_branch<-factor(df_nonmerged_factor$intra_branch,levels=c(0,1))


```

```{r}
table(df_nonmerged_factor$manual_analysis)
```

```{r}
# Define the columns with '\\N' values
columns_with_n_values <- c('same_country', 'prs_pri_same_nationality')

# Create a logical mask to identify rows with '\\N' in any of the specified columns
mask <- apply(df_nonmerged_encoded[columns_with_n_values], 1, function(row) any(grepl('\\N', row)))

# Use the mask to filter and display the rows where '\\N' occurs
rows_with_n_values <- df_nonmerged_encoded[mask, ]

# Replace '\\N' values with 0 in the selected columns
for (column in columns_with_n_values) {
  df_nonmerged_encoded[[column]][df_nonmerged_encoded[[column]] == '\\N'] <- 0
}


```

formula \<- manual_analysis \~ status + comments_counts (1) + commit_counts(0) + code_changes_counts(0) + author_country(0) + closer_country(0) + author_continent(1) + same_country(1) + author_eth(1) + closer_eth() + same_eth(Û±) + prs_white() + prs_api() + prs_black() + prs_hispanic() + pri_white() + pri_black() + pri_api() + pri_hispanic() + prs_eth_8() + prs_eth_7() + prs_eth_9() + prs_eth_diff() + prs_eth_diff_2() + manual_analysis() + prs_experience(0) + prs_succ_rate(0) + prs_popularity(0) + prs_watched_repo(0) + prs_followed_pri(0) + prs_tenure_mnth(0) + prs_main_team_member() + (1 \| author_id)

formula \<- manual_analysis \~ comments_counts + commit_counts + code_changes_counts + author_continent + author_eth + closer_eth + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + pr_opened_at + pr_files_changed + pr_lines_changed + intra_branch + (1 \| repo_id) + (1 \| author_id)

```{r}
formula <- manual_analysis ~  comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member +
repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

glmer_model_unnecessary<-glmer(formula, data=df_nonmerged_factor, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model_unnecessary), correlation=FALSE)
car::vif(glmer_model_unnecessary)

effect_size_glmer_model = anova(glmer_model_unnecessary,test='Chisq')
print(effect_size_glmer_model)
```

Now we try the model without the ethnicity

```{r}
formula <- manual_analysis ~  comments_counts + commit_counts + code_changes_counts + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

glmer_model_unnecessary_we<-glmer(formula, data=df_nonmerged_factor, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model_unnecessary_we), correlation=FALSE)
car::vif(glmer_model_unnecessary_we)

effect_size_glmer_model = anova(glmer_model_unnecessary_we,test='Chisq')
print(effect_size_glmer_model)
```

# Building the model for all merged and nonmerged pull reqests (Depricated)

this would be based on status of the pull request

## Encoding the model(depricated)

```{r}
# Create a copy of df_nonmerged
df_comp_encoded <- df_comp

# Define encoding for 'manual_analysis' column
encoding <- c(
  'Quality' = 0, 'Successful' = 0, 'Unnecessary' = 1, 'No reason' = 0,
  'Resolved' = 0, 'Replaced' = 0, 'Duplicate' = 0, 'Stale' = 0,
  'Merge Conflict' = 0, 'Chaotic' = 0, 'Not PR' = 0
  
)

# Map the encoding to 'manual_analysis' and convert to integer
#df_nonmerged_encoded$manual_analysis <- as.integer(factor(df_nonmerged_encoded$manual_analysis, levels = names(encoding)))
#df_nonmerged_encoded$manual_analysis <- encoding[df_nonmerged_encoded$manual_analysis]

# Replace missing values with 0 in selected columns
df_comp_encoded[is.na(df_comp_encoded)] <- 0

# Encode categorical columns using forcats
categorical_cols <- c(
  'author_id', 'author_eth', 'author_country', 'author_continent',
  'closer_eth', 'prs_eth_8', 'prs_eth_7', 'prs_eth_9',
  'prs_eth_diff', 'prs_eth_diff_2', 'closer_country'
)

for (col in categorical_cols) {
  df_comp_encoded[[col]] <- as.integer(factor(df_comp_encoded[[col]]))
}
# encoding status as zero for merged and 1 for not-merged
df_comp_encoded$status <- ifelse(df_comp_encoded$status == "merged", 0, 1)


```

## factoring the values

instead of encoding, i'm gonna use factoring

```{r}
df_comp_factor <- df_comp


df_comp_factor$status<-factor(df_comp_factor$status,levels=c("not-merged","merged"))

df_comp_factor$repo_pr_tenure_mnth<-as.integer(df_comp_factor$repo_pr_tenure_mnth)
df_comp_factor$repo_pr_tenure_mnth<-scale(log(df_comp_factor$repo_pr_tenure_mnth +1))
df_comp_factor$repo_pr_popularity<-as.integer(df_comp_factor$repo_pr_popularity)
df_comp_factor$repo_pr_popularity<-scale(log(df_comp_factor$repo_pr_popularity +1))
df_comp_factor$repo_pr_team_size<-as.integer(df_comp_factor$repo_pr_team_size)
df_comp_factor$repo_pr_team_size<-scale(log(df_comp_factor$repo_pr_team_size +1))
df_comp_factor$perc_external_contribs<-as.integer(df_comp_factor$perc_external_contribs)
df_comp_factor$perc_external_contribs<-scale(log(df_comp_factor$perc_external_contribs +1))

df_comp_factor$closer_country <- factor(df_comp_factor$closer_country)                                    
df_comp_factor$author_country <- factor(df_comp_factor$author_country)                                    
df_comp_factor$author_continent <- factor(df_comp_factor$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_comp_factor$prs_experience<-as.integer(df_comp_factor$prs_experience)
df_comp_factor$prs_experience<-scale(log(df_comp_factor$prs_experience +1))
df_comp_factor$prs_succ_rate<-as.integer(df_comp_factor$prs_succ_rate)
df_comp_factor$prs_succ_rate<-scale(log(df_comp_factor$prs_succ_rate +1))
df_comp_factor$prs_main_team_member<-factor(df_comp_factor$prs_main_team_member,levels=c(0,1))
df_comp_factor$prs_popularity<-as.integer(df_comp_factor$prs_popularity)
df_comp_factor$prs_popularity<-scale(log(df_comp_factor$prs_popularity +1))
df_comp_factor$prs_tenure_mnth<-as.integer(df_comp_factor$prs_tenure_mnth)
df_comp_factor$prs_tenure_mnth<-scale(log(df_comp_factor$prs_tenure_mnth +1))
df_comp_factor$comments_counts<-as.integer(df_comp_factor$comments_counts)
df_comp_factor$comments_counts<-scale(log(df_comp_factor$comments_counts +1))
df_comp_factor$commit_counts<-as.integer(df_comp_factor$commit_counts)
df_comp_factor$commit_counts<-scale(log(df_comp_factor$commit_counts +1))
df_comp_factor$prs_watched_repo<-factor(df_comp_factor$prs_watched_repo,levels=c(0,1))
df_comp_factor$prs_followed_pri<-factor(df_comp_factor$prs_followed_pri,levels=c(0,1))
df_comp_factor$same_eth<-factor(df_comp_factor$same_eth,levels=c(0,1))
df_comp_factor$same_country<-factor(df_comp_factor$same_country,levels=c(0,1))
df_comp_factor$intra_branch<-factor(df_comp_factor$intra_branch,levels=c(0,1))



```

## remove the \\N values and change them with 0

```{r}
# Define the columns with '\\N' values
columns_with_n_values <- c('same_country', 'prs_pri_same_nationality')

# Create a logical mask to identify rows with '\\N' in any of the specified columns
mask <- apply(df_comp_encoded[columns_with_n_values], 1, function(row) any(grepl('\\N', row)))

# Use the mask to filter and display the rows where '\\N' occurs
rows_with_n_values <- df_comp_encoded[mask, ]

# Replace '\\N' values with 0 in the selected columns
for (column in columns_with_n_values) {
  df_comp_encoded[[column]][df_comp_encoded[[column]] == '\\N'] <- 0
}


```

## Building the model

sampling the data to time the model and see if this works

```{r}
df_comp_factor_sample <- df_comp_factor %>% sample_n(10000) 
```

also normalizing to see what is the problem

```{r}
#df_comp_factor_sample <- df_comp_factor_sample %>% mutate_at(vars(code_changes_counts, author_country, closer_country, prs_experience, #prs_succ_rate, prs_popularity, prs_watched_repo, prs_tenure_mnth ), scale)

```

formula \<- status \~ comments_counts + commit_counts + code_changes_counts + author_country + closer_country + author_continent + same_country\<\> + author_eth + closer_eth + same_eth\<\> + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_followed_pri \<\> + prs_tenure_mnth + prs_main_team_member \<\>+ (1 \| repo_id) + (1 \| author_id)

```{r}
#formula <- status ~ comments_counts + commit_counts + author_continent  + author_eth + closer_eth  +  (1 | repo_id) 
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)
model <- glmer(formula, data = df_comp_encoded_sample, family = binomial, glmerControl( optCtrl = list(maxfun=1e5)))

```

```{r}
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)

glmer_model<-glmer(formula, data=df_comp_factor_sample, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model), correlation=FALSE)
car::vif(glmer_model)

effect_size_glmer_model = anova(glmer_model,test='Chisq')
print(effect_size_glmer_model)
```

```{r}
summary(model)
```

# Building the model in rejected categories with samples of merged (Depricated)

## Sampling the Data from merged prs based on nonmerged prs rejection reasons (Depricated as no bootstrapping)

```{r}
category <- 'Unnecessary'

 # Calculate the desired number of samples for the specified category
number_of_samples <- sum(df_nonmerged$manual_analysis == category)

 #Filter repo_id values associated with the specified category in df_nonmerged
repo_ids_for_category <- unique(df_nonmerged[df_nonmerged$manual_analysis == category, ]$repo_id)

 # Filter 'df_merged' to keep only rows with 'repo_id' values in repo_ids_for_category
filtered_df_merged <- df_merged[df_merged$repo_id %in% repo_ids_for_category, ]

 # Create an empty data frame to store the sampled data
sampled_data <- data.frame()

 # Iterate through the repositories with rejected PRs in the specified category
for (repo_id in repo_ids_for_category) {
  # Filter rows from filtered_df_merged for the current repo_id
  repo_samples <- filtered_df_merged[filtered_df_merged$repo_id == repo_id, ]
  
  # If there are multiple samples for the current repo, select one randomly
  if (nrow(repo_samples) > 1) {
    set.seed(42)  # Set seed for reproducibility
    repo_samples <- repo_samples[sample(nrow(repo_samples), size = 1), ]
  }
  
  # Append the selected sample to the sampled_data data frame
  sampled_data <- rbind(sampled_data, repo_samples)
}

 # Randomly select additional samples to reach the desired number
remaining_samples <- number_of_samples - nrow(sampled_data)
set.seed(42)  # Set seed for reproducibility
additional_samples <- filtered_df_merged[sample(nrow(filtered_df_merged), size = remaining_samples), ]

 # Append the additional samples to the sampled_data data frame
sampled_data <- rbind(sampled_data, additional_samples)
```

checking to see if the repos are the same

```{r}
 # Get the unique 'repo_id' values from the sampled_data data frame
sampled_repo_ids <- unique(sampled_data$repo_id)

 # Check if all sampled 'repo_id' values are in 'repo_ids_for_category'
if(all(sampled_repo_ids %in% repo_ids_for_category)) {
  cat("All samples are from repositories with the specified rejected reason.\n")
} else {
  cat("Some samples are not from repositories with the specified rejected reason.\n")
}
```

```{r}
 # there is a closer_id feature in sample_reason that is not in nonmerged, let's drop that first
sampled_data <- sampled_data[, !(names(sampled_data) %in% "closer_id")]
sampled_data <- sampled_data[, !(names(sampled_data) %in%  "checked")]

```

```{r}

common_columns <- intersect(names(df_nonmerged), names(sampled_data))
sampled_data <- sampled_data %>% rename(!!!setNames(common_columns, common_columns))
df_nonmerged_category <- df_nonmerged[df_nonmerged$manual_analysis == category, ]
df_nonmerged_category <- df_nonmerged_category[, !(names(df_nonmerged_category) %in% "manual_analysis")]


 # Concatenate data frames df_nonmerged and sampled_data by rows
df_sample_reason <- rbind(df_nonmerged_category, sampled_data) 


 # Sort the resulting data frame by 'repo_id'
df_sample_reason <- df_sample_reason[order(df_sample_reason$repo_id), ]

 # Drop the 'checked' and 'manual_analysis' columns
df_sample_reason <- df_sample_reason[, !(names(df_sample_reason) %in% c('checked', 'manual_analysis'))]

```

```{r}
table(df_sample_reason$status)

```

## Encoding and building the model (depricated)

```{r}
 # Create a copy of df_nonmerged
df_sample_reason_encoded <- df_sample_reason

 # Define encoding for 'manual_analysis' column
 
 # Map the encoding to 'manual_analysis' and convert to integer



 # Replace missing values with 0 in selected columns
df_sample_reason_encoded[is.na(df_sample_reason_encoded)] <- 0

 # Encode categorical columns using forcats
categorical_cols <- c(
  'author_id', 'author_eth', 'author_country', 'author_continent',
  'closer_eth', 'prs_eth_8', 'prs_eth_7', 'prs_eth_9',
  'prs_eth_diff', 'prs_eth_diff_2', 'closer_country'
)

for (col in categorical_cols) {
  df_sample_reason_encoded[[col]] <- as.integer(factor(df_sample_reason_encoded[[col]]))
}
 # encoding status as zero for merged and 1 for not-merged
df_sample_reason_encoded$status <- ifelse(df_sample_reason_encoded$status == "merged", 0, 1)
```

```{r}
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_country + closer_country + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)
model_2 <- glmer(formula, data = df_sample_reason_encoded, family = binomial, glmerControl( optCtrl = list(maxfun=1e5)))
```

```{r}
summary(model_2)
```

## selecting the category, getting the data for that category and Factoring the data (Depricated as i did it in a function)

```{r}
category <- 'Unnecessary'

# Factoring for both merged and nonmerged
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]
df_merged_factored <- df_merged

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



df_nonmerged_factor_unn$status<-factor(df_nonmerged_factor_unn$status,levels=c("not-merged","merged"))
df_merged_factored$status<-factor(df_merged_factored$status,levels=c("not-merged","merged"))

df_nonmerged_factor_unn$repo_pr_tenure_mnth<-as.integer(df_nonmerged_factor_unn$repo_pr_tenure_mnth)
df_nonmerged_factor_unn$repo_pr_tenure_mnth<-scale(log(df_nonmerged_factor_unn$repo_pr_tenure_mnth +1))
df_nonmerged_factor_unn$repo_pr_popularity<-as.integer(df_nonmerged_factor_unn$repo_pr_popularity)
df_nonmerged_factor_unn$repo_pr_popularity<-scale(log(df_nonmerged_factor_unn$repo_pr_popularity +1))
df_nonmerged_factor_unn$repo_pr_team_size<-as.integer(df_nonmerged_factor_unn$repo_pr_team_size)
df_nonmerged_factor_unn$repo_pr_team_size<-scale(log(df_nonmerged_factor_unn$repo_pr_team_size +1))
df_nonmerged_factor_unn$perc_external_contribs<-as.integer(df_nonmerged_factor_unn$perc_external_contribs)
df_nonmerged_factor_unn$perc_external_contribs<-scale(log(df_nonmerged_factor_unn$perc_external_contribs +1))

df_merged_factored$repo_pr_tenure_mnth<-as.integer(df_merged_factored$repo_pr_tenure_mnth)
df_merged_factored$repo_pr_tenure_mnth<-scale(log(df_merged_factored$repo_pr_tenure_mnth +1))
df_merged_factored$repo_pr_popularity<-as.integer(df_merged_factored$repo_pr_popularity)
df_merged_factored$repo_pr_popularity<-scale(log(df_merged_factored$repo_pr_popularity +1))
df_merged_factored$repo_pr_team_size<-as.integer(df_merged_factored$repo_pr_team_size)
df_merged_factored$repo_pr_team_size<-scale(log(df_merged_factored$repo_pr_team_size +1))
df_merged_factored$perc_external_contribs<-as.integer(df_merged_factored$perc_external_contribs)
df_merged_factored$perc_external_contribs<-scale(log(df_merged_factored$perc_external_contribs +1))

df_nonmerged_factor_unn$closer_country <- factor(df_nonmerged_factor_unn$closer_country)                                    
df_nonmerged_factor_unn$author_country <- factor(df_nonmerged_factor_unn$author_country)                                    
df_nonmerged_factor_unn$author_continent <- factor(df_nonmerged_factor_unn$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))

df_merged_factored$closer_country <- factor(df_merged_factored$closer_country)                                    
df_merged_factored$author_country <- factor(df_merged_factored$author_country)                                    
df_merged_factored$author_continent <- factor(df_merged_factored$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_nonmerged_factor_unn$prs_experience<-as.integer(df_nonmerged_factor_unn$prs_experience)
df_nonmerged_factor_unn$prs_experience<-scale(log(df_nonmerged_factor_unn$prs_experience +1))
df_nonmerged_factor_unn$prs_succ_rate<-as.integer(df_nonmerged_factor_unn$prs_succ_rate)
df_nonmerged_factor_unn$prs_succ_rate<-scale(log(df_nonmerged_factor_unn$prs_succ_rate +1))
df_nonmerged_factor_unn$prs_main_team_member<-factor(df_nonmerged_factor_unn$prs_main_team_member,levels=c(0,1))
df_nonmerged_factor_unn$prs_popularity<-as.integer(df_nonmerged_factor_unn$prs_popularity)
df_nonmerged_factor_unn$prs_popularity<-scale(log(df_nonmerged_factor_unn$prs_popularity +1))
df_nonmerged_factor_unn$prs_tenure_mnth<-as.integer(df_nonmerged_factor_unn$prs_tenure_mnth)
df_nonmerged_factor_unn$prs_tenure_mnth<-scale(log(df_nonmerged_factor_unn$prs_tenure_mnth +1))
df_nonmerged_factor_unn$comments_counts<-as.integer(df_nonmerged_factor_unn$comments_counts)
df_nonmerged_factor_unn$comments_counts<-scale(log(df_nonmerged_factor_unn$comments_counts +1))
df_nonmerged_factor_unn$commit_counts<-as.integer(df_nonmerged_factor_unn$commit_counts)
df_nonmerged_factor_unn$commit_counts<-scale(log(df_nonmerged_factor_unn$commit_counts +1))
df_nonmerged_factor_unn$prs_watched_repo<-factor(df_nonmerged_factor_unn$prs_watched_repo,levels=c(0,1))
df_nonmerged_factor_unn$prs_followed_pri<-factor(df_nonmerged_factor_unn$prs_followed_pri,levels=c(0,1))
df_nonmerged_factor_unn$same_eth<-factor(df_nonmerged_factor_unn$same_eth,levels=c(0,1))
df_nonmerged_factor_unn$same_country<-factor(df_nonmerged_factor_unn$same_country,levels=c(0,1))
df_nonmerged_factor_unn$intra_branch<-factor(df_nonmerged_factor_unn$intra_branch,levels=c(0,1))

                                    
df_merged_factored$prs_experience<-as.integer(df_merged_factored$prs_experience)
df_merged_factored$prs_experience<-scale(log(df_merged_factored$prs_experience +1))
df_merged_factored$prs_succ_rate<-as.integer(df_merged_factored$prs_succ_rate)
df_merged_factored$prs_succ_rate<-scale(log(df_merged_factored$prs_succ_rate +1))
df_merged_factored$prs_main_team_member<-factor(df_merged_factored$prs_main_team_member,levels=c(0,1))
df_merged_factored$prs_popularity<-as.integer(df_merged_factored$prs_popularity)
df_merged_factored$prs_popularity<-scale(log(df_merged_factored$prs_popularity +1))
df_merged_factored$prs_tenure_mnth<-as.integer(df_merged_factored$prs_tenure_mnth)
df_merged_factored$prs_tenure_mnth<-scale(log(df_merged_factored$prs_tenure_mnth +1))
df_merged_factored$comments_counts<-as.integer(df_merged_factored$comments_counts)
df_merged_factored$comments_counts<-scale(log(df_merged_factored$comments_counts +1))
df_merged_factored$commit_counts<-as.integer(df_merged_factored$commit_counts)
df_merged_factored$commit_counts<-scale(log(df_merged_factored$commit_counts +1))
df_merged_factored$prs_watched_repo<-factor(df_merged_factored$prs_watched_repo,levels=c(0,1))
df_merged_factored$prs_followed_pri<-factor(df_merged_factored$prs_followed_pri,levels=c(0,1))
df_merged_factored$same_eth<-factor(df_merged_factored$same_eth,levels=c(0,1))
df_merged_factored$same_country<-factor(df_merged_factored$same_country,levels=c(0,1))
df_merged_factored$intra_branch<-factor(df_merged_factored$intra_branch,levels=c(0,1))

```

## Preprocessing the data as a Function
```{r}
preprocess_data <- function(data){
  
  #Factorizing and scaling
  data$status <- factor(data$status, levels = c("not-merged", "merged"))
  data$repo_pr_tenure_mnth<-as.integer(data$repo_pr_tenure_mnth)
  data$repo_pr_tenure_mnth<-scale(log(data$repo_pr_tenure_mnth +1))
  data$repo_pr_popularity<-as.integer(data$repo_pr_popularity)
  data$repo_pr_popularity<-scale(log(data$repo_pr_popularity +1))
  data$repo_pr_team_size<-as.integer(data$repo_pr_team_size)
  data$repo_pr_team_size<-scale(log(data$repo_pr_team_size +1))
  data$perc_external_contribs<-as.integer(data$perc_external_contribs)
  data$perc_external_contribs<-scale(log(data$perc_external_contribs +1))

  
  data$closer_country <- factor(data$closer_country)                                    
  data$author_country <- factor(data$author_country)                                    
  data$author_continent <- factor(data$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
  
  data$prs_experience<-as.integer(data$prs_experience)
  data$prs_experience<-scale(log(data$prs_experience +1))
  data$prs_succ_rate<-as.integer(data$prs_succ_rate)
  data$prs_succ_rate<-scale(log(data$prs_succ_rate +1))
  data$prs_main_team_member<-factor(data$prs_main_team_member,levels=c(0,1))
  data$prs_popularity<-as.integer(data$prs_popularity)
  data$prs_popularity<-scale(log(data$prs_popularity +1))
  data$prs_tenure_mnth<-as.integer(data$prs_tenure_mnth)
  data$prs_tenure_mnth<-scale(log(data$prs_tenure_mnth +1))
  data$comments_counts<-as.integer(data$comments_counts)
  data$comments_counts<-scale(log(data$comments_counts +1))
  data$commit_counts<-as.integer(data$commit_counts)
  data$commit_counts<-scale(log(data$commit_counts +1))
  data$prs_watched_repo<-factor(data$prs_watched_repo,levels=c(0,1))
  data$prs_followed_pri<-factor(data$prs_followed_pri,levels=c(0,1))
  data$same_eth<-factor(data$same_eth,levels=c(0,1))
  data$same_country<-factor(data$same_country,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-factor(data$pr_files_changed,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-as.integer(data$pr_files_changed)
  data$pr_files_changed<-scale(log(data$pr_files_changed +1))
  data$pr_lines_changed<-as.integer(data$pr_lines_changed)
  data$pr_lines_changed<-scale(log(data$pr_lines_changed +1))
  return(data)

}
```


# Building the model for merged pull requests from the same repositories of the rejected reason

### bootstrapped Model( depricated)

```{r}

#building the model for Unnecessary
set.seed(42)
category <- 'Unnecessary'
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]

df_nonmerged_factor_unn <- preprocess_data(df_nonmerged_factor_unn)

df_merged_factored <- preprocess_data(df_merged)

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_unn$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


formula <- status ~  comments_counts + commit_counts + code_changes_counts  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


num_bootstraps <- 1

bootstrapped_models <- list()

bootstrapped_parameters <- list()
sample_size <- nrow(df_nonmerged_factor_unn)

#bootstrapping the sample
for (i in 1:num_bootstraps) {
  # Resample the data with replacement from merged pull requests
  boot_indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
  bootstrap_sample <- df_merged_factored[boot_indices, ]
  
  # Combine the "Unnecessary" pull requests with the bootstrapped merged data
  combined_data_boot <- rbind(df_nonmerged_factor_unn, bootstrap_sample)

  # Refit the model on the combined bootstrapped data
  boot_model_unn <- glmer(formula, data = combined_data_boot, family = binomial,
                      control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
  bootstrapped_models[[i]] <- boot_model_unn

  # Extract and store the model parameters
  bootstrapped_parameters[[i]] <- coef(boot_model_unn)
}




```
```{r}
for (i in 1:num_bootstraps) {
  model_summary_unn <- summary(bootstrapped_models[[i]])
  #conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
  
  # Print or analyze the=
  print(model_summary_unn, correlation=TRUE)
}
```
```{r}
fixed_effects <- fixef(boot_model_unn)
odds_ratios <- exp(fixed_effects)
print(odds_ratios)

```

```{r}
class(coef(boot_model_unn))

```



# Normalization(Depricated)

```{r}
# Factoring and scaling 
preprocess_data_norm <- function(data){
  

  data$status <- factor(data$status, levels = c("merged", "not-merged"))


  
  data$closer_country <- factor(data$closer_country)                                    
  data$author_country <- factor(data$author_country)                                    
  data$author_continent <- factor(data$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
  
  data$comments_counts<-as.integer(data$comments_counts)
  data$comments_counts<-scale(log(data$comments_counts +1))
  data$commit_counts<-as.integer(data$commit_counts)
  data$commit_counts<-scale(log(data$commit_counts +1))
  data$code_changes_counts<-as.integer(data$code_changes_counts)
  data$code_changes_counts<-scale(log(data$code_changes_counts +1))
  data$prs_experience<-as.integer(data$prs_experience)
  data$prs_experience<-scale(log(data$prs_experience +1))
  data$prs_succ_rate<-as.integer(data$prs_succ_rate)
  data$prs_succ_rate<-scale(log(data$prs_succ_rate +1))
  data$prs_popularity<-as.integer(data$prs_popularity)
  data$prs_popularity<-scale(log(data$prs_popularity +1))
  data$prs_tenure_mnth<-as.integer(data$prs_tenure_mnth)
  data$prs_tenure_mnth<-scale(log(data$prs_tenure_mnth +1))
  data$repo_pr_tenure_mnth<-as.integer(data$repo_pr_tenure_mnth)
  data$repo_pr_tenure_mnth<-scale(log(data$repo_pr_tenure_mnth +1))
  data$repo_pr_popularity<-as.integer(data$repo_pr_popularity)
  data$repo_pr_popularity<-scale(log(data$repo_pr_popularity +1))
  data$repo_pr_team_size<-as.integer(data$repo_pr_team_size)
  data$repo_pr_team_size<-scale(log(data$repo_pr_team_size +1))
  data$perc_external_contribs<-as.integer(data$perc_external_contribs)
  data$perc_external_contribs<-scale(log(data$perc_external_contribs +1))
  data$pr_lines_changed<-as.integer(data$pr_lines_changed)
  data$pr_lines_changed<-scale(log(data$pr_lines_changed +1))
                                      

  data$prs_main_team_member<-factor(data$prs_main_team_member,levels=c(0,1))
  data$prs_watched_repo<-factor(data$prs_watched_repo,levels=c(0,1))
  data$prs_followed_pri<-factor(data$prs_followed_pri,levels=c(0,1))
  data$same_eth<-factor(data$same_eth,levels=c(0,1))
  data$same_country<-factor(data$same_country,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-factor(data$pr_files_changed,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))

  
  
#  data$closer_country <- factor(data$closer_country)                                    
 # data$author_country <- factor(data$author_country)                                    
  #data$author_continent <- factor(data$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                      
                                      
  data$prs_main_team_member<-factor(data$prs_main_team_member,levels=c(0,1))
  data$prs_watched_repo<-factor(data$prs_watched_repo,levels=c(0,1))
  data$prs_followed_pri<-factor(data$prs_followed_pri,levels=c(0,1))
  data$same_eth<-factor(data$same_eth,levels=c(0,1))
  data$same_country<-factor(data$same_country,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
    # List of columns to normalize
  #columns_to_normalize <- c("comments_counts", "commit_counts", "code_changes_counts", "prs_experience", 
   #                         "prs_succ_rate", "prs_popularity", "prs_tenure_mnth", "repo_pr_tenure_mnth", 
    #                        "repo_pr_popularity", "repo_pr_team_size", "perc_external_contribs", 
     #                       "pr_files_changed", "pr_lines_changed")
  
  #for (col in columns_to_normalize) {
   # data[[col]] <- rescale(data[[col]])
  #}

  return(data)

}

df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

df_merged_factored <- preprocess_data_norm(df_merged)

df_comp_factored <- preprocess_data_norm(df_comp)


```
# Normalization
```{r}
preprocess_data_norm_test <- function(data) {
  # Convert status to factor
  data$status <- factor(data$status, levels = c("merged", "not-merged"))

  # List of numeric variables to apply log transformation and robust scaling
  numeric_vars <- c("comments_counts", "commit_counts", "prs_experience", "prs_succ_rate", "prs_popularity", "prs_tenure_mnth", "repo_pr_tenure_mnth", "repo_pr_popularity", "repo_pr_team_size", "perc_external_contribs", "pr_lines_changed", "pr_files_changed")

  # Apply log transformation and robust scaling
  for (var in numeric_vars) {
    # Log transformation (adding 1 to avoid log(0))
    data[[var]]<-as.integer(data[[var]])
    data[[var]] <- scale(log(data[[var]] + 1))
    
    # Calculate median and IQR for robust scaling
    #median_val <- median(data[[var]], na.rm = TRUE)
    #iqr_val <- IQR(data[[var]], na.rm = TRUE)

    # Perform robust scaling
    #data[[var]] <- (data[[var]] - median_val) / iqr_val
    
    #z-score
    #data[[var]] <- (data[[var]] - mean(data[[var]], na.rm = TRUE)) / sd(data[[var]], na.rm = TRUE)
    
    #min-max
    #data[[var]] <- (data[[var]] - min(data[[var]], na.rm = TRUE)) / (max(data[[var]], na.rm = TRUE) - min(data[[var]], na.rm = TRUE))
  
    #mean
    #data[[var]] <- (data[[var]] - mean(data[[var]], na.rm = TRUE)) / (max(data[[var]], na.rm = TRUE) - min(data[[var]], na.rm = TRUE))
    
    #square root
    #data[[var]] <- sqrt(data[[var]])

  }# Convert binary variables to factors
  binary_vars <- c("prs_main_team_member", "prs_watched_repo", "prs_followed_pri", "intra_branch")
  for (var in binary_vars) {
    data[[var]] <- factor(data[[var]], levels = c(0, 1))
  }

  return(data)
}

#df_nonmerged_factor <- preprocess_data_norm_test(df_nonmerged)
#df_noneth_nonmerged_factor <- preprocess_data_norm_test(df_noneth_nonmerged)
#df_eth_nonmerged_factor <- preprocess_data_norm_test(df_eth_nonmerged)

df_merged_factored <- preprocess_data_norm_test(df_merged)

df_comp_factored <- preprocess_data_norm_test(df_comp)
df_10000_sample_factored <- preprocess_data_norm_test(df_10000_sample)
```
```{r}
df_noneth_nonmerged_factor <- preprocess_data_norm_test(df_noneth_nonmerged)
df_merged_factored <- preprocess_data_norm_test(df_merged)
df_eth_nonmerged_factor <- preprocess_data_norm_test(df_eth_nonmerged)
```

```{r}
  df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]
  df_comp_factored <- df_comp_factored[, !colnames(df_comp_factored) %in% "checked"]

```


# Getting the summary as a dataframe function
```{r}
create_model_summary_df <- function(model) {
  # Extract model coefficients
  coefs <- summary(model)$coefficients
  
  # Create a dataframe from the coefficients
  df <- as.data.frame(coefs)
  
  # Calculate odds ratios for fixed effects
  df$odds_ratio <- exp(df[, "Estimate"])
  
  # Add row names as a new column for the terms
  df$term <- rownames(df)
  
  # Determine significance levels
  df$Significance <- ifelse(df[, "Pr(>|z|)"] < 0.001, '***',
                            ifelse(df[, "Pr(>|z|)"] < 0.01, '**',
                            ifelse(df[, "Pr(>|z|)"] < 0.05, '*',
                            ifelse(df[, "Pr(>|z|)"] < 0.1, '.', ' '))))
  
  # Return the dataframe
  return(df)
}


```

#Creating models based on the ratio of the repositories
```{r}


build_model_by_category <- function(category, df_sample, df_large, df_merged, formula, random_seed = 46) {
  set.seed(random_seed)

  # Preprocess and filter datasets
  df_sample_category <- df_sample[df_sample$manual_analysis == category, ]
  df_sample_category <- df_sample_category[, !colnames(df_sample_category) %in% "manual_analysis"]
  df_large <- df_large[, !colnames(df_large) %in% "checked"]
  #df_merged <- df_merged[, !colnames(df_merged) %in% "checked"]

  # Filter the sample dataset for the given category

  # Sample based on the ratio
  #unique_repo_ids <- unique(df_sample_category$repo_id)
  #df_merged_category <- df_merged[df_merged$repo_id %in% unique_repo_ids, ]

  sampled_data <- sample_by_ratio(df_sample_category, df_large)
  
  
  print(paste("Number of columns in df_sample_category in build_model_by_category :", ncol(df_sample_category)))
  print(paste("Number of columns in sampled_data in build_model_by_category:", ncol(sampled_data)))
  
  
  # Combine the sampled data with the filtered merged data
  combined_data <- rbind(sampled_data, df_sample_category)
  combined_data <- combined_data %>% distinct(pr_id, .keep_all = TRUE)

  # Build the model
  model <- glmer(formula, data = combined_data, family = binomial,
                 control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

  # Return the combined dataset and the model
  list(combined_data = combined_data, model = model)
}

# Usage example:


```


### Unnecessary Model normalization for each class(depricated for now, might come back later to it)

```{r}

#building the model for Unnecessary
set.seed(42)
category <- 'Unnecessary'
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]

df_nonmerged_factor_unn <- preprocess_data_norm(df_nonmerged_factor_unn)

unique_repo_ids <- unique(df_nonmerged_factor_unn$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_unn <- df_merged[df_merged$repo_id %in% unique_repo_ids, ]
df_merged_factored_unn <- preprocess_data_norm(df_merged_factored_unn)

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored_unn <- df_merged_factored_unn[, !colnames(df_merged_factored_unn) %in% "checked"]




formula <- status ~  comments_counts + commit_counts + code_changes_counts  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)



sample_size <- nrow(df_nonmerged_factor_unn)

indices <- sample(1:nrow(df_merged_factored_unn), size = sample_size, replace = TRUE)
sample <- df_merged_factored_unn[indices, ]

combined_data_unn <- rbind(df_nonmerged_factor_unn, sample)

model_unn <- glmer(formula, data = combined_data_unn, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```

```{r}
model_summary_unn <- summary(model_unn)
fixed_effects_unn <- fixef(model_unn)
odds_ratios_unn <- exp(fixed_effects_unn)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print(model_summary_unn, correlation=TRUE)
print(odds_ratios_unn)
car::vif(model_unn)


```

### Unnecessary with 1:1 sampling
```{r}

#building the model for Unnecessary
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Unnecessary'
#df_nonmerged_factor_unn <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_unn <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_unn <- preprocess_data(df_nonmerged_factor_unn)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_unn <- df_10000_factor_unn[, !colnames(df_10000_factor_unn) %in% "manual_analysis"]
df_merged_factored_unn <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_10000_factor_unn$repo_id)
df_merged_factored_unn <- df_merged_factored_unn[df_merged_factored_unn$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_unn)

indices <- sample(1:nrow(df_merged_factored_unn), size = sample_size, replace = TRUE)
df_merged_factored_unn <- df_merged_factored_unn[indices, ]


combined_data_unn <- rbind(df_10000_factor_unn, df_merged_factored_unn)

formula <- status ~ comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_unn <- glmer(formula, data = combined_data_unn, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_unn)
```

```{r}
formula <- status ~ comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch  + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_unn <- glmer(formula, data = combined_data_unn, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
```

```{r}
model_summary_unn <- summary(model_unn)
fixed_effects_unn <- fixef(model_unn)
odds_ratios_unn <- exp(fixed_effects_unn)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_unn, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_unn)
```
```{r}
#getting the summary as a dataframe
model_unn_df <- create_model_summary_df(model_unn)
write.csv(model_unn_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_unn_df.csv", row.names = FALSE)


```

### Unnecessary with ratio sampling

```{r}
formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


results_unn_ratio <- build_model_by_category("Unnecessary", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_unn_ratio <- results_unn_ratio$combined_data
model_unn_ratio <- results_unn_ratio$model
```
```{r}
print('VIF:')
car::vif(model_unn_ratio)
model_summary_unn_ratio <- summary(model_unn_ratio)
fixed_effects_unn_ratio <- fixef(model_unn_ratio)
odds_ratios_unn_ratio <- exp(fixed_effects_unn_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_unn_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_unn_ratio)
```


```{r}
table(combined_data_unn_ratio$status)

```
```{r}
model_unn_ratio_df <- create_model_summary_df(model_unn_ratio)
write.csv(model_unn_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_unn_ratio_wcc_df.csv", row.names = FALSE)

```



### Quality with 1:1 sampling
```{r}
#building the model for Quality
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Quality'
#df_nonmerged_factor_qua <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_qua <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_qua <- preprocess_data(df_nonmerged_factor_qua)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_qua <- df_10000_factor_qua[, !colnames(df_10000_factor_qua) %in% "manual_analysis"]
df_merged_factored_qua <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_10000_factor_qua$repo_id)
df_merged_factored_qua <- df_merged_factored_qua[df_merged_factored_qua$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_qua)

indices <- sample(1:nrow(df_merged_factored_qua), size = sample_size, replace = TRUE)
df_merged_factored_qua <- df_merged_factored_qua[indices, ]
# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
#df_merged_factored_qua <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]

combined_data_qua <- rbind(df_10000_factor_qua, df_merged_factored_qua)

formula <- status ~  comments_counts + commit_counts  + prs_experience + prs_succ_rate + prs_followed_pri + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)




model_qua <- glmer(formula, data = combined_data_qua, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_qua)
```

```{r}
formula <- status ~  comments_counts + commit_counts  + prs_experience + prs_succ_rate + prs_followed_pri + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch +  (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)




model_qua <- glmer(formula, data = combined_data_qua, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```


```{r}
model_summary_qua <- summary(model_qua)
fixed_effects_qua <- fixef(model_qua)
odds_ratios_qua <- exp(fixed_effects_qua)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_qua, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_qua)
```
```{r}
#getting the summary as a dataframe
model_qua_df <- create_model_summary_df(model_qua)
write.csv(model_qua_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_qua_df.csv", row.names = FALSE)


```
### Quality with ratio sampling

```{r}
formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


results_qua_ratio <- build_model_by_category("Quality", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_qua_ratio <- results_qua_ratio$combined_data
model_qua_ratio <- results_qua_ratio$model
```

```{r}
table(combined_data_qua_ratio$status)
```

```{r}
print('VIF:')
car::vif(model_qua_ratio)
model_summary_qua_ratio <- summary(model_qua_ratio)
fixed_effects_qua_ratio <- fixef(model_qua_ratio)
odds_ratios_qua_ratio <- exp(fixed_effects_qua_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_qua_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_qua_ratio)
```



```{r}
model_qua_ratio_df <- create_model_summary_df(model_qua_ratio)
write.csv(model_qua_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_qua_ratio_df.csv", row.names = FALSE)
```



### Resolved with 1:1 sampling

```{r}

#building the model for Resolved
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Resolved'
#df_nonmerged_factor_res <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_res <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_res <- preprocess_data(df_nonmerged_factor_res)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_res <- df_10000_factor_res[, !colnames(df_10000_factor_res) %in% "manual_analysis"]
df_merged_factored_res <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



unique_repo_ids <- unique(df_10000_factor_res$repo_id)
df_merged_factored_res <- df_merged_factored_res[df_merged_factored_res$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_res)

indices <- sample(1:nrow(df_merged_factored_res), size = sample_size, replace = TRUE)
df_merged_factored_res <- df_merged_factored_res[indices, ]


combined_data_res <- rbind(df_10000_factor_res, df_merged_factored_res)
 
formula <- status ~  comments_counts + commit_counts  + prs_experience + prs_followed_pri + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_res <- glmer(formula, data = combined_data_res, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_res)
```

```{r}
formula <- status ~  comments_counts + commit_counts  + prs_experience + prs_followed_pri + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_lines_changed + (1 | repo_id) + (1 | author_id)

#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_res <- glmer(formula, data = combined_data_res, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
```

```{r}
model_summary_res <- summary(model_res)
fixed_effects_res <- fixef(model_res)
odds_ratios_res <- exp(fixed_effects_res)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_res, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_res)
```

```{r}
#getting the summary as a dataframe
model_res_df <- create_model_summary_df(model_res)
write.csv(model_res_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_res_df.csv", row.names = FALSE)


```

### Resolved with ratio sampling
```{r}
formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


results_res_ratio <- build_model_by_category("Resolved", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_res_ratio <- results_res_ratio$combined_data
model_res_ratio <- results_res_ratio$model
```

```{r}
table(combined_data_res_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_res_ratio)
model_summary_res_ratio <- summary(model_res_ratio)
fixed_effects_res_ratio <- fixef(model_res_ratio)
odds_ratios_res_ratio <- exp(fixed_effects_res_ratio)
print('The model summary and correlation:')
print(model_summary_res_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_res_ratio)
```



```{r}
model_res_ratio_df <- create_model_summary_df(model_res_ratio)
write.csv(model_res_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_res_ratio_df.csv", row.names = FALSE)
```

### Replaced with 1:1 sampling

```{r}

#building the model for Replaced
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Replaced'
#df_nonmerged_factor_rep <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_rep <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_rep <- preprocess_data(df_nonmerged_factor_rep)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_rep <- df_10000_factor_rep[, !colnames(df_10000_factor_rep) %in% "manual_analysis"]
df_merged_factored_rep <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



unique_repo_ids <- unique(df_10000_factor_rep$repo_id)
df_merged_factored_rep <- df_merged_factored_rep[df_merged_factored_rep$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_rep)

indices <- sample(1:nrow(df_merged_factored_rep), size = sample_size, replace = TRUE)
df_merged_factored_rep <- df_merged_factored_rep[indices, ]


combined_data_rep <- rbind(df_10000_factor_rep, df_merged_factored_rep)
 

formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)




model_rep <- glmer(formula, data = combined_data_rep, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featurep have more than 3 in VIF
print('VIF:')
car::vif(model_rep) 
```
```{r}
formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)
model_rep <- glmer(formula, data = combined_data_rep, family = binomial, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```


```{r}
model_summary_rep <- summary(model_rep)
fixed_effects_rep <- fixef(model_rep)
odds_ratios_rep <- exp(fixed_effects_rep)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_rep, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_rep)
```
```{r}
#getting the summary as a dataframe
model_rep_df <- create_model_summary_df(model_rep)
write.csv(model_rep_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_rep_df.csv", row.names = FALSE)


```

### Replaced with ratio sampling
```{r}
formula <- status ~ commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + perc_external_contribs +intra_branch + (1 | repo_id) + (1 | author_id)


results_rep_ratio <- build_model_by_category("Replaced", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_rep_ratio <- results_rep_ratio$combined_data
model_rep_ratio <- results_rep_ratio$model
```

```{r}
table(combined_data_rep_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_rep_ratio)
model_summary_rep_ratio <- summary(model_rep_ratio)
fixed_effects_rep_ratio <- fixef(model_rep_ratio)
odds_ratios_rep_ratio <- exp(fixed_effects_rep_ratio)
print('The model summary and correlation:')
print(model_summary_rep_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_rep_ratio)
```


```{r}
model_rep_ratio_df <- create_model_summary_df(model_rep_ratio)
write.csv(model_rep_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_rep_ratio_df.csv", row.names = FALSE)
```


### Duplicate with 1:1 sampling
```{r}

#building the model for Duplicate
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Duplicate'
#df_nonmerged_factor_dup <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_dup <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_dup <- preprocess_data(df_nonmerged_factor_dup)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_dup <- df_10000_factor_dup[, !colnames(df_10000_factor_dup) %in% "manual_analysis"]
df_merged_factored_dup <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



unique_repo_ids <- unique(df_10000_factor_dup$repo_id)
df_merged_factored_dup <- df_merged_factored_dup[df_merged_factored_dup$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_dup)

indices <- sample(1:nrow(df_merged_factored_dup), size = sample_size, replace = TRUE)
df_merged_factored_dup <- df_merged_factored_dup[indices, ]


combined_data_dup <- rbind(df_10000_factor_dup, df_merged_factored_dup)
 

formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_dup <- glmer(formula, data = combined_data_dup, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_dup)
```
```{r}
formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

model_dup <- glmer(formula, data = combined_data_dup, family = binomial, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```


```{r}
model_summary_dup <- summary(model_dup)
fixed_effects_dup <- fixef(model_dup)
odds_ratios_dup <- exp(fixed_effects_dup)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_dup, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_dup)
```
```{r}
#getting the summary as a dataframe
model_dup_df <- create_model_summary_df(model_dup)
write.csv(model_dup_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_dup_df.csv", row.names = FALSE)


```


### Duplicate with ratio sampling
```{r}
formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + + perc_external_contribs +intra_branch + (1 | repo_id) + (1 | author_id)


results_dup_ratio <- build_model_by_category("Duplicate", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_dup_ratio <- results_dup_ratio$combined_data
model_dup_ratio <- results_dup_ratio$model
```

```{r}
table(combined_data_dup_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_dup_ratio)
model_summary_dup_ratio <- summary(model_dup_ratio)
fixed_effects_dup_ratio <- fixef(model_dup_ratio)
odds_ratios_dup_ratio <- exp(fixed_effects_dup_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_dup_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_dup_ratio)
```



```{r}
model_dup_ratio_df <- create_model_summary_df(model_dup_ratio)
write.csv(model_dup_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_dup_ratio_df.csv", row.names = FALSE)
```

### Merge Conflict with 1:1 sampling
```{r}

#building the model for Merge Conflict
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Merge Conflict'
#df_nonmerged_factor_mc <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_mc <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_mc <- preprocess_data(df_nonmerged_factor_mc)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_mc <- df_10000_factor_mc[, !colnames(df_10000_factor_mc) %in% "manual_analysis"]
df_merged_factored_mc <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_10000_factor_mc$repo_id)
df_merged_factored_mc <- df_merged_factored_mc[df_merged_factored_mc$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_mc)

indices <- sample(1:nrow(df_merged_factored_mc), size = sample_size, replace = TRUE)
df_merged_factored_mc <- df_merged_factored_mc[indices, ]


combined_data_mc <- rbind(df_10000_factor_mc, df_merged_factored_mc)
 

formula <- status ~  comments_counts + commit_counts + prs_followed_pri + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_mc <- glmer(formula, data = combined_data_mc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_mc)
```
```{r}
formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)
model_mc <- glmer(formula, data = combined_data_mc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```


```{r}
model_summary_mc <- summary(model_mc)
fixed_effects_mc <- fixef(model_mc)
odds_ratios_mc <- exp(fixed_effects_mc)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_mc, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_mc)
```
```{r}
#getting the summary as a dataframe
model_mc_df <- create_model_summary_df(model_mc)
write.csv(model_mc_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_mc_df.csv", row.names = FALSE)


```
### Merge Conflict with ratio sampling
```{r}
formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + perc_external_contribs +intra_branch + (1 | repo_id) + (1 | author_id)


results_mc_ratio <- build_model_by_category("Merge Conflict", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_mc_ratio <- results_mc_ratio$combined_data
model_mc_ratio <- results_mc_ratio$model
```

```{r}
table(combined_data_mc_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_mc_ratio)
model_summary_mc_ratio <- summary(model_mc_ratio)
fixed_effects_mc_ratio <- fixef(model_mc_ratio)
odds_ratios_mc_ratio <- exp(fixed_effects_mc_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_mc_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_mc_ratio)
```



```{r}
model_mc_ratio_df <- create_model_summary_df(model_mc_ratio)
write.csv(model_mc_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_mc_ratio_wcc_df.csv", row.names = FALSE)
```

### Stale with 1:1 sampling
```{r}

#building the model for Stale
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Stale'
#df_nonmerged_factor_sta <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_sta <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_sta <- preprocess_data(df_nonmerged_factor_sta)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_sta <- df_10000_factor_sta[, !colnames(df_10000_factor_sta) %in% "manual_analysis"]
df_merged_factored_sta <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_10000_factor_sta$repo_id)
df_merged_factored_sta <- df_merged_factored_sta[df_merged_factored_sta$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_sta)

indices <- sample(1:nrow(df_merged_factored_sta), size = sample_size, replace = TRUE)
df_merged_factored_sta <- df_merged_factored_sta[indices, ]


combined_data_sta <- rbind(df_10000_factor_sta, df_merged_factored_sta)
 


formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_sta <- glmer(formula, data = combined_data_sta, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_sta)
```

```{r}
formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

model_sta <- glmer(formula, data = combined_data_sta, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```

```{r}
model_summary_sta <- summary(model_sta)
fixed_effects_sta <- fixef(model_sta)
odds_ratios_sta <- exp(fixed_effects_sta)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_sta, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_sta)
```
```{r}
#getting the summary as a dataframe
model_sta_df <- create_model_summary_df(model_sta)
write.csv(model_sta_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_sta_df.csv", row.names = FALSE)


```

### Stale with ratio sampling
```{r}
formula <- status ~ commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + (1 | repo_id) + (1 | author_id)


results_sta_ratio <- build_model_by_category("Stale", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_sta_ratio <- results_sta_ratio$combined_data
model_sta_ratio <- results_sta_ratio$model
```

```{r}
table(combined_data_sta_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_sta_ratio)
model_summary_sta_ratio <- summary(model_sta_ratio)
fixed_effects_sta_ratio <- fixef(model_sta_ratio)
odds_ratios_sta_ratio <- exp(fixed_effects_sta_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_sta_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_sta_ratio)
```



```{r}
model_sta_ratio_df <- create_model_summary_df(model_sta_ratio)
write.csv(model_sta_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_sta_ratio_wcc_df.csv", row.names = FALSE)
```

### No Comment with 1:1 sampling
```{r}
#building the model for No Comment
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'No Comment'
#df_nonmerged_factor_nc <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_nc <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_nc <- preprocess_data(df_nonmerged_factor_nc)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_nc <- df_10000_factor_nc[, !colnames(df_10000_factor_nc) %in% "manual_analysis"]
df_merged_factored_nc <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



unique_repo_ids <- unique(df_10000_factor_nc$repo_id)
df_merged_factored_nc <- df_merged_factored_nc[df_merged_factored_nc$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_nc)

indices <- sample(1:nrow(df_merged_factored_nc), size = sample_size, replace = TRUE)
df_merged_factored_nc <- df_merged_factored_nc[indices, ]


combined_data_nc <- rbind(df_10000_factor_nc, df_merged_factored_nc)
 

formula <- status ~  commit_counts + prs_followed_pri + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_nc <- glmer(formula, data = combined_data_nc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_nc)
```

```{r}
model_summary_nc <- summary(model_nc)
fixed_effects_nc <- fixef(model_nc)
odds_ratios_nc <- exp(fixed_effects_nc)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_nc, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_nc)
```

```{r}
#getting the summary as a dataframe
model_nc_df <- create_model_summary_df(model_nc)
write.csv(model_nc_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_nc_df.csv", row.names = FALSE)


```

### No Comment with ratio sampling
```{r}
formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + (1 | repo_id) + (1 | author_id)


results_nc_ratio <- build_model_by_category("No Comment", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_nc_ratio <- results_nc_ratio$combined_data
model_nc_ratio <- results_nc_ratio$model
```

```{r}
table(combined_data_nc_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_nc_ratio)
model_summary_nc_ratio <- summary(model_nc_ratio)
fixed_effects_nc_ratio <- fixef(model_nc_ratio)
odds_ratios_nc_ratio <- exp(fixed_effects_nc_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_nc_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_nc_ratio)
```



```{r}
model_nc_ratio_df <- create_model_summary_df(model_nc_ratio)
write.csv(model_nc_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/Ratioed/model_nc_ratio_df.csv", row.names = FALSE)
```

### No Reason with 1:1 sampling
```{r}

#building the model for No Reason
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'No Reason'
#df_nonmerged_factor_nr <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_nr <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_nr <- preprocess_data(df_nonmerged_factor_nr)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_nr <- df_10000_factor_nr[, !colnames(df_10000_factor_nr) %in% "manual_analysis"]
df_merged_factored_nr <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_10000_factor_nr$repo_id)
df_merged_factored_nr <- df_merged_factored_nr[df_merged_factored_nr$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_nr)

indices <- sample(1:nrow(df_merged_factored_nr), size = sample_size, replace = TRUE)
df_merged_factored_nr <- df_merged_factored_nr[indices, ]


combined_data_nr <- rbind(df_10000_factor_nr, df_merged_factored_nr)
 

formula <- status ~  comments_counts + commit_counts + prs_followed_pri + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_nr <- glmer(formula, data = combined_data_nr, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_nr)
```
```{r}

formula <- status ~  comments_counts + commit_counts + prs_followed_pri + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member  + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_nr <- glmer(formula, data = combined_data_nr, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```

```{r}
model_summary_nr <- summary(model_nr)
fixed_effects_nr <- fixef(model_nr)
odds_ratios_nr <- exp(fixed_effects_nr)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_nr, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_nr)
```
```{r}
#getting the summary as a dataframe
model_nr_df <- create_model_summary_df(model_nr)
write.csv(model_nr_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_nr_df.csv", row.names = FALSE)


```

### No Reason with ratio sampling
```{r}
formula <- status ~ commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


results_nr_ratio <- build_model_by_category("No Reason", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_nr_ratio <- results_nr_ratio$combined_data
model_nr_ratio <- results_nr_ratio$model
```

```{r}
table(combined_data_nr_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_nr_ratio)
model_summary_nr_ratio <- summary(model_nr_ratio)
fixed_effects_nr_ratio <- fixef(model_nr_ratio)
odds_ratios_nr_ratio <- exp(fixed_effects_nr_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_nr_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_nr_ratio)
```



```{r}
model_nr_ratio_df <- create_model_summary_df(model_nr_ratio)
write.csv(model_nr_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_nr_ratio_wcc_df.csv", row.names = FALSE)
```

### Successful with 1:1 sampling
```{r}

#building the model for Successful
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Successful'
#df_nonmerged_factor_suc <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]
df_10000_factor_suc <- df_10000_sample_factored[df_10000_sample_factored$manual_analysis == category, ]

#df_nonmerged_factor_suc <- preprocess_data(df_nonmerged_factor_suc)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_10000_factor_suc <- df_10000_factor_suc[, !colnames(df_10000_factor_suc) %in% "manual_analysis"]
df_merged_factored_suc <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_10000_factor_suc$repo_id)
df_merged_factored_suc <- df_merged_factored_suc[df_merged_factored_suc$repo_id %in% unique_repo_ids, ]

sample_size <- nrow(df_10000_factor_suc)

indices <- sample(1:nrow(df_merged_factored_suc), size = sample_size, replace = TRUE)
df_merged_factored_suc <- df_merged_factored_suc[indices, ]


combined_data_suc <- rbind(df_10000_factor_suc, df_merged_factored_suc)
 


formula <- status ~  comments_counts + commit_counts + prs_followed_pri + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)



model_suc <- glmer(formula, data = combined_data_suc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_suc)
```
```{r}
model_summary_suc <- summary(model_suc)
fixed_effects_suc <- fixef(model_suc)
odds_ratios_suc <- exp(fixed_effects_suc)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_suc, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_suc)
```
```{r}
#getting the summary as a dataframe
model_suc_df <- create_model_summary_df(model_suc)
write.csv(model_suc_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Jan_2024/model_suc_df.csv", row.names = FALSE)
```

### Successful with ratio sampling
```{r}
formula <- status ~ commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


results_suc_ratio <- build_model_by_category("Successful", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_suc_ratio <- results_suc_ratio$combined_data
model_suc_ratio <- results_suc_ratio$model
```

```{r}
table(combined_data_suc_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_suc_ratio)
model_summary_suc_ratio <- summary(model_suc_ratio)
fixed_effects_suc_ratio <- fixef(model_suc_ratio)
odds_ratios_suc_ratio <- exp(fixed_effects_suc_ratio)
print('The model summary and correlation:')
print(model_summary_suc_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_suc_ratio)
```



```{r}
model_suc_ratio_df <- create_model_summary_df(model_suc_ratio)
write.csv(model_suc_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_suc_ratio_wcc_df.csv", row.names = FALSE)
```

### Chaotic with ratio sampling
```{r}
formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + perc_external_contribs +intra_branch  + (1 | repo_id) + (1 | author_id)


results_chao_ratio <- build_model_by_category("Chaotic", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_chao_ratio <- results_chao_ratio$combined_data
model_chao_ratio <- results_chao_ratio$model
```

```{r}
table(combined_data_chao_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_chao_ratio)
model_summary_chao_ratio <- summary(model_chao_ratio)
fixed_effects_chao_ratio <- fixef(model_chao_ratio)
odds_ratios_chao_ratio <- exp(fixed_effects_chao_ratio)
print('The model summary and correlation:')
print(model_summary_chao_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_chao_ratio)
```



```{r}
model_chao_ratio_df <- create_model_summary_df(model_chao_ratio)
write.csv(model_chao_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_chao_ratio_df.csv", row.names = FALSE)
```

### Not PR with ratio sampling
```{r}
formula <- status ~ prs_succ_rate  + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth  + perc_external_contribs +intra_branch + (1 | repo_id) + (1 | author_id)


results_npr_ratio <- build_model_by_category("Not PR", df_10000_sample_factored, df_comp_factored, df_merged_factored, formula)

combined_data_npr_ratio <- results_npr_ratio$combined_data
model_npr_ratio <- results_npr_ratio$model
```

```{r}
table(combined_data_npr_ratio$status)

```

```{r}
print('VIF:')
car::vif(model_npr_ratio)
model_summary_npr_ratio <- summary(model_npr_ratio)
fixed_effects_npr_ratio <- fixef(model_npr_ratio)
odds_ratios_npr_ratio <- exp(fixed_effects_npr_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_npr_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_npr_ratio)
```



```{r}
model_npr_ratio_df <- create_model_summary_df(model_npr_ratio)
write.csv(model_npr_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_npr_ratio_wcc_df.csv", row.names = FALSE)
```

#Sampling function based on the need
```{r}
sample_by_ratio <- function(labeled_data, large_data, repo_id_col = "repo_id", status_col = "status") {
  # Calculate the count of merged and non-merged PRs per repo in the large data
  set.seed(46)
  #large_counts <- table(large_data[[repo_id_col]], large_data[[status_col]])
  large_counts_df <- as.data.frame(table(large_data[[repo_id_col]], large_data[[status_col]]))
  names(large_counts_df) <- c("repo_id", "status", "count")

  common_repos <- intersect(unique(labeled_data[[repo_id_col]]), unique(large_data[[repo_id_col]]))
  labeled_data <- labeled_data[, !colnames(labeled_data) %in% "manual_analysis"]
  large_data <- large_data[, !colnames(large_data) %in% "checked"]


  # Create an empty data frame to store the sampled non-merged PRs
  sampled_merged_data <- data.frame()

  # Loop through each repository in the labeled dataset
  for (repo_id in common_repos) {
    # Get counts of merged and non-merged PRs in this repository in the large dataset
    # Check if repo_id exists in large_counts and has both 'merged' and 'non-merged' entries
    #if (!(repo_id %in% rownames(large_counts)) || 
     #   !("merged" %in% colnames(large_counts)) || 
     #   !("not-merged" %in% colnames(large_counts))) {
     # next  # Skip to the next iteration if not found
    #}
    repo_counts <- subset(large_counts_df, repo_id == repo_id)
    
    #print("repo_counts:")
    #print(repo_counts)
    
    #count_merged_large <- ifelse("merged" %in% repo_counts$status, sum(repo_counts$count[repo_counts$status == "merged"]), 0)
    #count_nonmerged_large <- ifelse("non-merged" %in% repo_counts$status, sum(repo_counts$count[repo_counts$status == "non-merged"]), 0)
    count_merged_large <- sum(repo_counts$count[repo_counts$status == "merged" & repo_counts$repo_id == repo_id])
    #print("count_merged_large")
    #print(count_merged_large)
    count_nonmerged_large <- sum(repo_counts$count[repo_counts$status == "not-merged" & repo_counts$repo_id == repo_id])
    #print("count_nonmerged_large")
    #print(count_nonmerged_large)
    #count_merged_large <- as.integer(large_counts[repo_id, "merged"])
    #count_nonmerged_large <- as.integer(large_counts[repo_id, "not-merged"])

    # Calculate the ratio (avoid division by zero)
    ratio <- if (count_nonmerged_large > 0) count_merged_large / count_nonmerged_large else 0
    
    #print("ratio")
    #print(ratio)

    # Get non-merged PRs in this repo from the labeled dataset
    #merged_in_repo <- labeled_data[labeled_data[[repo_id_col]] == repo_id & labeled_data[[status_col]] == "not-merged", ]

    # Calculate the number of non-merged PRs to sample based on the ratio
    #merged_in_repo <- large_data[large_data[[repo_id_col]] == repo_id & large_data[[status_col]] == "merged", ]
    
    
    count_nonmerged_labeled <- sum(labeled_data[[repo_id_col]] == repo_id & labeled_data[[status_col]] == "not-merged")
    #print("count_nonmerged_labeled")
    #print(count_nonmerged_labeled)

    # Determine the number of merged PRs to sample based on the ratio and count in labeled data
    #count_to_sample <- min(nrow(large_data[large_data[[repo_id_col]] == repo_id & large_data[[status_col]] == "merged", ]),round(count_nonmerged_labeled * ratio))
    count_to_sample <- min(count_merged_large, round(count_nonmerged_labeled * ratio))

    #print("count_to_sample")
    #print(count_to_sample)

    # Sample non-merged PRs from this repo
    if (count_to_sample > 0) {
        merged_in_repo <- large_data[large_data[[repo_id_col]] == repo_id & large_data[[status_col]] == "merged", ]
        sampled_merged <- merged_in_repo[sample(nrow(merged_in_repo), count_to_sample), ]
        sampled_merged_data <- rbind(sampled_merged_data, sampled_merged)    }
  }
  print(paste("Number of columns in labeled_data in sample_by_ratio:", ncol(labeled_data)))
  print(paste("Number of columns in sampled_merged_datain sample_by_ratio:", ncol(sampled_merged_data)))

  combined_data <- rbind(labeled_data, sampled_merged_data)
  return(combined_data)
}


#sample <- combined_data(df_nonmerged_factor, df_comp_factored)

```

## Test
```{r}
sample_by_ratio_test <- function(labeled_data, large_data, repo_id_col = "repo_id", status_col = "status") {
  # Prepare a summary of counts for merged and non-merged PRs in the large data
  large_summary <- aggregate(. ~ repo_id + status, data = large_data, FUN = length)
  names(large_summary)[3] <- "count"

  # Filter out the common repos
  common_repos <- intersect(unique(labeled_data[[repo_id_col]]), unique(large_data[[repo_id_col]]))

  # Initialize an empty data frame for the sampled data
  sampled_merged_data <- data.frame()

  # Loop through each repository in the common repos
  for (repo_id in common_repos) {
    # Extract counts for merged and non-merged PRs for the current repo_id
    merged_count <- with(large_summary, sum(count[repo_id == repo_id & status == "merged"]))
    nonmerged_count <- with(large_summary, sum(count[repo_id == repo_id & status == "not-merged"]))

    # Calculate the ratio (avoid division by zero)
    ratio <- if (nonmerged_count > 0) merged_count / nonmerged_count else 0

    # Determine the number of non-merged PRs in the labeled dataset for this repo
    count_nonmerged_labeled <- sum(labeled_data[[repo_id_col]] == repo_id & labeled_data[[status_col]] == "not-merged")

    # Determine the number of merged PRs to sample
    count_to_sample <- min(nrow(large_data[large_data[[repo_id_col]] == repo_id & large_data[[status_col]] == "merged", ]), round(count_nonmerged_labeled * ratio))

    # Sample merged PRs from the large dataset for this repo
    if (count_to_sample > 0) {
      merged_in_repo <- large_data[large_data[[repo_id_col]] == repo_id & large_data[[status_col]] == "merged", ]
      if (nrow(merged_in_repo) > 0) {
        sampled_indices <- sample(nrow(merged_in_repo), count_to_sample)
        sampled_merged_data <- rbind(sampled_merged_data, merged_in_repo[sampled_indices, ])
      }
    }
  }

  # Combine the sampled merged PRs with the labeled dataset
  combined_data <- rbind(labeled_data, sampled_merged_data)

  return(combined_data)
}



```


# Building the model for labeled dataset


```{r}
hist(df_nonmerged_factor$comments_counts, main = "Distribution of Comments Counts", xlab = "Comments Counts", col = "lightblue", border = "black")


```


```{r}
set.seed(46)

#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor <- df_nonmerged_factor[, !colnames(df_nonmerged_factor) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


sample_size <- nrow(df_nonmerged_factor)

indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
sample_merged_data_15k <- df_merged_factored[indices, ]
combined_data <- rbind(df_nonmerged_factor, sample_merged_data_15k)

formula <- status ~  comments_counts + commit_counts + prs_experience  + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + prs_followed_pri + perc_external_contribs + intra_branch +pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_labeled <- glmer(formula, data = combined_data, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
table(combined_data$status)
```

```{r}
model_summary <- summary(model_labeled)
fixed_effects <- fixef(model_labeled)
odds_ratios <- exp(fixed_effects)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios)
print('VIF:')
car::vif(model_labeled)

```
```{r}
#getting the summary as a dataframe
model_labeled_df <- create_model_summary_df(model_labeled)
write.csv(model_labeled_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_labeled_df.csv", row.names = FALSE)


```

# Merged prs from same repos as labeled
Task 1 asked by Ice. saying: First Dataset: Extract project names from the labels dataset [reject one]. Create a new dataset that includes All successfully merged from extracted projects and combine it with the labels dataset.

```{r}
# i should get all the prs from merged, filter the ones in the labeled, and then build a model.
```



# Building model of all_data only with repos in labeled and merged ones only


```{r}

df_nonmerged_factor <- df_nonmerged_factor[, !colnames(df_nonmerged_factor) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]

unique_repo_ids_labeled <- unique(df_nonmerged_factor$repo_id)


df_merged_factored_filtered<- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids_labeled, ]

df_merged_labeled <- rbind(df_nonmerged_factor, df_merged_factored_filtered)

```

```{r}
table(df_merged_labeled$status)

```


```{r}
formula <- status ~  comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + prs_followed_pri + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_merged_labeled <- glmer(formula, data = df_merged_labeled, family = binomial, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```

```{r}
model_summary <- summary(model_merged_labeled)
fixed_effects <- fixef(model_merged_labeled)
odds_ratios <- exp(fixed_effects)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios)
print('VIF:')
car::vif(model_merged_labeled)
```

```{r}
model_merged_labeled_df <- create_model_summary_df(model_merged_labeled)
write.csv(model_merged_labeled_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_merged_labeled_df.csv", row.names = FALSE)

```

# Building a model with data before sampling ethnicity
```{r}
set.seed(46)

#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_noneth_nonmerged_factor <- df_noneth_nonmerged_factor[, !colnames(df_noneth_nonmerged_factor) %in% "manual_analysis"]
#df_noneth_nonmerged_factor <- df_noneth_nonmerged_factor[, !colnames(df_noneth_nonmerged_factor) %in% "Unnamed: 39"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_noneth_nonmerged_factor$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


sample_size <- nrow(df_noneth_nonmerged_factor)

indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
sample_merged_data_9k <- df_merged_factored[indices, ]

combined_data_noneth <- rbind(df_noneth_nonmerged_factor, sample_merged_data_9k)

formula <- status ~ comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_labeled_noneth <- glmer(formula, data = combined_data_noneth, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
table(combined_data_noneth$status)
```

```{r}
model_summary <- summary(model_labeled_noneth)
fixed_effects <- fixef(model_labeled_noneth)
odds_ratios <- exp(fixed_effects)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios)
print('VIF:')
car::vif(model_labeled_noneth)

```

```{r}
#getting the summary as a dataframe
model_labeled_noneth_df <- create_model_summary_df(model_labeled_noneth)
write.csv(model_labeled_noneth_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_labeled_noneth_df.csv", row.names = FALSE)


```

# Building a model with sampled data based on ethnicity
```{r}
set.seed(46)

#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_eth_nonmerged_factor <- df_eth_nonmerged_factor[, !colnames(df_eth_nonmerged_factor) %in% "manual_analysis"]
#df_noneth_nonmerged_factor <- df_noneth_nonmerged_factor[, !colnames(df_noneth_nonmerged_factor) %in% "Unnamed: 39"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_eth_nonmerged_factor$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


sample_size <- nrow(df_eth_nonmerged_factor)

indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
sample_merged_data_6k <- df_merged_factored[indices, ]

combined_data_eth <- rbind(df_eth_nonmerged_factor, sample_merged_data_6k)

formula <- status ~ comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

#perc_external_contribs is removed

model_labeled_eth <- glmer(formula, data = combined_data_eth, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
table(combined_data_eth$status)


```

```{r}
model_summary <- summary(model_labeled_eth)
fixed_effects <- fixef(model_labeled_eth)
odds_ratios <- exp(fixed_effects)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios)
print('VIF:')
car::vif(model_labeled_eth)

```

```{r}
#getting the summary as a dataframe
model_labeled_eth_df <- create_model_summary_df(model_labeled_eth)
write.csv(model_labeled_eth_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_labeled_eth_df.csv", row.names = FALSE)


```
# Building a model with sampling ratio based on repo
```{r}
set.seed(46)

df_nonmerged_factor <- df_nonmerged_factor[, !colnames(df_nonmerged_factor) %in% "manual_analysis"]
df_comp_factored <- df_comp_factored[, !colnames(df_comp_factored) %in% "checked"]


sampled_nonmerged_ratio <- sample_by_ratio(df_nonmerged_factor, df_comp_factored)

formula <- status ~ comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_labeled_ratio <- glmer(formula, data = sampled_nonmerged_ratio, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
model_summary_ratio <- summary(model_labeled_ratio)
fixed_effects_ratio <- fixef(model_labeled_ratio)
odds_ratios_ratio <- exp(fixed_effects_ratio)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_ratio, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_ratio)
print('VIF:')
car::vif(model_labeled_ratio)
```

```{r}
table(sampled_nonmerged_ratio$status)

```
```{r}
#getting the summary as a dataframe
model_labeled_ratio_df <- create_model_summary_df(model_labeled_ratio)
write.csv(model_labeled_ratio_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_labeled_ratio_df.csv", row.names = FALSE)

```

# Building a model with sampling ratio based on repo only for non eth
```{r}
set.seed(46)

df_noneth_nonmerged_factor <- df_noneth_nonmerged_factor[, !colnames(df_noneth_nonmerged_factor) %in% "manual_analysis"]
df_comp_factored <- df_comp_factored[, !colnames(df_comp_factored) %in% "checked"]


sampled_nonmerged_ratio_noneth <- sample_by_ratio(df_noneth_nonmerged_factor, df_comp_factored)

formula <- status ~ comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_labeled_ratio_noneth <- glmer(formula, data = sampled_nonmerged_ratio_noneth, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```

```{r}
model_summary_ratio_noneth <- summary(model_labeled_ratio_noneth)
fixed_effects_ratio_noneth <- fixef(model_labeled_ratio_noneth)
odds_ratios_ratio_noneth <- exp(fixed_effects_ratio_noneth)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_ratio_noneth, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_ratio_noneth)
print('VIF:')
car::vif(model_labeled_ratio_noneth)
```

```{r}
#getting the summary as a dataframe
model_labeled_ratio_noneth_df <- create_model_summary_df(model_labeled_ratio_noneth)
write.csv(model_labeled_ratio_noneth_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_labeled_ratio_noneth_df.csv", row.names = FALSE)

```

# Building a model with sampling ratio based on repo only for eth

```{r}
set.seed(46)

df_eth_nonmerged_factor <- df_eth_nonmerged_factor[, !colnames(df_eth_nonmerged_factor) %in% "manual_analysis"]
df_comp_factored <- df_comp_factored[, !colnames(df_comp_factored) %in% "checked"]


sampled_nonmerged_ratio_eth <- sample_by_ratio(df_eth_nonmerged_factor, df_comp_factored)

formula <- status ~ comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_labeled_ratio_eth <- glmer(formula, data = sampled_nonmerged_ratio_eth, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```

```{r}
model_summary_ratio_eth <- summary(model_labeled_ratio_eth)
fixed_effects_ratio_eth <- fixef(model_labeled_ratio_eth)
odds_ratios_ratio_eth <- exp(fixed_effects_ratio_eth)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_ratio_eth, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_ratio_eth)
print('VIF:')
car::vif(model_labeled_ratio_eth)
```

```{r}
#getting the summary as a dataframe
model_labeled_ratio_eth_df <- create_model_summary_df(model_labeled_ratio_eth)
write.csv(model_labeled_ratio_eth_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_labeled_ratio_eth_df.csv", row.names = FALSE)

```

# Building a model with sampling ratio with 10000 samples

```{r}
set.seed(46)

df_10000_sample_factored <- df_10000_sample_factored[, !colnames(df_10000_sample_factored) %in% "manual_analysis"]
df_comp_factored <- df_comp_factored[, !colnames(df_comp_factored) %in% "checked"]


sampled_nonmerged_ratio_10000_sample <- sample_by_ratio(df_10000_sample_factored, df_comp_factored)

formula <- status ~  commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


model_labeled_ratio_10000 <- glmer(formula, data = sampled_nonmerged_ratio_10000_sample, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```

```{r}
table(sampled_nonmerged_ratio_10000_sample$status)

```
```{r}
write.csv(sampled_nonmerged_ratio_10000_sample, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/sampled_dataset.csv")
```


```{r}
model_summary_ratio_10000_sample <- summary(model_labeled_ratio_10000)
fixed_effects_ratio_10000 <- fixef(model_labeled_ratio_10000)
odds_ratios_ratio_10000 <- exp(fixed_effects_ratio_10000)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_ratio_10000_sample, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_ratio_10000)
print('VIF:')
car::vif(model_labeled_ratio_10000)
```


```{r}
#getting the summary as a dataframe
model_labeled_ratio_10000_sample_df <- create_model_summary_df(model_labeled_ratio_10000)
write.csv(model_labeled_ratio_10000_sample_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary_Feb_2024/model_labeled_ratio_wccno_10000_sample.csv", row.names = FALSE)

```

### Sampling the all data 
```{r}
set.seed(46)

# Assuming df_comp_factored has a column 'merged' to distinguish between merged and non-merged PRs
df_nonmerged_alldata_factor <- df_comp_factored[df_comp_factored$status == 'not-merged', ]
df_merged_alldata_factored <- df_comp_factored[df_comp_factored$status == 'merged', ]


# Get unique repo_ids from non-merged PRs
unique_repo_ids <- unique(df_nonmerged_alldata_factor$repo_id)

# Filter merged PRs for those repos
df_merged_alldata_factored <- df_merged_alldata_factored[df_merged_alldata_factored$repo_id %in% unique_repo_ids, ]

# Define your model formula
formula <- status ~  comments_counts + commit_counts + code_changes_counts + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + prs_followed_pri + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

# Determine the sample size (number of non-merged PRs)
sample_size <- nrow(df_nonmerged_alldata_factor)

# Randomly sample merged PRs to match the count of non-merged PRs
indices <- sample(1:nrow(df_merged_alldata_factored), size = sample_size, replace = FALSE)
sampled_merged <- df_merged_alldata_factored[indices, ]

# Combine the datasets
combined_data_alldata <- rbind(df_nonmerged_alldata_factor, sampled_merged)

# Fit the model
model_alldata <- glmer(formula, data = combined_data_alldata, family = binomial, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```


```{r}
model_summary <- summary(model_alldata)
fixed_effects <- fixef(model_alldata)
odds_ratios <- exp(fixed_effects)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios)
print('VIF:')
car::vif(model_alldata)
```

```{r}
model_alldata_df <- create_model_summary_df(model_alldata)
write.csv(model_alldata_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_alldata_df.csv", row.names = FALSE)
```
