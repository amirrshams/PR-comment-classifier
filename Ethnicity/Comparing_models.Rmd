---
title: "Comparing_models"
output: html_document
date: "2023-09-18"
---

```{r}
library(readr)
library(dplyr)
library(forcats)
library(lme4)
library(glmnet)
library(optimx)

library(car)
library(stargazer)
library(texreg)
library(plyr)
library(xtable)
library(splitstackshape)

library(Hmisc)
library(lmerTest)
library(e1071)
library(ggplot2)
```

```{r}
df_nonmerged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Non_Merged/Sample/temp/Sample_15000_manual.csv")
df_merged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Merged/pr_merged_final_April_2023.csv")
df_comp <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/pr_final_April_2023.csv")
df_TSE <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Reza's Dataset/TSE paper/2020-TSE-Developers-Perceptible-Ethnicity-and-PR-evaluation-main/Dataset/pull_requests.csv")
```

```{r}
df_TSE <- df_TSE %>%
  distinct(pr_id, .keep_all = TRUE)

df_nonmerged <- df_nonmerged %>%
  distinct(pr_id, .keep_all = TRUE)
```

```{r}
df_nonmerged <- left_join(df_nonmerged, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch), by= "pr_id", all.y = TRUE)
```

```{r}
df_merged <- left_join(df_merged, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch)
, by= "pr_id", all.y = TRUE)

df_comp <- left_join(df_comp, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch) , by= "pr_id", all.y = TRUE)
```

### Dropping the columns (depricated)

```{r}
df_nonmerged <- df_nonmerged %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, closer_id, comments, created_at, closed_at))


df_merged <- df_merged %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, comments, created_at, closed_at))


df_comp <- df_comp %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, comments, created_at, closed_at))

```

```{r}
df_comp <- df_comp %>%
  select(-c(closer_id))
```

# Building the model in rejected categories

for one rejected category against all the other categories. here for testing we are going to use \## Encoding the manual analysis label and factoring the rest

```{r}
# Create a copy of df_nonmerged
df_nonmerged_factor <- df_nonmerged

# Define encoding for 'manual_analysis' column
encoding <- c(
  'Quality' = 0, 'Successful' = 0, 'Unnecessary' = 1, 'No Reason' = 0,
  'Resolved' = 0, 'Replaced' = 0, 'Duplicate' = 0, 'Stale' = 0,
  'Merge Conflict' = 0, 'Chaotic' = 0, 'Not PR' = 0, 'No Comment' = 0
)

df_nonmerged_factor$manual_analysis <- as.integer(factor(df_nonmerged_factor$manual_analysis, levels = names(encoding)))
df_nonmerged_factor$manual_analysis <- encoding[df_nonmerged_factor$manual_analysis]

df_nonmerged_factor$status<-factor(df_nonmerged_factor$status,levels=c("not-merged","merged"))

df_nonmerged_factor$repo_pr_tenure_mnth<-as.integer(df_nonmerged_factor$repo_pr_tenure_mnth)
df_nonmerged_factor$repo_pr_tenure_mnth<-scale(log(df_nonmerged_factor$repo_pr_tenure_mnth +1))
df_nonmerged_factor$repo_pr_popularity<-as.integer(df_nonmerged_factor$repo_pr_popularity)
df_nonmerged_factor$repo_pr_popularity<-scale(log(df_nonmerged_factor$repo_pr_popularity +1))
df_nonmerged_factor$repo_pr_team_size<-as.integer(df_nonmerged_factor$repo_pr_team_size)
df_nonmerged_factor$repo_pr_team_size<-scale(log(df_nonmerged_factor$repo_pr_team_size +1))
df_nonmerged_factor$perc_external_contribs<-as.integer(df_nonmerged_factor$perc_external_contribs)
df_nonmerged_factor$perc_external_contribs<-scale(log(df_nonmerged_factor$perc_external_contribs +1))

df_nonmerged_factor$closer_country <- factor(df_nonmerged_factor$closer_country)                                    
df_nonmerged_factor$author_country <- factor(df_nonmerged_factor$author_country)                                    
df_nonmerged_factor$author_continent <- factor(df_nonmerged_factor$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_nonmerged_factor$prs_experience<-as.integer(df_nonmerged_factor$prs_experience)
df_nonmerged_factor$prs_experience<-scale(log(df_nonmerged_factor$prs_experience +1))
df_nonmerged_factor$prs_succ_rate<-as.integer(df_nonmerged_factor$prs_succ_rate)
df_nonmerged_factor$prs_succ_rate<-scale(log(df_nonmerged_factor$prs_succ_rate +1))
df_nonmerged_factor$prs_main_team_member<-factor(df_nonmerged_factor$prs_main_team_member,levels=c(0,1))
df_nonmerged_factor$prs_popularity<-as.integer(df_nonmerged_factor$prs_popularity)
df_nonmerged_factor$prs_popularity<-scale(log(df_nonmerged_factor$prs_popularity +1))
df_nonmerged_factor$prs_tenure_mnth<-as.integer(df_nonmerged_factor$prs_tenure_mnth)
df_nonmerged_factor$prs_tenure_mnth<-scale(log(df_nonmerged_factor$prs_tenure_mnth +1))
df_nonmerged_factor$comments_counts<-as.integer(df_nonmerged_factor$comments_counts)
df_nonmerged_factor$comments_counts<-scale(log(df_nonmerged_factor$comments_counts +1))
df_nonmerged_factor$commit_counts<-as.integer(df_nonmerged_factor$commit_counts)
df_nonmerged_factor$commit_counts<-scale(log(df_nonmerged_factor$commit_counts +1))
df_nonmerged_factor$prs_watched_repo<-factor(df_nonmerged_factor$prs_watched_repo,levels=c(0,1))
df_nonmerged_factor$prs_followed_pri<-factor(df_nonmerged_factor$prs_followed_pri,levels=c(0,1))
df_nonmerged_factor$same_eth<-factor(df_nonmerged_factor$same_eth,levels=c(0,1))
df_nonmerged_factor$same_country<-factor(df_nonmerged_factor$same_country,levels=c(0,1))
df_nonmerged_factor$intra_branch<-factor(df_nonmerged_factor$intra_branch,levels=c(0,1))


```

```{r}
table(df_nonmerged_factor$manual_analysis)
```

```{r}
# Define the columns with '\\N' values
columns_with_n_values <- c('same_country', 'prs_pri_same_nationality')

# Create a logical mask to identify rows with '\\N' in any of the specified columns
mask <- apply(df_nonmerged_encoded[columns_with_n_values], 1, function(row) any(grepl('\\N', row)))

# Use the mask to filter and display the rows where '\\N' occurs
rows_with_n_values <- df_nonmerged_encoded[mask, ]

# Replace '\\N' values with 0 in the selected columns
for (column in columns_with_n_values) {
  df_nonmerged_encoded[[column]][df_nonmerged_encoded[[column]] == '\\N'] <- 0
}


```

formula \<- manual_analysis \~ status + comments_counts (1) + commit_counts(0) + code_changes_counts(0) + author_country(0) + closer_country(0) + author_continent(1) + same_country(1) + author_eth(1) + closer_eth() + same_eth(Û±) + prs_white() + prs_api() + prs_black() + prs_hispanic() + pri_white() + pri_black() + pri_api() + pri_hispanic() + prs_eth_8() + prs_eth_7() + prs_eth_9() + prs_eth_diff() + prs_eth_diff_2() + manual_analysis() + prs_experience(0) + prs_succ_rate(0) + prs_popularity(0) + prs_watched_repo(0) + prs_followed_pri(0) + prs_tenure_mnth(0) + prs_main_team_member() + (1 \| author_id)

formula \<- manual_analysis \~ comments_counts + commit_counts + code_changes_counts + author_continent + author_eth + closer_eth + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + pr_opened_at + pr_files_changed + pr_lines_changed + intra_branch + (1 \| repo_id) + (1 \| author_id)

```{r}
formula <- manual_analysis ~  comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member +
repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

glmer_model_unnecessary<-glmer(formula, data=df_nonmerged_factor, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model_unnecessary), correlation=FALSE)
car::vif(glmer_model_unnecessary)

effect_size_glmer_model = anova(glmer_model_unnecessary,test='Chisq')
print(effect_size_glmer_model)
```

Now we try the model without the ethnicity

```{r}
formula <- manual_analysis ~  comments_counts + commit_counts + code_changes_counts + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

glmer_model_unnecessary_we<-glmer(formula, data=df_nonmerged_factor, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model_unnecessary_we), correlation=FALSE)
car::vif(glmer_model_unnecessary_we)

effect_size_glmer_model = anova(glmer_model_unnecessary_we,test='Chisq')
print(effect_size_glmer_model)
```

# Building the model for all merged and nonmerged pull reqests

this would be based on status of the pull request

## Encoding the model(depricated)

```{r}
# Create a copy of df_nonmerged
df_comp_encoded <- df_comp

# Define encoding for 'manual_analysis' column
encoding <- c(
  'Quality' = 0, 'Successful' = 0, 'Unnecessary' = 1, 'No reason' = 0,
  'Resolved' = 0, 'Replaced' = 0, 'Duplicate' = 0, 'Stale' = 0,
  'Merge Conflict' = 0, 'Chaotic' = 0, 'Not PR' = 0
  
)

# Map the encoding to 'manual_analysis' and convert to integer
#df_nonmerged_encoded$manual_analysis <- as.integer(factor(df_nonmerged_encoded$manual_analysis, levels = names(encoding)))
#df_nonmerged_encoded$manual_analysis <- encoding[df_nonmerged_encoded$manual_analysis]

# Replace missing values with 0 in selected columns
df_comp_encoded[is.na(df_comp_encoded)] <- 0

# Encode categorical columns using forcats
categorical_cols <- c(
  'author_id', 'author_eth', 'author_country', 'author_continent',
  'closer_eth', 'prs_eth_8', 'prs_eth_7', 'prs_eth_9',
  'prs_eth_diff', 'prs_eth_diff_2', 'closer_country'
)

for (col in categorical_cols) {
  df_comp_encoded[[col]] <- as.integer(factor(df_comp_encoded[[col]]))
}
# encoding status as zero for merged and 1 for not-merged
df_comp_encoded$status <- ifelse(df_comp_encoded$status == "merged", 0, 1)


```

## factoring the values

instead of encoding, i'm gonna use factoring

```{r}
df_comp_factor <- df_comp


df_comp_factor$status<-factor(df_comp_factor$status,levels=c("not-merged","merged"))

df_comp_factor$repo_pr_tenure_mnth<-as.integer(df_comp_factor$repo_pr_tenure_mnth)
df_comp_factor$repo_pr_tenure_mnth<-scale(log(df_comp_factor$repo_pr_tenure_mnth +1))
df_comp_factor$repo_pr_popularity<-as.integer(df_comp_factor$repo_pr_popularity)
df_comp_factor$repo_pr_popularity<-scale(log(df_comp_factor$repo_pr_popularity +1))
df_comp_factor$repo_pr_team_size<-as.integer(df_comp_factor$repo_pr_team_size)
df_comp_factor$repo_pr_team_size<-scale(log(df_comp_factor$repo_pr_team_size +1))
df_comp_factor$perc_external_contribs<-as.integer(df_comp_factor$perc_external_contribs)
df_comp_factor$perc_external_contribs<-scale(log(df_comp_factor$perc_external_contribs +1))

df_comp_factor$closer_country <- factor(df_comp_factor$closer_country)                                    
df_comp_factor$author_country <- factor(df_comp_factor$author_country)                                    
df_comp_factor$author_continent <- factor(df_comp_factor$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_comp_factor$prs_experience<-as.integer(df_comp_factor$prs_experience)
df_comp_factor$prs_experience<-scale(log(df_comp_factor$prs_experience +1))
df_comp_factor$prs_succ_rate<-as.integer(df_comp_factor$prs_succ_rate)
df_comp_factor$prs_succ_rate<-scale(log(df_comp_factor$prs_succ_rate +1))
df_comp_factor$prs_main_team_member<-factor(df_comp_factor$prs_main_team_member,levels=c(0,1))
df_comp_factor$prs_popularity<-as.integer(df_comp_factor$prs_popularity)
df_comp_factor$prs_popularity<-scale(log(df_comp_factor$prs_popularity +1))
df_comp_factor$prs_tenure_mnth<-as.integer(df_comp_factor$prs_tenure_mnth)
df_comp_factor$prs_tenure_mnth<-scale(log(df_comp_factor$prs_tenure_mnth +1))
df_comp_factor$comments_counts<-as.integer(df_comp_factor$comments_counts)
df_comp_factor$comments_counts<-scale(log(df_comp_factor$comments_counts +1))
df_comp_factor$commit_counts<-as.integer(df_comp_factor$commit_counts)
df_comp_factor$commit_counts<-scale(log(df_comp_factor$commit_counts +1))
df_comp_factor$prs_watched_repo<-factor(df_comp_factor$prs_watched_repo,levels=c(0,1))
df_comp_factor$prs_followed_pri<-factor(df_comp_factor$prs_followed_pri,levels=c(0,1))
df_comp_factor$same_eth<-factor(df_comp_factor$same_eth,levels=c(0,1))
df_comp_factor$same_country<-factor(df_comp_factor$same_country,levels=c(0,1))
df_comp_factor$intra_branch<-factor(df_comp_factor$intra_branch,levels=c(0,1))



```

## remove the \\N values and change them with 0

```{r}
# Define the columns with '\\N' values
columns_with_n_values <- c('same_country', 'prs_pri_same_nationality')

# Create a logical mask to identify rows with '\\N' in any of the specified columns
mask <- apply(df_comp_encoded[columns_with_n_values], 1, function(row) any(grepl('\\N', row)))

# Use the mask to filter and display the rows where '\\N' occurs
rows_with_n_values <- df_comp_encoded[mask, ]

# Replace '\\N' values with 0 in the selected columns
for (column in columns_with_n_values) {
  df_comp_encoded[[column]][df_comp_encoded[[column]] == '\\N'] <- 0
}


```

## Building the model

sampling the data to time the model and see if this works

```{r}
df_comp_factor_sample <- df_comp_factor %>% sample_n(10000) 
```

also normalizing to see what is the problem

```{r}
#df_comp_factor_sample <- df_comp_factor_sample %>% mutate_at(vars(code_changes_counts, author_country, closer_country, prs_experience, #prs_succ_rate, prs_popularity, prs_watched_repo, prs_tenure_mnth ), scale)

```

formula \<- status \~ comments_counts + commit_counts + code_changes_counts + author_country + closer_country + author_continent + same_country\<\> + author_eth + closer_eth + same_eth\<\> + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_followed_pri \<\> + prs_tenure_mnth + prs_main_team_member \<\>+ (1 \| repo_id) + (1 \| author_id)

```{r}
#formula <- status ~ comments_counts + commit_counts + author_continent  + author_eth + closer_eth  +  (1 | repo_id) 
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)
model <- glmer(formula, data = df_comp_encoded_sample, family = binomial, glmerControl( optCtrl = list(maxfun=1e5)))

```

```{r}
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)

glmer_model<-glmer(formula, data=df_comp_factor_sample, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model), correlation=FALSE)
car::vif(glmer_model)

effect_size_glmer_model = anova(glmer_model,test='Chisq')
print(effect_size_glmer_model)
```

```{r}
summary(model)
```

# Building the model in rejected categories with samples of merged

## Sampling the Data from merged prs based on nonmerged prs rejection reasons (Depricated as no bootstrapping)

```{r}
category <- 'Unnecessary'

 # Calculate the desired number of samples for the specified category
number_of_samples <- sum(df_nonmerged$manual_analysis == category)

 #Filter repo_id values associated with the specified category in df_nonmerged
repo_ids_for_category <- unique(df_nonmerged[df_nonmerged$manual_analysis == category, ]$repo_id)

 # Filter 'df_merged' to keep only rows with 'repo_id' values in repo_ids_for_category
filtered_df_merged <- df_merged[df_merged$repo_id %in% repo_ids_for_category, ]

 # Create an empty data frame to store the sampled data
sampled_data <- data.frame()

 # Iterate through the repositories with rejected PRs in the specified category
for (repo_id in repo_ids_for_category) {
  # Filter rows from filtered_df_merged for the current repo_id
  repo_samples <- filtered_df_merged[filtered_df_merged$repo_id == repo_id, ]
  
  # If there are multiple samples for the current repo, select one randomly
  if (nrow(repo_samples) > 1) {
    set.seed(42)  # Set seed for reproducibility
    repo_samples <- repo_samples[sample(nrow(repo_samples), size = 1), ]
  }
  
  # Append the selected sample to the sampled_data data frame
  sampled_data <- rbind(sampled_data, repo_samples)
}

 # Randomly select additional samples to reach the desired number
remaining_samples <- number_of_samples - nrow(sampled_data)
set.seed(42)  # Set seed for reproducibility
additional_samples <- filtered_df_merged[sample(nrow(filtered_df_merged), size = remaining_samples), ]

 # Append the additional samples to the sampled_data data frame
sampled_data <- rbind(sampled_data, additional_samples)
```

checking to see if the repos are the same

```{r}
 # Get the unique 'repo_id' values from the sampled_data data frame
sampled_repo_ids <- unique(sampled_data$repo_id)

 # Check if all sampled 'repo_id' values are in 'repo_ids_for_category'
if(all(sampled_repo_ids %in% repo_ids_for_category)) {
  cat("All samples are from repositories with the specified rejected reason.\n")
} else {
  cat("Some samples are not from repositories with the specified rejected reason.\n")
}
```

```{r}
 # there is a closer_id feature in sample_reason that is not in nonmerged, let's drop that first
sampled_data <- sampled_data[, !(names(sampled_data) %in% "closer_id")]
sampled_data <- sampled_data[, !(names(sampled_data) %in%  "checked")]

```

```{r}

common_columns <- intersect(names(df_nonmerged), names(sampled_data))
sampled_data <- sampled_data %>% rename(!!!setNames(common_columns, common_columns))
df_nonmerged_category <- df_nonmerged[df_nonmerged$manual_analysis == category, ]
df_nonmerged_category <- df_nonmerged_category[, !(names(df_nonmerged_category) %in% "manual_analysis")]


 # Concatenate data frames df_nonmerged and sampled_data by rows
df_sample_reason <- rbind(df_nonmerged_category, sampled_data) 


 # Sort the resulting data frame by 'repo_id'
df_sample_reason <- df_sample_reason[order(df_sample_reason$repo_id), ]

 # Drop the 'checked' and 'manual_analysis' columns
df_sample_reason <- df_sample_reason[, !(names(df_sample_reason) %in% c('checked', 'manual_analysis'))]

```

```{r}
table(df_sample_reason$status)

```

## Encoding and building the model (depricated)

```{r}
 # Create a copy of df_nonmerged
df_sample_reason_encoded <- df_sample_reason

 # Define encoding for 'manual_analysis' column
 
 # Map the encoding to 'manual_analysis' and convert to integer



 # Replace missing values with 0 in selected columns
df_sample_reason_encoded[is.na(df_sample_reason_encoded)] <- 0

 # Encode categorical columns using forcats
categorical_cols <- c(
  'author_id', 'author_eth', 'author_country', 'author_continent',
  'closer_eth', 'prs_eth_8', 'prs_eth_7', 'prs_eth_9',
  'prs_eth_diff', 'prs_eth_diff_2', 'closer_country'
)

for (col in categorical_cols) {
  df_sample_reason_encoded[[col]] <- as.integer(factor(df_sample_reason_encoded[[col]]))
}
 # encoding status as zero for merged and 1 for not-merged
df_sample_reason_encoded$status <- ifelse(df_sample_reason_encoded$status == "merged", 0, 1)
```

```{r}
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_country + closer_country + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)
model_2 <- glmer(formula, data = df_sample_reason_encoded, family = binomial, glmerControl( optCtrl = list(maxfun=1e5)))
```

```{r}
summary(model_2)
```

## selecting the category, getting the data for that category and Factoring the data (Depricated as i did it in a function)

```{r}
category <- 'Unnecessary'

# Factoring for both merged and nonmerged
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]
df_merged_factored <- df_merged

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



df_nonmerged_factor_unn$status<-factor(df_nonmerged_factor_unn$status,levels=c("not-merged","merged"))
df_merged_factored$status<-factor(df_merged_factored$status,levels=c("not-merged","merged"))

df_nonmerged_factor_unn$repo_pr_tenure_mnth<-as.integer(df_nonmerged_factor_unn$repo_pr_tenure_mnth)
df_nonmerged_factor_unn$repo_pr_tenure_mnth<-scale(log(df_nonmerged_factor_unn$repo_pr_tenure_mnth +1))
df_nonmerged_factor_unn$repo_pr_popularity<-as.integer(df_nonmerged_factor_unn$repo_pr_popularity)
df_nonmerged_factor_unn$repo_pr_popularity<-scale(log(df_nonmerged_factor_unn$repo_pr_popularity +1))
df_nonmerged_factor_unn$repo_pr_team_size<-as.integer(df_nonmerged_factor_unn$repo_pr_team_size)
df_nonmerged_factor_unn$repo_pr_team_size<-scale(log(df_nonmerged_factor_unn$repo_pr_team_size +1))
df_nonmerged_factor_unn$perc_external_contribs<-as.integer(df_nonmerged_factor_unn$perc_external_contribs)
df_nonmerged_factor_unn$perc_external_contribs<-scale(log(df_nonmerged_factor_unn$perc_external_contribs +1))

df_merged_factored$repo_pr_tenure_mnth<-as.integer(df_merged_factored$repo_pr_tenure_mnth)
df_merged_factored$repo_pr_tenure_mnth<-scale(log(df_merged_factored$repo_pr_tenure_mnth +1))
df_merged_factored$repo_pr_popularity<-as.integer(df_merged_factored$repo_pr_popularity)
df_merged_factored$repo_pr_popularity<-scale(log(df_merged_factored$repo_pr_popularity +1))
df_merged_factored$repo_pr_team_size<-as.integer(df_merged_factored$repo_pr_team_size)
df_merged_factored$repo_pr_team_size<-scale(log(df_merged_factored$repo_pr_team_size +1))
df_merged_factored$perc_external_contribs<-as.integer(df_merged_factored$perc_external_contribs)
df_merged_factored$perc_external_contribs<-scale(log(df_merged_factored$perc_external_contribs +1))

df_nonmerged_factor_unn$closer_country <- factor(df_nonmerged_factor_unn$closer_country)                                    
df_nonmerged_factor_unn$author_country <- factor(df_nonmerged_factor_unn$author_country)                                    
df_nonmerged_factor_unn$author_continent <- factor(df_nonmerged_factor_unn$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))

df_merged_factored$closer_country <- factor(df_merged_factored$closer_country)                                    
df_merged_factored$author_country <- factor(df_merged_factored$author_country)                                    
df_merged_factored$author_continent <- factor(df_merged_factored$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_nonmerged_factor_unn$prs_experience<-as.integer(df_nonmerged_factor_unn$prs_experience)
df_nonmerged_factor_unn$prs_experience<-scale(log(df_nonmerged_factor_unn$prs_experience +1))
df_nonmerged_factor_unn$prs_succ_rate<-as.integer(df_nonmerged_factor_unn$prs_succ_rate)
df_nonmerged_factor_unn$prs_succ_rate<-scale(log(df_nonmerged_factor_unn$prs_succ_rate +1))
df_nonmerged_factor_unn$prs_main_team_member<-factor(df_nonmerged_factor_unn$prs_main_team_member,levels=c(0,1))
df_nonmerged_factor_unn$prs_popularity<-as.integer(df_nonmerged_factor_unn$prs_popularity)
df_nonmerged_factor_unn$prs_popularity<-scale(log(df_nonmerged_factor_unn$prs_popularity +1))
df_nonmerged_factor_unn$prs_tenure_mnth<-as.integer(df_nonmerged_factor_unn$prs_tenure_mnth)
df_nonmerged_factor_unn$prs_tenure_mnth<-scale(log(df_nonmerged_factor_unn$prs_tenure_mnth +1))
df_nonmerged_factor_unn$comments_counts<-as.integer(df_nonmerged_factor_unn$comments_counts)
df_nonmerged_factor_unn$comments_counts<-scale(log(df_nonmerged_factor_unn$comments_counts +1))
df_nonmerged_factor_unn$commit_counts<-as.integer(df_nonmerged_factor_unn$commit_counts)
df_nonmerged_factor_unn$commit_counts<-scale(log(df_nonmerged_factor_unn$commit_counts +1))
df_nonmerged_factor_unn$prs_watched_repo<-factor(df_nonmerged_factor_unn$prs_watched_repo,levels=c(0,1))
df_nonmerged_factor_unn$prs_followed_pri<-factor(df_nonmerged_factor_unn$prs_followed_pri,levels=c(0,1))
df_nonmerged_factor_unn$same_eth<-factor(df_nonmerged_factor_unn$same_eth,levels=c(0,1))
df_nonmerged_factor_unn$same_country<-factor(df_nonmerged_factor_unn$same_country,levels=c(0,1))
df_nonmerged_factor_unn$intra_branch<-factor(df_nonmerged_factor_unn$intra_branch,levels=c(0,1))

                                    
df_merged_factored$prs_experience<-as.integer(df_merged_factored$prs_experience)
df_merged_factored$prs_experience<-scale(log(df_merged_factored$prs_experience +1))
df_merged_factored$prs_succ_rate<-as.integer(df_merged_factored$prs_succ_rate)
df_merged_factored$prs_succ_rate<-scale(log(df_merged_factored$prs_succ_rate +1))
df_merged_factored$prs_main_team_member<-factor(df_merged_factored$prs_main_team_member,levels=c(0,1))
df_merged_factored$prs_popularity<-as.integer(df_merged_factored$prs_popularity)
df_merged_factored$prs_popularity<-scale(log(df_merged_factored$prs_popularity +1))
df_merged_factored$prs_tenure_mnth<-as.integer(df_merged_factored$prs_tenure_mnth)
df_merged_factored$prs_tenure_mnth<-scale(log(df_merged_factored$prs_tenure_mnth +1))
df_merged_factored$comments_counts<-as.integer(df_merged_factored$comments_counts)
df_merged_factored$comments_counts<-scale(log(df_merged_factored$comments_counts +1))
df_merged_factored$commit_counts<-as.integer(df_merged_factored$commit_counts)
df_merged_factored$commit_counts<-scale(log(df_merged_factored$commit_counts +1))
df_merged_factored$prs_watched_repo<-factor(df_merged_factored$prs_watched_repo,levels=c(0,1))
df_merged_factored$prs_followed_pri<-factor(df_merged_factored$prs_followed_pri,levels=c(0,1))
df_merged_factored$same_eth<-factor(df_merged_factored$same_eth,levels=c(0,1))
df_merged_factored$same_country<-factor(df_merged_factored$same_country,levels=c(0,1))
df_merged_factored$intra_branch<-factor(df_merged_factored$intra_branch,levels=c(0,1))

```

## Preprocessing the data as a Function
```{r}
preprocess_data <- function(data){
  
  #Factorizing and scaling
  data$status <- factor(data$status, levels = c("not-merged", "merged"))
  data$repo_pr_tenure_mnth<-as.integer(data$repo_pr_tenure_mnth)
  data$repo_pr_tenure_mnth<-scale(log(data$repo_pr_tenure_mnth +1))
  data$repo_pr_popularity<-as.integer(data$repo_pr_popularity)
  data$repo_pr_popularity<-scale(log(data$repo_pr_popularity +1))
  data$repo_pr_team_size<-as.integer(data$repo_pr_team_size)
  data$repo_pr_team_size<-scale(log(data$repo_pr_team_size +1))
  data$perc_external_contribs<-as.integer(data$perc_external_contribs)
  data$perc_external_contribs<-scale(log(data$perc_external_contribs +1))

  
  data$closer_country <- factor(data$closer_country)                                    
  data$author_country <- factor(data$author_country)                                    
  data$author_continent <- factor(data$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
  
  data$prs_experience<-as.integer(data$prs_experience)
  data$prs_experience<-scale(log(data$prs_experience +1))
  data$prs_succ_rate<-as.integer(data$prs_succ_rate)
  data$prs_succ_rate<-scale(log(data$prs_succ_rate +1))
  data$prs_main_team_member<-factor(data$prs_main_team_member,levels=c(0,1))
  data$prs_popularity<-as.integer(data$prs_popularity)
  data$prs_popularity<-scale(log(data$prs_popularity +1))
  data$prs_tenure_mnth<-as.integer(data$prs_tenure_mnth)
  data$prs_tenure_mnth<-scale(log(data$prs_tenure_mnth +1))
  data$comments_counts<-as.integer(data$comments_counts)
  data$comments_counts<-scale(log(data$comments_counts +1))
  data$commit_counts<-as.integer(data$commit_counts)
  data$commit_counts<-scale(log(data$commit_counts +1))
  data$prs_watched_repo<-factor(data$prs_watched_repo,levels=c(0,1))
  data$prs_followed_pri<-factor(data$prs_followed_pri,levels=c(0,1))
  data$same_eth<-factor(data$same_eth,levels=c(0,1))
  data$same_country<-factor(data$same_country,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-factor(data$pr_files_changed,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-as.integer(data$pr_files_changed)
  data$pr_files_changed<-scale(log(data$pr_files_changed +1))
  data$pr_lines_changed<-as.integer(data$pr_lines_changed)
  data$pr_lines_changed<-scale(log(data$pr_lines_changed +1))
  return(data)

}
```


## making the samples from merged pull requests from the same repositories of the rejected reason
also bootstrapping and making the model

### Unnecessary Model

```{r}

#building the model for Unnecessary
set.seed(42)
category <- 'Unnecessary'
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]

df_nonmerged_factor_unn <- preprocess_data(df_nonmerged_factor_unn)

df_merged_factored <- preprocess_data(df_merged)

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_unn$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


formula <- status ~  comments_counts + commit_counts + code_changes_counts + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


num_bootstraps <- 1

bootstrapped_models <- list()

bootstrapped_parameters <- list()
sample_size <- nrow(df_nonmerged_factor_unn)

#bootstrapping the sample
for (i in 1:num_bootstraps) {
  # Resample the data with replacement from merged pull requests
  boot_indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
  bootstrap_sample <- df_merged_factored[boot_indices, ]
  
  # Combine the "Unnecessary" pull requests with the bootstrapped merged data
  combined_data_boot <- rbind(df_nonmerged_factor_unn, bootstrap_sample)

  # Refit the model on the combined bootstrapped data
  boot_model_unn <- glmer(formula, data = combined_data_boot, family = binomial,
                      control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
  bootstrapped_models[[i]] <- boot_model_unn

  # Extract and store the model parameters
  bootstrapped_parameters[[i]] <- coef(boot_model_unn)
}




```
```{r}
for (i in 1:num_bootstraps) {
  model_summary_unn <- summary(bootstrapped_models[[i]])
  #conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
  
  # Print or analyze the summary and confidence intervals as needed
  print(model_summary_unn, correlation=TRUE)
}
```

### Quality Model

```{r}
set.seed(44)
category <- 'Quality'
df_nonmerged_factor_qua <- df_nonmerged[df_nonmerged$manual_analysis == category, ]

df_nonmerged_factor_qua <- preprocess_data(df_nonmerged_factor_qua)

df_merged_factored <- preprocess_data(df_merged)

df_nonmerged_factor_qua <- df_nonmerged_factor_qua[, !colnames(df_nonmerged_factor_qua) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_qua$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


formula <- status ~  comments_counts + commit_counts + code_changes_counts + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


num_bootstraps <- 1

bootstrapped_models <- list()

bootstrapped_parameters <- list()
sample_size <- nrow(df_nonmerged_factor_qua)

#bootstrapping the sample
for (i in 1:num_bootstraps) {
  # Resample the data with replacement from merged pull requests
  boot_indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
  bootstrap_sample <- df_merged_factored[boot_indices, ]
  
  # Combine the "Unnecessary" pull requests with the bootstrapped merged data
  combined_data_boot <- rbind(df_nonmerged_factor_qua, bootstrap_sample)

  # Refit the model on the combined bootstrapped data
  boot_model_qua <- glmer(formula, data = combined_data_boot, family = binomial,
                      control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
  bootstrapped_models[[i]] <- boot_model_qua

  # Extract and store the model parameters
  bootstrapped_parameters[[i]] <- coef(boot_model_qua)
}




```

```{r}
for (i in 1:num_bootstraps) {
  model_summary_qua <- summary(bootstrapped_models[[i]])
  #conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
  
  # Print or analyze the summary and confidence intervals as needed
  print(model_summary_qua, correlation=TRUE)
}
```   

### Resolved Model

```{r}
set.seed(44)
category <- 'Resolved'
df_nonmerged_factor_res <- df_nonmerged[df_nonmerged$manual_analysis == category, ]

df_nonmerged_factor_res <- preprocess_data(df_nonmerged_factor_res)

df_merged_factored <- preprocess_data(df_merged)

df_nonmerged_factor_res <- df_nonmerged_factor_res[, !colnames(df_nonmerged_factor_res) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_res$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


formula <- status ~  comments_counts + commit_counts + code_changes_counts + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member +
repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


num_bootstraps <- 1

bootstrapped_models <- list()

bootstrapped_parameters <- list()
sample_size <- nrow(df_nonmerged_factor_res)

#bootstrapping the sample
for (i in 1:num_bootstraps) {
  # Resample the data with replacement from merged pull requests
  boot_indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
  bootstrap_sample <- df_merged_factored[boot_indices, ]
  
  # Combine the "Unnecessary" pull requests with the bootstrapped merged data
  combined_data_boot <- rbind(df_nonmerged_factor_res, bootstrap_sample)

  # Refit the model on the combined bootstrapped data
  boot_model_res <- glmer(formula, data = combined_data_boot, family = binomial,
                      control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
  bootstrapped_models[[i]] <- boot_model_res

  # Extract and store the model parameters
  bootstrapped_parameters[[i]] <- coef(boot_model_res)
}




```

```{r}
for (i in 1:num_bootstraps) {
  model_summary_res <- summary(bootstrapped_models[[i]])
  #conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
  
  # Print or analyze the summary and confidence intervals as needed
  print(model_summary_res, correlation=TRUE)
}
```

