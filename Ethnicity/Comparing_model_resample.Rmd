---
title: "Comparing_models"
output: html_document
date: "2023-09-18"
---

```{r}
library(readr)
library(dplyr)
library(forcats)
library(lme4)
library(glmnet)
library(optimx)
library(broom.mixed)

library(car)
library(stargazer)
library(texreg)
library(plyr)
library(xtable)
library(splitstackshape)
library(scales)

library(Hmisc)
library(lmerTest)
library(e1071)
library(ggplot2)
```
# Loading the data
```{r}
df_nonmerged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Non_Merged/Sample/temp/Sample_15000_manual.csv")
df_merged <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Merged/pr_merged_final_April_2023.csv")
df_comp <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/pr_final_April_2023.csv")
df_TSE <- read_csv("/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Reza's Dataset/TSE paper/2020-TSE-Developers-Perceptible-Ethnicity-and-PR-evaluation-main/Dataset/pull_requests.csv")
```

```{r}
df_TSE <- df_TSE %>%
  distinct(pr_id, .keep_all = TRUE)

df_nonmerged <- df_nonmerged %>%
  distinct(pr_id, .keep_all = TRUE)
```

```{r}
df_nonmerged <- left_join(df_nonmerged, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch), by= "pr_id", all.y = TRUE)
```

```{r}
df_merged <- left_join(df_merged, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch)
, by= "pr_id", all.y = TRUE)

df_comp <- left_join(df_comp, select(df_TSE, pr_id, prs_pri_same_nationality, prs_experience, prs_succ_rate, prs_popularity, prs_watched_repo, prs_followed_pri, prs_tenure_mnth, prs_main_team_member, repo_pr_tenure_mnth, repo_pr_popularity,repo_pr_team_size, perc_external_contribs, pr_opened_at, pr_files_changed, pr_lines_changed, intra_branch) , by= "pr_id", all.y = TRUE)
```

### Dropping the columns (depricated)

```{r}
df_nonmerged <- df_nonmerged %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, closer_id, comments, created_at, closed_at))


df_merged <- df_merged %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, comments, created_at, closed_at))


df_comp <- df_comp %>%
  select(-c(`Unnamed: 0`, pr_id, api_url, url, pr_url, prs_white, prs_api, prs_black, prs_hispanic, pri_white, pri_black, pri_api, pri_hispanic , pr_api_url, author_desc_body, comments, created_at, closed_at))

```

```{r}
df_comp <- df_comp %>%
  select(-c(closer_id))
```

# Building the model in rejected categories(Depricated)

for one rejected category against all the other categories. here for testing we are going to use \## Encoding the manual analysis label and factoring the rest

```{r}
# Create a copy of df_nonmerged
df_nonmerged_factor <- df_nonmerged

# Define encoding for 'manual_analysis' column
encoding <- c(
  'Quality' = 0, 'Successful' = 0, 'Unnecessary' = 1, 'No Reason' = 0,
  'Resolved' = 0, 'Replaced' = 0, 'Duplicate' = 0, 'Stale' = 0,
  'Merge Conflict' = 0, 'Chaotic' = 0, 'Not PR' = 0, 'No Comment' = 0
)

df_nonmerged_factor$manual_analysis <- as.integer(factor(df_nonmerged_factor$manual_analysis, levels = names(encoding)))
df_nonmerged_factor$manual_analysis <- encoding[df_nonmerged_factor$manual_analysis]

df_nonmerged_factor$status<-factor(df_nonmerged_factor$status,levels=c("not-merged","merged"))

df_nonmerged_factor$repo_pr_tenure_mnth<-as.integer(df_nonmerged_factor$repo_pr_tenure_mnth)
df_nonmerged_factor$repo_pr_tenure_mnth<-scale(log(df_nonmerged_factor$repo_pr_tenure_mnth +1))
df_nonmerged_factor$repo_pr_popularity<-as.integer(df_nonmerged_factor$repo_pr_popularity)
df_nonmerged_factor$repo_pr_popularity<-scale(log(df_nonmerged_factor$repo_pr_popularity +1))
df_nonmerged_factor$repo_pr_team_size<-as.integer(df_nonmerged_factor$repo_pr_team_size)
df_nonmerged_factor$repo_pr_team_size<-scale(log(df_nonmerged_factor$repo_pr_team_size +1))
df_nonmerged_factor$perc_external_contribs<-as.integer(df_nonmerged_factor$perc_external_contribs)
df_nonmerged_factor$perc_external_contribs<-scale(log(df_nonmerged_factor$perc_external_contribs +1))

df_nonmerged_factor$closer_country <- factor(df_nonmerged_factor$closer_country)                                    
df_nonmerged_factor$author_country <- factor(df_nonmerged_factor$author_country)                                    
df_nonmerged_factor$author_continent <- factor(df_nonmerged_factor$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_nonmerged_factor$prs_experience<-as.integer(df_nonmerged_factor$prs_experience)
df_nonmerged_factor$prs_experience<-scale(log(df_nonmerged_factor$prs_experience +1))
df_nonmerged_factor$prs_succ_rate<-as.integer(df_nonmerged_factor$prs_succ_rate)
df_nonmerged_factor$prs_succ_rate<-scale(log(df_nonmerged_factor$prs_succ_rate +1))
df_nonmerged_factor$prs_main_team_member<-factor(df_nonmerged_factor$prs_main_team_member,levels=c(0,1))
df_nonmerged_factor$prs_popularity<-as.integer(df_nonmerged_factor$prs_popularity)
df_nonmerged_factor$prs_popularity<-scale(log(df_nonmerged_factor$prs_popularity +1))
df_nonmerged_factor$prs_tenure_mnth<-as.integer(df_nonmerged_factor$prs_tenure_mnth)
df_nonmerged_factor$prs_tenure_mnth<-scale(log(df_nonmerged_factor$prs_tenure_mnth +1))
df_nonmerged_factor$comments_counts<-as.integer(df_nonmerged_factor$comments_counts)
df_nonmerged_factor$comments_counts<-scale(log(df_nonmerged_factor$comments_counts +1))
df_nonmerged_factor$commit_counts<-as.integer(df_nonmerged_factor$commit_counts)
df_nonmerged_factor$commit_counts<-scale(log(df_nonmerged_factor$commit_counts +1))
df_nonmerged_factor$prs_watched_repo<-factor(df_nonmerged_factor$prs_watched_repo,levels=c(0,1))
df_nonmerged_factor$prs_followed_pri<-factor(df_nonmerged_factor$prs_followed_pri,levels=c(0,1))
df_nonmerged_factor$same_eth<-factor(df_nonmerged_factor$same_eth,levels=c(0,1))
df_nonmerged_factor$same_country<-factor(df_nonmerged_factor$same_country,levels=c(0,1))
df_nonmerged_factor$intra_branch<-factor(df_nonmerged_factor$intra_branch,levels=c(0,1))


```

```{r}
table(df_nonmerged_factor$manual_analysis)
```

```{r}
# Define the columns with '\\N' values
columns_with_n_values <- c('same_country', 'prs_pri_same_nationality')

# Create a logical mask to identify rows with '\\N' in any of the specified columns
mask <- apply(df_nonmerged_encoded[columns_with_n_values], 1, function(row) any(grepl('\\N', row)))

# Use the mask to filter and display the rows where '\\N' occurs
rows_with_n_values <- df_nonmerged_encoded[mask, ]

# Replace '\\N' values with 0 in the selected columns
for (column in columns_with_n_values) {
  df_nonmerged_encoded[[column]][df_nonmerged_encoded[[column]] == '\\N'] <- 0
}


```

formula \<- manual_analysis \~ status + comments_counts (1) + commit_counts(0) + code_changes_counts(0) + author_country(0) + closer_country(0) + author_continent(1) + same_country(1) + author_eth(1) + closer_eth() + same_eth(Û±) + prs_white() + prs_api() + prs_black() + prs_hispanic() + pri_white() + pri_black() + pri_api() + pri_hispanic() + prs_eth_8() + prs_eth_7() + prs_eth_9() + prs_eth_diff() + prs_eth_diff_2() + manual_analysis() + prs_experience(0) + prs_succ_rate(0) + prs_popularity(0) + prs_watched_repo(0) + prs_followed_pri(0) + prs_tenure_mnth(0) + prs_main_team_member() + (1 \| author_id)

formula \<- manual_analysis \~ comments_counts + commit_counts + code_changes_counts + author_continent + author_eth + closer_eth + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + pr_opened_at + pr_files_changed + pr_lines_changed + intra_branch + (1 \| repo_id) + (1 \| author_id)

```{r}
formula <- manual_analysis ~  comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member +
repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

glmer_model_unnecessary<-glmer(formula, data=df_nonmerged_factor, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model_unnecessary), correlation=FALSE)
car::vif(glmer_model_unnecessary)

effect_size_glmer_model = anova(glmer_model_unnecessary,test='Chisq')
print(effect_size_glmer_model)
```

Now we try the model without the ethnicity

```{r}
formula <- manual_analysis ~  comments_counts + commit_counts + code_changes_counts + prs_pri_same_nationality + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + (1 | repo_id) + (1 | author_id)

glmer_model_unnecessary_we<-glmer(formula, data=df_nonmerged_factor, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model_unnecessary_we), correlation=FALSE)
car::vif(glmer_model_unnecessary_we)

effect_size_glmer_model = anova(glmer_model_unnecessary_we,test='Chisq')
print(effect_size_glmer_model)
```

# Building the model for all merged and nonmerged pull reqests (Depricated)

this would be based on status of the pull request

## Encoding the model(depricated)

```{r}
# Create a copy of df_nonmerged
df_comp_encoded <- df_comp

# Define encoding for 'manual_analysis' column
encoding <- c(
  'Quality' = 0, 'Successful' = 0, 'Unnecessary' = 1, 'No reason' = 0,
  'Resolved' = 0, 'Replaced' = 0, 'Duplicate' = 0, 'Stale' = 0,
  'Merge Conflict' = 0, 'Chaotic' = 0, 'Not PR' = 0
  
)

# Map the encoding to 'manual_analysis' and convert to integer
#df_nonmerged_encoded$manual_analysis <- as.integer(factor(df_nonmerged_encoded$manual_analysis, levels = names(encoding)))
#df_nonmerged_encoded$manual_analysis <- encoding[df_nonmerged_encoded$manual_analysis]

# Replace missing values with 0 in selected columns
df_comp_encoded[is.na(df_comp_encoded)] <- 0

# Encode categorical columns using forcats
categorical_cols <- c(
  'author_id', 'author_eth', 'author_country', 'author_continent',
  'closer_eth', 'prs_eth_8', 'prs_eth_7', 'prs_eth_9',
  'prs_eth_diff', 'prs_eth_diff_2', 'closer_country'
)

for (col in categorical_cols) {
  df_comp_encoded[[col]] <- as.integer(factor(df_comp_encoded[[col]]))
}
# encoding status as zero for merged and 1 for not-merged
df_comp_encoded$status <- ifelse(df_comp_encoded$status == "merged", 0, 1)


```

## factoring the values

instead of encoding, i'm gonna use factoring

```{r}
df_comp_factor <- df_comp


df_comp_factor$status<-factor(df_comp_factor$status,levels=c("not-merged","merged"))

df_comp_factor$repo_pr_tenure_mnth<-as.integer(df_comp_factor$repo_pr_tenure_mnth)
df_comp_factor$repo_pr_tenure_mnth<-scale(log(df_comp_factor$repo_pr_tenure_mnth +1))
df_comp_factor$repo_pr_popularity<-as.integer(df_comp_factor$repo_pr_popularity)
df_comp_factor$repo_pr_popularity<-scale(log(df_comp_factor$repo_pr_popularity +1))
df_comp_factor$repo_pr_team_size<-as.integer(df_comp_factor$repo_pr_team_size)
df_comp_factor$repo_pr_team_size<-scale(log(df_comp_factor$repo_pr_team_size +1))
df_comp_factor$perc_external_contribs<-as.integer(df_comp_factor$perc_external_contribs)
df_comp_factor$perc_external_contribs<-scale(log(df_comp_factor$perc_external_contribs +1))

df_comp_factor$closer_country <- factor(df_comp_factor$closer_country)                                    
df_comp_factor$author_country <- factor(df_comp_factor$author_country)                                    
df_comp_factor$author_continent <- factor(df_comp_factor$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_comp_factor$prs_experience<-as.integer(df_comp_factor$prs_experience)
df_comp_factor$prs_experience<-scale(log(df_comp_factor$prs_experience +1))
df_comp_factor$prs_succ_rate<-as.integer(df_comp_factor$prs_succ_rate)
df_comp_factor$prs_succ_rate<-scale(log(df_comp_factor$prs_succ_rate +1))
df_comp_factor$prs_main_team_member<-factor(df_comp_factor$prs_main_team_member,levels=c(0,1))
df_comp_factor$prs_popularity<-as.integer(df_comp_factor$prs_popularity)
df_comp_factor$prs_popularity<-scale(log(df_comp_factor$prs_popularity +1))
df_comp_factor$prs_tenure_mnth<-as.integer(df_comp_factor$prs_tenure_mnth)
df_comp_factor$prs_tenure_mnth<-scale(log(df_comp_factor$prs_tenure_mnth +1))
df_comp_factor$comments_counts<-as.integer(df_comp_factor$comments_counts)
df_comp_factor$comments_counts<-scale(log(df_comp_factor$comments_counts +1))
df_comp_factor$commit_counts<-as.integer(df_comp_factor$commit_counts)
df_comp_factor$commit_counts<-scale(log(df_comp_factor$commit_counts +1))
df_comp_factor$prs_watched_repo<-factor(df_comp_factor$prs_watched_repo,levels=c(0,1))
df_comp_factor$prs_followed_pri<-factor(df_comp_factor$prs_followed_pri,levels=c(0,1))
df_comp_factor$same_eth<-factor(df_comp_factor$same_eth,levels=c(0,1))
df_comp_factor$same_country<-factor(df_comp_factor$same_country,levels=c(0,1))
df_comp_factor$intra_branch<-factor(df_comp_factor$intra_branch,levels=c(0,1))



```

## remove the \\N values and change them with 0

```{r}
# Define the columns with '\\N' values
columns_with_n_values <- c('same_country', 'prs_pri_same_nationality')

# Create a logical mask to identify rows with '\\N' in any of the specified columns
mask <- apply(df_comp_encoded[columns_with_n_values], 1, function(row) any(grepl('\\N', row)))

# Use the mask to filter and display the rows where '\\N' occurs
rows_with_n_values <- df_comp_encoded[mask, ]

# Replace '\\N' values with 0 in the selected columns
for (column in columns_with_n_values) {
  df_comp_encoded[[column]][df_comp_encoded[[column]] == '\\N'] <- 0
}


```

## Building the model

sampling the data to time the model and see if this works

```{r}
df_comp_factor_sample <- df_comp_factor %>% sample_n(10000) 
```

also normalizing to see what is the problem

```{r}
#df_comp_factor_sample <- df_comp_factor_sample %>% mutate_at(vars(code_changes_counts, author_country, closer_country, prs_experience, #prs_succ_rate, prs_popularity, prs_watched_repo, prs_tenure_mnth ), scale)

```

formula \<- status \~ comments_counts + commit_counts + code_changes_counts + author_country + closer_country + author_continent + same_country\<\> + author_eth + closer_eth + same_eth\<\> + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_followed_pri \<\> + prs_tenure_mnth + prs_main_team_member \<\>+ (1 \| repo_id) + (1 \| author_id)

```{r}
#formula <- status ~ comments_counts + commit_counts + author_continent  + author_eth + closer_eth  +  (1 | repo_id) 
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)
model <- glmer(formula, data = df_comp_encoded_sample, family = binomial, glmerControl( optCtrl = list(maxfun=1e5)))

```

```{r}
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)

glmer_model<-glmer(formula, data=df_comp_factor_sample, family=binomial,control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
print(summary(glmer_model), correlation=FALSE)
car::vif(glmer_model)

effect_size_glmer_model = anova(glmer_model,test='Chisq')
print(effect_size_glmer_model)
```

```{r}
summary(model)
```

# Building the model in rejected categories with samples of merged (Depricated)

## Sampling the Data from merged prs based on nonmerged prs rejection reasons (Depricated as no bootstrapping)

```{r}
category <- 'Unnecessary'

 # Calculate the desired number of samples for the specified category
number_of_samples <- sum(df_nonmerged$manual_analysis == category)

 #Filter repo_id values associated with the specified category in df_nonmerged
repo_ids_for_category <- unique(df_nonmerged[df_nonmerged$manual_analysis == category, ]$repo_id)

 # Filter 'df_merged' to keep only rows with 'repo_id' values in repo_ids_for_category
filtered_df_merged <- df_merged[df_merged$repo_id %in% repo_ids_for_category, ]

 # Create an empty data frame to store the sampled data
sampled_data <- data.frame()

 # Iterate through the repositories with rejected PRs in the specified category
for (repo_id in repo_ids_for_category) {
  # Filter rows from filtered_df_merged for the current repo_id
  repo_samples <- filtered_df_merged[filtered_df_merged$repo_id == repo_id, ]
  
  # If there are multiple samples for the current repo, select one randomly
  if (nrow(repo_samples) > 1) {
    set.seed(42)  # Set seed for reproducibility
    repo_samples <- repo_samples[sample(nrow(repo_samples), size = 1), ]
  }
  
  # Append the selected sample to the sampled_data data frame
  sampled_data <- rbind(sampled_data, repo_samples)
}

 # Randomly select additional samples to reach the desired number
remaining_samples <- number_of_samples - nrow(sampled_data)
set.seed(42)  # Set seed for reproducibility
additional_samples <- filtered_df_merged[sample(nrow(filtered_df_merged), size = remaining_samples), ]

 # Append the additional samples to the sampled_data data frame
sampled_data <- rbind(sampled_data, additional_samples)
```

checking to see if the repos are the same

```{r}
 # Get the unique 'repo_id' values from the sampled_data data frame
sampled_repo_ids <- unique(sampled_data$repo_id)

 # Check if all sampled 'repo_id' values are in 'repo_ids_for_category'
if(all(sampled_repo_ids %in% repo_ids_for_category)) {
  cat("All samples are from repositories with the specified rejected reason.\n")
} else {
  cat("Some samples are not from repositories with the specified rejected reason.\n")
}
```

```{r}
 # there is a closer_id feature in sample_reason that is not in nonmerged, let's drop that first
sampled_data <- sampled_data[, !(names(sampled_data) %in% "closer_id")]
sampled_data <- sampled_data[, !(names(sampled_data) %in%  "checked")]

```

```{r}

common_columns <- intersect(names(df_nonmerged), names(sampled_data))
sampled_data <- sampled_data %>% rename(!!!setNames(common_columns, common_columns))
df_nonmerged_category <- df_nonmerged[df_nonmerged$manual_analysis == category, ]
df_nonmerged_category <- df_nonmerged_category[, !(names(df_nonmerged_category) %in% "manual_analysis")]


 # Concatenate data frames df_nonmerged and sampled_data by rows
df_sample_reason <- rbind(df_nonmerged_category, sampled_data) 


 # Sort the resulting data frame by 'repo_id'
df_sample_reason <- df_sample_reason[order(df_sample_reason$repo_id), ]

 # Drop the 'checked' and 'manual_analysis' columns
df_sample_reason <- df_sample_reason[, !(names(df_sample_reason) %in% c('checked', 'manual_analysis'))]

```

```{r}
table(df_sample_reason$status)

```

## Encoding and building the model (depricated)

```{r}
 # Create a copy of df_nonmerged
df_sample_reason_encoded <- df_sample_reason

 # Define encoding for 'manual_analysis' column
 
 # Map the encoding to 'manual_analysis' and convert to integer



 # Replace missing values with 0 in selected columns
df_sample_reason_encoded[is.na(df_sample_reason_encoded)] <- 0

 # Encode categorical columns using forcats
categorical_cols <- c(
  'author_id', 'author_eth', 'author_country', 'author_continent',
  'closer_eth', 'prs_eth_8', 'prs_eth_7', 'prs_eth_9',
  'prs_eth_diff', 'prs_eth_diff_2', 'closer_country'
)

for (col in categorical_cols) {
  df_sample_reason_encoded[[col]] <- as.integer(factor(df_sample_reason_encoded[[col]]))
}
 # encoding status as zero for merged and 1 for not-merged
df_sample_reason_encoded$status <- ifelse(df_sample_reason_encoded$status == "merged", 0, 1)
```

```{r}
formula <- status ~ comments_counts + commit_counts + code_changes_counts + author_country + closer_country + author_continent  + author_eth + closer_eth  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth +  (1 | repo_id) + (1 | author_id)
model_2 <- glmer(formula, data = df_sample_reason_encoded, family = binomial, glmerControl( optCtrl = list(maxfun=1e5)))
```

```{r}
summary(model_2)
```

## selecting the category, getting the data for that category and Factoring the data (Depricated as i did it in a function)

```{r}
category <- 'Unnecessary'

# Factoring for both merged and nonmerged
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]
df_merged_factored <- df_merged

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



df_nonmerged_factor_unn$status<-factor(df_nonmerged_factor_unn$status,levels=c("not-merged","merged"))
df_merged_factored$status<-factor(df_merged_factored$status,levels=c("not-merged","merged"))

df_nonmerged_factor_unn$repo_pr_tenure_mnth<-as.integer(df_nonmerged_factor_unn$repo_pr_tenure_mnth)
df_nonmerged_factor_unn$repo_pr_tenure_mnth<-scale(log(df_nonmerged_factor_unn$repo_pr_tenure_mnth +1))
df_nonmerged_factor_unn$repo_pr_popularity<-as.integer(df_nonmerged_factor_unn$repo_pr_popularity)
df_nonmerged_factor_unn$repo_pr_popularity<-scale(log(df_nonmerged_factor_unn$repo_pr_popularity +1))
df_nonmerged_factor_unn$repo_pr_team_size<-as.integer(df_nonmerged_factor_unn$repo_pr_team_size)
df_nonmerged_factor_unn$repo_pr_team_size<-scale(log(df_nonmerged_factor_unn$repo_pr_team_size +1))
df_nonmerged_factor_unn$perc_external_contribs<-as.integer(df_nonmerged_factor_unn$perc_external_contribs)
df_nonmerged_factor_unn$perc_external_contribs<-scale(log(df_nonmerged_factor_unn$perc_external_contribs +1))

df_merged_factored$repo_pr_tenure_mnth<-as.integer(df_merged_factored$repo_pr_tenure_mnth)
df_merged_factored$repo_pr_tenure_mnth<-scale(log(df_merged_factored$repo_pr_tenure_mnth +1))
df_merged_factored$repo_pr_popularity<-as.integer(df_merged_factored$repo_pr_popularity)
df_merged_factored$repo_pr_popularity<-scale(log(df_merged_factored$repo_pr_popularity +1))
df_merged_factored$repo_pr_team_size<-as.integer(df_merged_factored$repo_pr_team_size)
df_merged_factored$repo_pr_team_size<-scale(log(df_merged_factored$repo_pr_team_size +1))
df_merged_factored$perc_external_contribs<-as.integer(df_merged_factored$perc_external_contribs)
df_merged_factored$perc_external_contribs<-scale(log(df_merged_factored$perc_external_contribs +1))

df_nonmerged_factor_unn$closer_country <- factor(df_nonmerged_factor_unn$closer_country)                                    
df_nonmerged_factor_unn$author_country <- factor(df_nonmerged_factor_unn$author_country)                                    
df_nonmerged_factor_unn$author_continent <- factor(df_nonmerged_factor_unn$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))

df_merged_factored$closer_country <- factor(df_merged_factored$closer_country)                                    
df_merged_factored$author_country <- factor(df_merged_factored$author_country)                                    
df_merged_factored$author_continent <- factor(df_merged_factored$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                    
                                    
                                    
df_nonmerged_factor_unn$prs_experience<-as.integer(df_nonmerged_factor_unn$prs_experience)
df_nonmerged_factor_unn$prs_experience<-scale(log(df_nonmerged_factor_unn$prs_experience +1))
df_nonmerged_factor_unn$prs_succ_rate<-as.integer(df_nonmerged_factor_unn$prs_succ_rate)
df_nonmerged_factor_unn$prs_succ_rate<-scale(log(df_nonmerged_factor_unn$prs_succ_rate +1))
df_nonmerged_factor_unn$prs_main_team_member<-factor(df_nonmerged_factor_unn$prs_main_team_member,levels=c(0,1))
df_nonmerged_factor_unn$prs_popularity<-as.integer(df_nonmerged_factor_unn$prs_popularity)
df_nonmerged_factor_unn$prs_popularity<-scale(log(df_nonmerged_factor_unn$prs_popularity +1))
df_nonmerged_factor_unn$prs_tenure_mnth<-as.integer(df_nonmerged_factor_unn$prs_tenure_mnth)
df_nonmerged_factor_unn$prs_tenure_mnth<-scale(log(df_nonmerged_factor_unn$prs_tenure_mnth +1))
df_nonmerged_factor_unn$comments_counts<-as.integer(df_nonmerged_factor_unn$comments_counts)
df_nonmerged_factor_unn$comments_counts<-scale(log(df_nonmerged_factor_unn$comments_counts +1))
df_nonmerged_factor_unn$commit_counts<-as.integer(df_nonmerged_factor_unn$commit_counts)
df_nonmerged_factor_unn$commit_counts<-scale(log(df_nonmerged_factor_unn$commit_counts +1))
df_nonmerged_factor_unn$prs_watched_repo<-factor(df_nonmerged_factor_unn$prs_watched_repo,levels=c(0,1))
df_nonmerged_factor_unn$prs_followed_pri<-factor(df_nonmerged_factor_unn$prs_followed_pri,levels=c(0,1))
df_nonmerged_factor_unn$same_eth<-factor(df_nonmerged_factor_unn$same_eth,levels=c(0,1))
df_nonmerged_factor_unn$same_country<-factor(df_nonmerged_factor_unn$same_country,levels=c(0,1))
df_nonmerged_factor_unn$intra_branch<-factor(df_nonmerged_factor_unn$intra_branch,levels=c(0,1))

                                    
df_merged_factored$prs_experience<-as.integer(df_merged_factored$prs_experience)
df_merged_factored$prs_experience<-scale(log(df_merged_factored$prs_experience +1))
df_merged_factored$prs_succ_rate<-as.integer(df_merged_factored$prs_succ_rate)
df_merged_factored$prs_succ_rate<-scale(log(df_merged_factored$prs_succ_rate +1))
df_merged_factored$prs_main_team_member<-factor(df_merged_factored$prs_main_team_member,levels=c(0,1))
df_merged_factored$prs_popularity<-as.integer(df_merged_factored$prs_popularity)
df_merged_factored$prs_popularity<-scale(log(df_merged_factored$prs_popularity +1))
df_merged_factored$prs_tenure_mnth<-as.integer(df_merged_factored$prs_tenure_mnth)
df_merged_factored$prs_tenure_mnth<-scale(log(df_merged_factored$prs_tenure_mnth +1))
df_merged_factored$comments_counts<-as.integer(df_merged_factored$comments_counts)
df_merged_factored$comments_counts<-scale(log(df_merged_factored$comments_counts +1))
df_merged_factored$commit_counts<-as.integer(df_merged_factored$commit_counts)
df_merged_factored$commit_counts<-scale(log(df_merged_factored$commit_counts +1))
df_merged_factored$prs_watched_repo<-factor(df_merged_factored$prs_watched_repo,levels=c(0,1))
df_merged_factored$prs_followed_pri<-factor(df_merged_factored$prs_followed_pri,levels=c(0,1))
df_merged_factored$same_eth<-factor(df_merged_factored$same_eth,levels=c(0,1))
df_merged_factored$same_country<-factor(df_merged_factored$same_country,levels=c(0,1))
df_merged_factored$intra_branch<-factor(df_merged_factored$intra_branch,levels=c(0,1))

```

## Preprocessing the data as a Function
```{r}
preprocess_data <- function(data){
  
  #Factorizing and scaling
  data$status <- factor(data$status, levels = c("not-merged", "merged"))
  data$repo_pr_tenure_mnth<-as.integer(data$repo_pr_tenure_mnth)
  data$repo_pr_tenure_mnth<-scale(log(data$repo_pr_tenure_mnth +1))
  data$repo_pr_popularity<-as.integer(data$repo_pr_popularity)
  data$repo_pr_popularity<-scale(log(data$repo_pr_popularity +1))
  data$repo_pr_team_size<-as.integer(data$repo_pr_team_size)
  data$repo_pr_team_size<-scale(log(data$repo_pr_team_size +1))
  data$perc_external_contribs<-as.integer(data$perc_external_contribs)
  data$perc_external_contribs<-scale(log(data$perc_external_contribs +1))

  
  data$closer_country <- factor(data$closer_country)                                    
  data$author_country <- factor(data$author_country)                                    
  data$author_continent <- factor(data$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
  
  data$prs_experience<-as.integer(data$prs_experience)
  data$prs_experience<-scale(log(data$prs_experience +1))
  data$prs_succ_rate<-as.integer(data$prs_succ_rate)
  data$prs_succ_rate<-scale(log(data$prs_succ_rate +1))
  data$prs_main_team_member<-factor(data$prs_main_team_member,levels=c(0,1))
  data$prs_popularity<-as.integer(data$prs_popularity)
  data$prs_popularity<-scale(log(data$prs_popularity +1))
  data$prs_tenure_mnth<-as.integer(data$prs_tenure_mnth)
  data$prs_tenure_mnth<-scale(log(data$prs_tenure_mnth +1))
  data$comments_counts<-as.integer(data$comments_counts)
  data$comments_counts<-scale(log(data$comments_counts +1))
  data$commit_counts<-as.integer(data$commit_counts)
  data$commit_counts<-scale(log(data$commit_counts +1))
  data$prs_watched_repo<-factor(data$prs_watched_repo,levels=c(0,1))
  data$prs_followed_pri<-factor(data$prs_followed_pri,levels=c(0,1))
  data$same_eth<-factor(data$same_eth,levels=c(0,1))
  data$same_country<-factor(data$same_country,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-factor(data$pr_files_changed,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-as.integer(data$pr_files_changed)
  data$pr_files_changed<-scale(log(data$pr_files_changed +1))
  data$pr_lines_changed<-as.integer(data$pr_lines_changed)
  data$pr_lines_changed<-scale(log(data$pr_lines_changed +1))
  return(data)

}
```


# Removing highly correlated features


# Building the model for merged pull requests from the same repositories of the rejected reason

### bootstrapped Model( depricated)

```{r}

#building the model for Unnecessary
set.seed(42)
category <- 'Unnecessary'
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]

df_nonmerged_factor_unn <- preprocess_data(df_nonmerged_factor_unn)

df_merged_factored <- preprocess_data(df_merged)

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_unn$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids, ]


formula <- status ~  comments_counts + commit_counts + code_changes_counts  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


num_bootstraps <- 1

bootstrapped_models <- list()

bootstrapped_parameters <- list()
sample_size <- nrow(df_nonmerged_factor_unn)

#bootstrapping the sample
for (i in 1:num_bootstraps) {
  # Resample the data with replacement from merged pull requests
  boot_indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
  bootstrap_sample <- df_merged_factored[boot_indices, ]
  
  # Combine the "Unnecessary" pull requests with the bootstrapped merged data
  combined_data_boot <- rbind(df_nonmerged_factor_unn, bootstrap_sample)

  # Refit the model on the combined bootstrapped data
  boot_model_unn <- glmer(formula, data = combined_data_boot, family = binomial,
                      control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))
  bootstrapped_models[[i]] <- boot_model_unn

  # Extract and store the model parameters
  bootstrapped_parameters[[i]] <- coef(boot_model_unn)
}




```
```{r}
for (i in 1:num_bootstraps) {
  model_summary_unn <- summary(bootstrapped_models[[i]])
  #conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
  
  # Print or analyze the=
  print(model_summary_unn, correlation=TRUE)
}
```
```{r}
fixed_effects <- fixef(boot_model_unn)
odds_ratios <- exp(fixed_effects)
print(odds_ratios)

```

```{r}
class(coef(boot_model_unn))

```



# Normalization

```{r}
# Factoring and scaling 
preprocess_data_norm <- function(data){
  

  data$status <- factor(data$status, levels = c("merged", "not-merged"))


  
  data$closer_country <- factor(data$closer_country)                                    
  data$author_country <- factor(data$author_country)                                    
  data$author_continent <- factor(data$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
  
  data$comments_counts<-as.integer(data$comments_counts)
  data$comments_counts<-scale(log(data$comments_counts +1))
  data$commit_counts<-as.integer(data$commit_counts)
  data$commit_counts<-scale(log(data$commit_counts +1))
  data$code_changes_counts<-as.integer(data$code_changes_counts)
  data$code_changes_counts<-scale(log(data$code_changes_counts +1))
  data$prs_experience<-as.integer(data$prs_experience)
  data$prs_experience<-scale(log(data$prs_experience +1))
  data$prs_succ_rate<-as.integer(data$prs_succ_rate)
  data$prs_succ_rate<-scale(log(data$prs_succ_rate +1))
  data$prs_popularity<-as.integer(data$prs_popularity)
  data$prs_popularity<-scale(log(data$prs_popularity +1))
  data$prs_tenure_mnth<-as.integer(data$prs_tenure_mnth)
  data$prs_tenure_mnth<-scale(log(data$prs_tenure_mnth +1))
  data$repo_pr_tenure_mnth<-as.integer(data$repo_pr_tenure_mnth)
  data$repo_pr_tenure_mnth<-scale(log(data$repo_pr_tenure_mnth +1))
  data$repo_pr_popularity<-as.integer(data$repo_pr_popularity)
  data$repo_pr_popularity<-scale(log(data$repo_pr_popularity +1))
  data$repo_pr_team_size<-as.integer(data$repo_pr_team_size)
  data$repo_pr_team_size<-scale(log(data$repo_pr_team_size +1))
  data$perc_external_contribs<-as.integer(data$perc_external_contribs)
  data$perc_external_contribs<-scale(log(data$perc_external_contribs +1))
  data$pr_lines_changed<-as.integer(data$pr_lines_changed)
  data$pr_lines_changed<-scale(log(data$pr_lines_changed +1))


  data$prs_main_team_member<-factor(data$prs_main_team_member,levels=c(0,1))
  data$prs_watched_repo<-factor(data$prs_watched_repo,levels=c(0,1))
  data$prs_followed_pri<-factor(data$prs_followed_pri,levels=c(0,1))
  data$same_eth<-factor(data$same_eth,levels=c(0,1))
  data$same_country<-factor(data$same_country,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
  data$pr_files_changed<-factor(data$pr_files_changed,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))

  
  
#  data$closer_country <- factor(data$closer_country)                                    
 # data$author_country <- factor(data$author_country)                                    
  #data$author_continent <- factor(data$author_continent,levels=c("Asia","Africa","South America","Antarctica", "Unknown", "North America", "Europe", "Oceania"))
                                      
                                      
  data$prs_main_team_member<-factor(data$prs_main_team_member,levels=c(0,1))
  data$prs_watched_repo<-factor(data$prs_watched_repo,levels=c(0,1))
  data$prs_followed_pri<-factor(data$prs_followed_pri,levels=c(0,1))
  data$same_eth<-factor(data$same_eth,levels=c(0,1))
  data$same_country<-factor(data$same_country,levels=c(0,1))
  data$intra_branch<-factor(data$intra_branch,levels=c(0,1))
    # List of columns to normalize
  #columns_to_normalize <- c("comments_counts", "commit_counts", "code_changes_counts", "prs_experience", 
   #                         "prs_succ_rate", "prs_popularity", "prs_tenure_mnth", "repo_pr_tenure_mnth", 
    #                        "repo_pr_popularity", "repo_pr_team_size", "perc_external_contribs", 
     #                       "pr_files_changed", "pr_lines_changed")
  
  #for (col in columns_to_normalize) {
   # data[[col]] <- rescale(data[[col]])
  #}

  return(data)

}

df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

df_merged_factored <- preprocess_data_norm(df_merged)

df_comp_factored <- preprocess_data_norm(df_comp)


```
# combined normalization
```{r}
preprocess_data_norm_test <- function(data) {
  # Convert status to factor
  data$status <- factor(data$status, levels = c("merged", "not-merged"))

  # List of numeric variables to apply log transformation and robust scaling
  numeric_vars <- c("comments_counts", "commit_counts", "prs_experience", "prs_succ_rate", "prs_popularity", "prs_tenure_mnth", "repo_pr_tenure_mnth", "repo_pr_popularity", "repo_pr_team_size", "perc_external_contribs", "pr_lines_changed")

  # Apply log transformation and robust scaling
  for (var in numeric_vars) {
    # Log transformation (adding 1 to avoid log(0))
    data[[var]]<-as.integer(data[[var]])
    #data[[var]] <- scale(log(data[[var]] + 1))
    
    # Calculate median and IQR for robust scaling
    #median_val <- median(data[[var]], na.rm = TRUE)
    #iqr_val <- IQR(data[[var]], na.rm = TRUE)

    # Perform robust scaling
    #data[[var]] <- (data[[var]] - median_val) / iqr_val
    
    #z-score
    #data[[var]] <- (data[[var]] - mean(data[[var]], na.rm = TRUE)) / sd(data[[var]], na.rm = TRUE)
    
    #min-max
    #data[[var]] <- (data[[var]] - min(data[[var]], na.rm = TRUE)) / (max(data[[var]], na.rm = TRUE) - min(data[[var]], na.rm = TRUE))
  
    #mean
    #data[[var]] <- (data[[var]] - mean(data[[var]], na.rm = TRUE)) / (max(data[[var]], na.rm = TRUE) - min(data[[var]], na.rm = TRUE))
    
    #square root
    #data[[var]] <- sqrt(data[[var]])

  }

  # Convert binary variables to factors
  binary_vars <- c("prs_main_team_member", "prs_watched_repo", "prs_followed_pri", "intra_branch", "pr_files_changed")
  for (var in binary_vars) {
    data[[var]] <- factor(data[[var]], levels = c(0, 1))
  }

  return(data)
}

df_nonmerged_factor <- preprocess_data_norm_test(df_nonmerged)

df_merged_factored <- preprocess_data_norm_test(df_merged)

df_comp_factored <- preprocess_data_norm_test(df_comp)
```


# Getting the summary as a dataframe
```{r}
create_model_summary_df <- function(model) {
  # Extract model coefficients
  coefs <- summary(model)$coefficients
  
  # Create a dataframe from the coefficients
  df <- as.data.frame(coefs)
  
  # Calculate odds ratios for fixed effects
  df$odds_ratio <- exp(df[, "Estimate"])
  
  # Add row names as a new column for the terms
  df$term <- rownames(df)
  
  # Determine significance levels
  df$Significance <- ifelse(df[, "Pr(>|z|)"] < 0.001, '***',
                            ifelse(df[, "Pr(>|z|)"] < 0.01, '**',
                            ifelse(df[, "Pr(>|z|)"] < 0.05, '*',
                            ifelse(df[, "Pr(>|z|)"] < 0.1, '.', ' '))))
  
  # Return the dataframe
  return(df)
}


```


### Unnecessary Model normalization for each class(depricated for now, might come back later to it)

```{r}

#building the model for Unnecessary
set.seed(42)
category <- 'Unnecessary'
df_nonmerged_factor_unn <- df_nonmerged[df_nonmerged$manual_analysis == category, ]

df_nonmerged_factor_unn <- preprocess_data_norm(df_nonmerged_factor_unn)

unique_repo_ids <- unique(df_nonmerged_factor_unn$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_unn <- df_merged[df_merged$repo_id %in% unique_repo_ids, ]
df_merged_factored_unn <- preprocess_data_norm(df_merged_factored_unn)

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
df_merged_factored_unn <- df_merged_factored_unn[, !colnames(df_merged_factored_unn) %in% "checked"]




formula <- status ~  comments_counts + commit_counts + code_changes_counts  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)



sample_size <- nrow(df_nonmerged_factor_unn)

indices <- sample(1:nrow(df_merged_factored_unn), size = sample_size, replace = TRUE)
sample <- df_merged_factored_unn[indices, ]

combined_data_unn <- rbind(df_nonmerged_factor_unn, sample)

model_unn <- glmer(formula, data = combined_data_unn, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```

```{r}
model_summary_unn <- summary(model_unn)
fixed_effects_unn <- fixef(model_unn)
odds_ratios_unn <- exp(fixed_effects_unn)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print(model_summary_unn, correlation=TRUE)
print(odds_ratios_unn)
car::vif(model_unn)


```

```{r}
#doing this after doing other things
df_nonmerged_factor <- preprocess_data_norm_test(df_nonmerged)

```

### Unnecessary
```{r}

#building the model for Unnecessary
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Unnecessary'
df_nonmerged_factor_unn <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_unn <- preprocess_data(df_nonmerged_factor_unn)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_unn <- df_nonmerged_factor_unn[, !colnames(df_nonmerged_factor_unn) %in% "manual_analysis"]
#df_merged_factored_unn <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]

unique_repo_ids <- unique(df_nonmerged_factor_unn$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
#df_merged_factored_unn <- df_merged_factored_unn[df_merged_factored_unn$repo_id %in% unique_repo_ids, ]
df_merged_factored_unn <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

 
#comments_counts + 
sample_size <- nrow(df_nonmerged_factor_unn)

indices <- sample(1:nrow(df_merged_factored_unn), size = sample_size, replace = TRUE)
sample <- df_merged_factored_unn[indices, ]

combined_data_unn <- rbind(df_nonmerged_factor_unn, sample)

model_unn <- glmer(formula, data = combined_data_unn, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_unn)
```
```{r}
model_summary_unn <- summary(model_unn)
fixed_effects_unn <- fixef(model_unn)
odds_ratios_unn <- exp(fixed_effects_unn)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_unn, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_unn)
```
```{r}
#getting the summary as a dataframe
model_unn_df <- create_model_summary_df(model_unn)
write.csv(model_unn_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_unn_df.csv", row.names = FALSE)


```

### Quality Model
```{r}
#building the model for Quality
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Quality'
df_nonmerged_factor_qua <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_qua <- preprocess_data(df_nonmerged_factor_qua)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_qua <- df_nonmerged_factor_qua[, !colnames(df_nonmerged_factor_qua) %in% "manual_analysis"]
#df_merged_factored_qua <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_qua$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_qua <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


sample_size <- nrow(df_nonmerged_factor_qua)

indices <- sample(1:nrow(df_merged_factored_qua), size = sample_size, replace = TRUE)
sample <- df_merged_factored_qua[indices, ]

combined_data_qua <- rbind(df_nonmerged_factor_qua, sample)

model_qua <- glmer(formula, data = combined_data_qua, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_qua)
```



```{r}
model_summary_qua <- summary(model_qua)
fixed_effects_qua <- fixef(model_qua)
odds_ratios_qua <- exp(fixed_effects_qua)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_qua, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_qua)
```
```{r}
#getting the summary as a dataframe
model_qua_df <- create_model_summary_df(model_qua)
write.csv(model_qua_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_qua_df.csv", row.names = FALSE)


```


### Resolved Model

```{r}

#building the model for Resolved
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Resolved'
df_nonmerged_factor_res <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_res <- preprocess_data(df_nonmerged_factor_res)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_res <- df_nonmerged_factor_res[, !colnames(df_nonmerged_factor_res) %in% "manual_analysis"]
#df_merged_factored_res <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_res$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_res <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

sample_size <- nrow(df_nonmerged_factor_res)

indices <- sample(1:nrow(df_merged_factored_res), size = sample_size, replace = TRUE)
sample <- df_merged_factored_res[indices, ]

combined_data_res <- rbind(df_nonmerged_factor_res, sample)

model_res <- glmer(formula, data = combined_data_res, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_res)
```
```{r}
model_summary_res <- summary(model_res)
fixed_effects_res <- fixef(model_res)
odds_ratios_res <- exp(fixed_effects_res)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_res, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_res)
```

```{r}
#getting the summary as a dataframe
model_res_df <- create_model_summary_df(model_res)
write.csv(model_res_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_res_df.csv", row.names = FALSE)


```
### Replaced

```{r}

#building the model for Replaced
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Replaced'
df_nonmerged_factor_rep <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_rep <- preprocess_data(df_nonmerged_factor_rep)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_rep <- df_nonmerged_factor_rep[, !colnames(df_nonmerged_factor_rep) %in% "manual_analysis"]
#df_merged_factored_rep <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_rep$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_rep <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


sample_size <- nrow(df_nonmerged_factor_rep)

indices <- sample(1:nrow(df_merged_factored_rep), size = sample_size, replace = TRUE)
sample <- df_merged_factored_rep[indices, ]

combined_data_rep <- rbind(df_nonmerged_factor_rep, sample)

model_rep <- glmer(formula, data = combined_data_rep, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featurep have more than 3 in VIF
print('VIF:')
car::vif(model_rep) 
```


```{r}
model_summary_rep <- summary(model_rep)
fixed_effects_rep <- fixef(model_rep)
odds_ratios_rep <- exp(fixed_effects_rep)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_rep, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_rep)
```
```{r}
#getting the summary as a dataframe
model_rep_df <- create_model_summary_df(model_rep)
write.csv(model_rep_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_rep_df.csv", row.names = FALSE)


```
### Duplicate
```{r}

#building the model for Duplicate
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Duplicate'
df_nonmerged_factor_dup <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_dup <- preprocess_data(df_nonmerged_factor_dup)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_dup <- df_nonmerged_factor_dup[, !colnames(df_nonmerged_factor_dup) %in% "manual_analysis"]
#df_merged_factored_dup <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_dup$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_dup <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


sample_size <- nrow(df_nonmerged_factor_dup)

indices <- sample(1:nrow(df_merged_factored_dup), size = sample_size, replace = TRUE)
sample <- df_merged_factored_dup[indices, ]

combined_data_dup <- rbind(df_nonmerged_factor_dup, sample)

model_dup <- glmer(formula, data = combined_data_dup, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_dup)
```
```{r}
#formula <- status ~  comments_counts + commit_counts + code_changes_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

#model_dup <- glmer(formula, data = combined_data_dup, family = binomial,
                 #   control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```


```{r}
model_summary_dup <- summary(model_dup)
fixed_effects_dup <- fixef(model_dup)
odds_ratios_dup <- exp(fixed_effects_dup)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_dup, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_dup)
```
```{r}
#getting the summary as a dataframe
model_dup_df <- create_model_summary_df(model_dup)
write.csv(model_dup_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_dup_df.csv", row.names = FALSE)


```
### Merge Conflict
```{r}

#building the model for Merge Conflict
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Merge Conflict'
df_nonmerged_factor_mc <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_mc <- preprocess_data(df_nonmerged_factor_mc)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_mc <- df_nonmerged_factor_mc[, !colnames(df_nonmerged_factor_mc) %in% "manual_analysis"]
#df_merged_factored_mc <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_mc$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_mc <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

sample_size <- nrow(df_nonmerged_factor_mc)

indices <- sample(1:nrow(df_merged_factored_mc), size = sample_size, replace = TRUE)
sample <- df_merged_factored_mc[indices, ]

combined_data_mc <- rbind(df_nonmerged_factor_mc, sample)

model_mc <- glmer(formula, data = combined_data_mc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what features have more than 3 in VIF
print('VIF:')
car::vif(model_mc)
```
```{r}
formula <- status ~  comments_counts + commit_counts +prs_followed_pri + prs_experience +prs_succ_rate +prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member  +repo_pr_tenure_mnth+ perc_external_contribs + pr_files_changed  + intra_branch + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_tenure_mnth + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
model_mc <- glmer(formula, data = combined_data_mc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```


```{r}
model_summary_mc <- summary(model_mc)
fixed_effects_mc <- fixef(model_mc)
odds_ratios_mc <- exp(fixed_effects_mc)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_mc, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_mc)
```
```{r}
#getting the summary as a dataframe
model_mc_df <- create_model_summary_df(model_mc)
write.csv(model_mc_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_mc_df.csv", row.names = FALSE)


```
### Stale
```{r}

#building the model for Stale
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Stale'
df_nonmerged_factor_sta <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_sta <- preprocess_data(df_nonmerged_factor_sta)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_sta <- df_nonmerged_factor_sta[, !colnames(df_nonmerged_factor_sta) %in% "manual_analysis"]
#df_merged_factored_sta <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_sta$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_sta <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


sample_size <- nrow(df_nonmerged_factor_sta)

indices <- sample(1:nrow(df_merged_factored_sta), size = sample_size, replace = TRUE)
sample <- df_merged_factored_sta[indices, ]

combined_data_sta <- rbind(df_nonmerged_factor_sta, sample)

model_sta <- glmer(formula, data = combined_data_sta, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_sta)
```

```{r}
formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate +prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_sta <- glmer(formula, data = combined_data_sta, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```

```{r}
model_summary_sta <- summary(model_sta)
fixed_effects_sta <- fixef(model_sta)
odds_ratios_sta <- exp(fixed_effects_sta)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_sta, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_sta)
```
```{r}
#getting the summary as a dataframe
model_sta_df <- create_model_summary_df(model_sta)
write.csv(model_sta_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_sta_df.csv", row.names = FALSE)


```
### No Comment
```{r}
#building the model for No Comment
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'No Comment'
df_nonmerged_factor_nc <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_nc <- preprocess_data(df_nonmerged_factor_nc)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_nc <- df_nonmerged_factor_nc[, !colnames(df_nonmerged_factor_nc) %in% "manual_analysis"]
#df_merged_factored_nc <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_nc$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_nc <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)#formula <- status ~ commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


sample_size <- nrow(df_nonmerged_factor_nc)

indices <- sample(1:nrow(df_merged_factored_nc), size = sample_size, replace = TRUE)
sample <- df_merged_factored_nc[indices, ]

combined_data_nc <- rbind(df_nonmerged_factor_nc, sample)

model_nc <- glmer(formula, data = combined_data_nc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_nc)
```
```{r}
model_summary_nc <- summary(model_nc)
fixed_effects_nc <- fixef(model_nc)
odds_ratios_nc <- exp(fixed_effects_nc)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_nc, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_nc)
```

```{r}
#getting the summary as a dataframe
model_nc_df <- create_model_summary_df(model_nc)
write.csv(model_nc_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_nc_df.csv", row.names = FALSE)


```
### No Reason
```{r}

#building the model for No Reason
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'No Reason'
df_nonmerged_factor_nr <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_nr <- preprocess_data(df_nonmerged_factor_nr)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_nr <- df_nonmerged_factor_nr[, !colnames(df_nonmerged_factor_nr) %in% "manual_analysis"]
#df_merged_factored_nr <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]


unique_repo_ids <- unique(df_nonmerged_factor_nr$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_nr <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


sample_size <- nrow(df_nonmerged_factor_nr)

indices <- sample(1:nrow(df_merged_factored_nr), size = sample_size, replace = TRUE)
sample <- df_merged_factored_nr[indices, ]

combined_data_nr <- rbind(df_nonmerged_factor_nr, sample)

model_nr <- glmer(formula, data = combined_data_nr, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_nr)
```
```{r}

formula <- status ~  comments_counts + commit_counts + prs_followed_pri  + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth  + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)
#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member  + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_nr <- glmer(formula, data = combined_data_nr, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```

```{r}
model_summary_nr <- summary(model_nr)
fixed_effects_nr <- fixef(model_nr)
odds_ratios_nr <- exp(fixed_effects_nr)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_nr, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_nr)
```
```{r}
#getting the summary as a dataframe
model_nr_df <- create_model_summary_df(model_nr)
write.csv(model_nr_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_nr_df.csv", row.names = FALSE)


```
### Successful
```{r}

#building the model for Successful
set.seed(46)
#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

category <- 'Successful'
df_nonmerged_factor_suc <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis == category, ]

#df_nonmerged_factor_suc <- preprocess_data(df_nonmerged_factor_suc)

#df_merged_factored <- preprocess_data_norm(df_merged)

df_nonmerged_factor_suc <- df_nonmerged_factor_suc[, !colnames(df_nonmerged_factor_suc) %in% "manual_analysis"]
#df_merged_factored_suc <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]

 
unique_repo_ids <- unique(df_nonmerged_factor_suc$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored_suc <- sample_merged_data_15k[sample_merged_data_15k$repo_id %in% unique_repo_ids, ]


formula <- status ~ comments_counts + commit_counts + prs_experience + prs_popularity + prs_followed_pri + prs_succ_rate + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)#formula <- status ~ comments_counts + commit_counts  + prs_popularity + prs_followed_pri + prs_watched_repo + prs_main_team_member + repo_pr_popularity + repo_pr_team_size + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)


sample_size <- nrow(df_nonmerged_factor_suc)

indices <- sample(1:nrow(df_merged_factored_suc), size = sample_size, replace = TRUE)
sample <- df_merged_factored_suc[indices, ]

combined_data_suc <- rbind(df_nonmerged_factor_suc, sample)

model_suc <- glmer(formula, data = combined_data_suc, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#See what featuers have more than 3 in VIF
print('VIF:')
car::vif(model_suc)
```
```{r}
model_summary_suc <- summary(model_suc)
fixed_effects_suc <- fixef(model_suc)
odds_ratios_suc <- exp(fixed_effects_suc)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary_suc, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios_suc)
```
```{r}
#getting the summary as a dataframe
model_suc_df <- create_model_summary_df(model_suc)
write.csv(model_suc_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_suc_df.csv", row.names = FALSE)


```
# Building the model for labeled dataset


```{r}
hist(df_nonmerged_factor$comments_counts, main = "Distribution of Comments Counts", xlab = "Comments Counts", col = "lightblue", border = "black")


```

```{r}
df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

df_merged_factored <- preprocess_data_norm(df_merged)

```

```{r}
set.seed(46)

#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

#df_merged_factored <- preprocess_data_norm(df_merged)
#df_nonmerged_factor <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis != 'Successful', ]

df_nonmerged_factor <- df_nonmerged_factor[, !colnames(df_nonmerged_factor) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



unique_repo_ids_sampled <- unique(df_nonmerged_factor$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids_sampled, ]


sample_size <- nrow(df_nonmerged_factor)

indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
sample_merged_data_15k <- df_merged_factored[indices, ]

combined_data <- rbind(df_nonmerged_factor, sample_merged_data_15k)


formula <- status ~  comments_counts + commit_counts + prs_experience + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + prs_succ_rate + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + prs_followed_pri + perc_external_contribs + intra_branch +pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_labeled <- glmer(formula, data = combined_data, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```
```{r}
#model withough normalizing

set.seed(46)

#df_nonmerged_factor <- preprocess_data_norm(df_nonmerged)

#df_merged_factored <- preprocess_data_norm(df_merged)
#df_nonmerged_factor <- df_nonmerged_factor[df_nonmerged_factor$manual_analysis != 'Successful', ]

df_nonmerged_factor <- df_nonmerged_factor[, !colnames(df_nonmerged_factor) %in% "manual_analysis"]
df_merged_factored <- df_merged_factored[, !colnames(df_merged_factored) %in% "checked"]



unique_repo_ids_sampled <- unique(df_nonmerged_factor$repo_id)

# Filtering the merged pull requests to keep only those with repo_ids in unique_repo_ids
df_merged_factored <- df_merged_factored[df_merged_factored$repo_id %in% unique_repo_ids_sampled, ]


sample_size <- nrow(df_nonmerged_factor)

indices <- sample(1:nrow(df_merged_factored), size = sample_size, replace = TRUE)
sample_merged_data_15k <- df_merged_factored[indices, ]

combined_data <- rbind(df_nonmerged_factor, sample_merged_data_15k)


formula <- status ~  comments_counts + commit_counts + prs_experience + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + prs_succ_rate + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + prs_followed_pri + perc_external_contribs + intra_branch +pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

model_labeled <- glmer(formula, data = combined_data, family = binomial,
                    control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```



```{r}
model_summary <- summary(model_labeled)
fixed_effects <- fixef(model_labeled)
odds_ratios <- exp(fixed_effects)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios)
print('VIF:')
car::vif(model_labeled)

```
```{r}
#getting the summary as a dataframe
model_labeled_df <- create_model_summary_df(model_labeled)
write.csv(model_labeled_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_labeled_df.csv", row.names = FALSE)


```

```{r}
write.csv(df_comp_factored, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Normalized_data/all_data.csv", row.names = FALSE)
write.csv(combined_data, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Normalized_data/sampled_data.csv", row.names = FALSE)

```
### Building model of all_data only with repos in non_merged


```{r}
df_comp_factored <- preprocess_data_norm(df_comp)

```

```{r}
df_comp_factored_filtered<- df_comp_factored[df_comp_factored$repo_id %in% unique_repo_ids_sampled, ]
formula <- status ~  comments_counts + commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + prs_followed_pri + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

#model_alldata <- glmer(formula, data = df_comp_factored_filtered, family = binomial, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))

```


### Sampling the all data 
```{r}
set.seed(46)

# Assuming df_comp_factored has a column 'merged' to distinguish between merged and non-merged PRs
df_nonmerged_alldata_factor <- df_comp_factored[df_comp_factored$status == 'not-merged', ]
df_merged_alldata_factored <- df_comp_factored[df_comp_factored$status == 'merged', ]


# Get unique repo_ids from non-merged PRs
unique_repo_ids <- unique(df_nonmerged_alldata_factor$repo_id)

# Filter merged PRs for those repos
df_merged_alldata_factored <- df_merged_alldata_factored[df_merged_alldata_factored$repo_id %in% unique_repo_ids, ]

# Define your model formula
formula <- status ~  comments_counts + commit_counts + code_changes_counts + prs_experience + prs_succ_rate + prs_popularity + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + prs_followed_pri + repo_pr_popularity + repo_pr_team_size + perc_external_contribs + intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)

# Determine the sample size (number of non-merged PRs)
sample_size <- nrow(df_nonmerged_alldata_factor)

# Randomly sample merged PRs to match the count of non-merged PRs
indices <- sample(1:nrow(df_merged_alldata_factored), size = sample_size, replace = FALSE)
sampled_merged <- df_merged_alldata_factored[indices, ]

# Combine the datasets
combined_data_alldata <- rbind(df_nonmerged_alldata_factor, sampled_merged)

# Fit the model
model_alldata <- glmer(formula, data = combined_data_alldata, family = binomial, control = glmerControl(optimizer = "nloptwrap", calc.derivs = FALSE, optCtrl = list(maxeval = 50)))


```


```{r}
model_summary <- summary(model_alldata)
fixed_effects <- fixef(model_alldata)
odds_ratios <- exp(fixed_effects)
#conf_intervals <- confint(bootstrapped_models[[i]], which = "fixed")
print('The model summary and correlation:')
print(model_summary, correlation=TRUE)
print('Odds Ratio:')
print(odds_ratios)
print('VIF:')
car::vif(model_alldata)
```

```{r}
model_alldata_df <- create_model_summary_df(model_alldata)
write.csv(model_alldata_df, "/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Paper_1/Results/Model_summary/model_alldata_df.csv", row.names = FALSE)
```

# Comparing the models

```{r}
extract_model_metrics <- function(fitted_model) {
  
  # Extract fixed effects from model summary
  fixed_effects <- summary(fitted_model)$coefficients
  
  # Extract required metrics: Estimate, Std. Error, and p-value
  coeff_data <- fixed_effects[, c("Estimate", "Std. Error", "Pr(>|z|)")]
  
  return(coeff_data)
}



```

