{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to make a xgboost classification of out 56000 pull request which 10k are non-merged and 46k are merged. we want to do two stage classification and prediction, first stage is for non merged and merged, and then we want to predict and classifiy each category after that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v7/m50ww3p142130jtt2scggl3r0000gq/T/ipykernel_80675/552830788.py:7: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import ast\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/sampled_dataset.csv')\n",
    "df_nonmerged = pd.read_csv('/Users/amirrshams/Library/CloudStorage/OneDrive-UniversityofWaterloo/Thesis/Dataset/Dataset/Non_Merged/Sample/Sample_10000_new_manual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>status</th>\n",
       "      <th>pr_id</th>\n",
       "      <th>pullreq_id</th>\n",
       "      <th>api_url</th>\n",
       "      <th>url</th>\n",
       "      <th>pr_url</th>\n",
       "      <th>pr_api_url</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_desc_body</th>\n",
       "      <th>closer_id</th>\n",
       "      <th>comments_counts</th>\n",
       "      <th>comments</th>\n",
       "      <th>commit_counts</th>\n",
       "      <th>code_changes_counts</th>\n",
       "      <th>created_at</th>\n",
       "      <th>closed_at</th>\n",
       "      <th>author_country</th>\n",
       "      <th>closer_country</th>\n",
       "      <th>author_continent</th>\n",
       "      <th>same_country</th>\n",
       "      <th>author_eth</th>\n",
       "      <th>closer_eth</th>\n",
       "      <th>same_eth</th>\n",
       "      <th>prs_white</th>\n",
       "      <th>prs_api</th>\n",
       "      <th>prs_black</th>\n",
       "      <th>prs_hispanic</th>\n",
       "      <th>pri_white</th>\n",
       "      <th>pri_black</th>\n",
       "      <th>pri_api</th>\n",
       "      <th>pri_hispanic</th>\n",
       "      <th>prs_eth_8</th>\n",
       "      <th>prs_eth_7</th>\n",
       "      <th>prs_eth_9</th>\n",
       "      <th>prs_eth_diff</th>\n",
       "      <th>prs_eth_diff_2</th>\n",
       "      <th>prs_pri_same_nationality</th>\n",
       "      <th>prs_experience</th>\n",
       "      <th>prs_succ_rate</th>\n",
       "      <th>prs_popularity</th>\n",
       "      <th>prs_watched_repo</th>\n",
       "      <th>prs_followed_pri</th>\n",
       "      <th>prs_tenure_mnth</th>\n",
       "      <th>prs_main_team_member</th>\n",
       "      <th>repo_pr_tenure_mnth</th>\n",
       "      <th>repo_pr_popularity</th>\n",
       "      <th>repo_pr_team_size</th>\n",
       "      <th>perc_external_contribs</th>\n",
       "      <th>pr_opened_at</th>\n",
       "      <th>pr_files_changed</th>\n",
       "      <th>pr_lines_changed</th>\n",
       "      <th>intra_branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2250</td>\n",
       "      <td>6</td>\n",
       "      <td>not-merged</td>\n",
       "      <td>2697422</td>\n",
       "      <td>4651</td>\n",
       "      <td>https://api.github.com/repos/cocos2d/cocos2d-x</td>\n",
       "      <td>https://github.com/cocos2d/cocos2d-x</td>\n",
       "      <td>https://github.com/cocos2d/cocos2d-x/pull/4651</td>\n",
       "      <td>https://api.github.com/repos/cocos2d/cocos2d-x/pulls/4651</td>\n",
       "      <td>CocosRobot</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.623582</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.500975</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-12-25 04:04:41</td>\n",
       "      <td>2013-12-25 05:41:54</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>API</td>\n",
       "      <td>0</td>\n",
       "      <td>0.889200</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.059421</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.933594</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>1.915057</td>\n",
       "      <td>1.150350</td>\n",
       "      <td>-0.444593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.077583</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224940</td>\n",
       "      <td>1.028133</td>\n",
       "      <td>0.992756</td>\n",
       "      <td>-0.699726</td>\n",
       "      <td>1387940681</td>\n",
       "      <td>-1.047192</td>\n",
       "      <td>-1.251865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5916</td>\n",
       "      <td>6</td>\n",
       "      <td>not-merged</td>\n",
       "      <td>7456135</td>\n",
       "      <td>11761</td>\n",
       "      <td>https://api.github.com/repos/cocos2d/cocos2d-x</td>\n",
       "      <td>https://github.com/cocos2d/cocos2d-x</td>\n",
       "      <td>https://github.com/cocos2d/cocos2d-x/pull/11761</td>\n",
       "      <td>https://api.github.com/repos/cocos2d/cocos2d-x/pulls/11761</td>\n",
       "      <td>CocosRobot</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.623582</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.500975</td>\n",
       "      <td>9</td>\n",
       "      <td>2015-05-08 09:07:16</td>\n",
       "      <td>2015-05-11 01:53:15</td>\n",
       "      <td>\\N</td>\n",
       "      <td>china</td>\n",
       "      <td>\\N</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0.889200</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.088110</td>\n",
       "      <td>0.014689</td>\n",
       "      <td>0.569895</td>\n",
       "      <td>0.032570</td>\n",
       "      <td>0.367695</td>\n",
       "      <td>0.028239</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>2.676846</td>\n",
       "      <td>0.764089</td>\n",
       "      <td>-0.161012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.488885</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608178</td>\n",
       "      <td>1.292924</td>\n",
       "      <td>1.375811</td>\n",
       "      <td>-0.232106</td>\n",
       "      <td>1431068836</td>\n",
       "      <td>-1.047192</td>\n",
       "      <td>-1.251865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>17935</td>\n",
       "      <td>183</td>\n",
       "      <td>not-merged</td>\n",
       "      <td>645270</td>\n",
       "      <td>2808</td>\n",
       "      <td>https://api.github.com/repos/zendframework/zendframework</td>\n",
       "      <td>https://github.com/zendframework/zendframework</td>\n",
       "      <td>https://github.com/zendframework/zendframework/pull/2808</td>\n",
       "      <td>https://api.github.com/repos/zendframework/zendframework/pulls/2808</td>\n",
       "      <td>blanchonvincent</td>\n",
       "      <td>Usage with static instead of self\\n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.623582</td>\n",
       "      <td>[]</td>\n",
       "      <td>-0.500975</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-19 19:34:23</td>\n",
       "      <td>2012-10-30 19:46:43</td>\n",
       "      <td>france</td>\n",
       "      <td>united states</td>\n",
       "      <td>Europe</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982306</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.930962</td>\n",
       "      <td>0.031869</td>\n",
       "      <td>0.009878</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0.995788</td>\n",
       "      <td>1.083482</td>\n",
       "      <td>0.968358</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.253013</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.069841</td>\n",
       "      <td>1.172173</td>\n",
       "      <td>0.886383</td>\n",
       "      <td>0.179764</td>\n",
       "      <td>1350668063</td>\n",
       "      <td>-1.047192</td>\n",
       "      <td>-1.251865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>19620</td>\n",
       "      <td>183</td>\n",
       "      <td>not-merged</td>\n",
       "      <td>2203867</td>\n",
       "      <td>5219</td>\n",
       "      <td>https://api.github.com/repos/zendframework/zendframework</td>\n",
       "      <td>https://github.com/zendframework/zendframework</td>\n",
       "      <td>https://github.com/zendframework/zendframework/pull/5219</td>\n",
       "      <td>https://api.github.com/repos/zendframework/zendframework/pulls/5219</td>\n",
       "      <td>samsonasik</td>\n",
       "      <td>\\N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.182242</td>\n",
       "      <td>['Woah, ancient links spotting :O\\n', '@Ocramius  I just realize that the old link still valid :D , should I close it ? \\n', \"It's a mirror of ZF2 hosted in Zend Technologies. It's deliberate use that URI in the file.\\n\"]</td>\n",
       "      <td>-0.500975</td>\n",
       "      <td>1</td>\n",
       "      <td>2013-10-03 19:34:04</td>\n",
       "      <td>2013-10-03 19:48:05</td>\n",
       "      <td>indonesia</td>\n",
       "      <td>spain</td>\n",
       "      <td>Asia</td>\n",
       "      <td>0</td>\n",
       "      <td>API</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024666</td>\n",
       "      <td>0.975110</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.996368</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>API</td>\n",
       "      <td>API</td>\n",
       "      <td>API</td>\n",
       "      <td>API</td>\n",
       "      <td>API</td>\n",
       "      <td>0</td>\n",
       "      <td>1.759672</td>\n",
       "      <td>0.880055</td>\n",
       "      <td>1.906032</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.279995</td>\n",
       "      <td>0</td>\n",
       "      <td>0.280881</td>\n",
       "      <td>1.227766</td>\n",
       "      <td>1.307105</td>\n",
       "      <td>0.144283</td>\n",
       "      <td>1380821644</td>\n",
       "      <td>-1.047192</td>\n",
       "      <td>-1.251865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>27952</td>\n",
       "      <td>340</td>\n",
       "      <td>not-merged</td>\n",
       "      <td>23622497</td>\n",
       "      <td>6647</td>\n",
       "      <td>https://api.github.com/repos/netty/netty</td>\n",
       "      <td>https://github.com/netty/netty</td>\n",
       "      <td>https://github.com/netty/netty/pull/6647</td>\n",
       "      <td>https://api.github.com/repos/netty/netty/pulls/6647</td>\n",
       "      <td>fenik17</td>\n",
       "      <td>Motivation:\\r\\n\\r\\n1. The use of the `InternetProtocolFamily` is not consistent:\\r\\n   the `DnsNameResolverContext` and `DnsNameResolver` contains switches\\r\\n   instead of appropriate methods usage.\\r\\n2. The `InternetProtocolFamily` class contains redundant switches in the\\r\\n   constructor.\\r\\n\\r\\nModifications:\\r\\n\\r\\n1. Replacing switches to the use of an appropriate methods.\\r\\n2. Simplifying the `InternetProtocolFamily` constructor.\\r\\n\\r\\nResult:\\r\\n\\r\\nCode is cleaner and simpler.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.720670</td>\n",
       "      <td>['Cherry-picked into 4.1 (970d310ec9ae3d0581adf48eec815d54e93b4960).\\r\\n\\r\\n@fenik17 thanks!']</td>\n",
       "      <td>-0.500975</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-04-19 18:56:34</td>\n",
       "      <td>2017-04-20 03:23:50</td>\n",
       "      <td>russia</td>\n",
       "      <td>germany</td>\n",
       "      <td>Asia</td>\n",
       "      <td>0</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990941</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.008697</td>\n",
       "      <td>0.992539</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0.105514</td>\n",
       "      <td>-1.103914</td>\n",
       "      <td>-0.997446</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.017751</td>\n",
       "      <td>0</td>\n",
       "      <td>1.009221</td>\n",
       "      <td>1.516362</td>\n",
       "      <td>1.220494</td>\n",
       "      <td>-0.886764</td>\n",
       "      <td>1492628194</td>\n",
       "      <td>-1.047192</td>\n",
       "      <td>-1.251865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  repo_id      status     pr_id  pullreq_id  \\\n",
       "0  1             2250        6        not-merged  2697422   4651         \n",
       "1  2             5916        6        not-merged  7456135   11761        \n",
       "2  3             17935       183      not-merged  645270    2808         \n",
       "3  4             19620       183      not-merged  2203867   5219         \n",
       "4  5             27952       340      not-merged  23622497  6647         \n",
       "\n",
       "                                                    api_url  \\\n",
       "0  https://api.github.com/repos/cocos2d/cocos2d-x             \n",
       "1  https://api.github.com/repos/cocos2d/cocos2d-x             \n",
       "2  https://api.github.com/repos/zendframework/zendframework   \n",
       "3  https://api.github.com/repos/zendframework/zendframework   \n",
       "4  https://api.github.com/repos/netty/netty                   \n",
       "\n",
       "                                              url  \\\n",
       "0  https://github.com/cocos2d/cocos2d-x             \n",
       "1  https://github.com/cocos2d/cocos2d-x             \n",
       "2  https://github.com/zendframework/zendframework   \n",
       "3  https://github.com/zendframework/zendframework   \n",
       "4  https://github.com/netty/netty                   \n",
       "\n",
       "                                                     pr_url  \\\n",
       "0  https://github.com/cocos2d/cocos2d-x/pull/4651             \n",
       "1  https://github.com/cocos2d/cocos2d-x/pull/11761            \n",
       "2  https://github.com/zendframework/zendframework/pull/2808   \n",
       "3  https://github.com/zendframework/zendframework/pull/5219   \n",
       "4  https://github.com/netty/netty/pull/6647                   \n",
       "\n",
       "                                                            pr_api_url  \\\n",
       "0  https://api.github.com/repos/cocos2d/cocos2d-x/pulls/4651             \n",
       "1  https://api.github.com/repos/cocos2d/cocos2d-x/pulls/11761            \n",
       "2  https://api.github.com/repos/zendframework/zendframework/pulls/2808   \n",
       "3  https://api.github.com/repos/zendframework/zendframework/pulls/5219   \n",
       "4  https://api.github.com/repos/netty/netty/pulls/6647                   \n",
       "\n",
       "         author_id  \\\n",
       "0  CocosRobot        \n",
       "1  CocosRobot        \n",
       "2  blanchonvincent   \n",
       "3  samsonasik        \n",
       "4  fenik17           \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 author_desc_body  \\\n",
       "0  \\N                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "1  \\N                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "2  Usage with static instead of self\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "3  \\N                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \n",
       "4  Motivation:\\r\\n\\r\\n1. The use of the `InternetProtocolFamily` is not consistent:\\r\\n   the `DnsNameResolverContext` and `DnsNameResolver` contains switches\\r\\n   instead of appropriate methods usage.\\r\\n2. The `InternetProtocolFamily` class contains redundant switches in the\\r\\n   constructor.\\r\\n\\r\\nModifications:\\r\\n\\r\\n1. Replacing switches to the use of an appropriate methods.\\r\\n2. Simplifying the `InternetProtocolFamily` constructor.\\r\\n\\r\\nResult:\\r\\n\\r\\nCode is cleaner and simpler.   \n",
       "\n",
       "  closer_id  comments_counts  \\\n",
       "0  NaN      -1.623582          \n",
       "1  NaN      -1.623582          \n",
       "2  NaN      -1.623582          \n",
       "3  NaN       0.182242          \n",
       "4  NaN      -0.720670          \n",
       "\n",
       "                                                                                                                                                                                                                        comments  \\\n",
       "0  []                                                                                                                                                                                                                              \n",
       "1  []                                                                                                                                                                                                                              \n",
       "2  []                                                                                                                                                                                                                              \n",
       "3  ['Woah, ancient links spotting :O\\n', '@Ocramius  I just realize that the old link still valid :D , should I close it ? \\n', \"It's a mirror of ZF2 hosted in Zend Technologies. It's deliberate use that URI in the file.\\n\"]   \n",
       "4  ['Cherry-picked into 4.1 (970d310ec9ae3d0581adf48eec815d54e93b4960).\\r\\n\\r\\n@fenik17 thanks!']                                                                                                                                  \n",
       "\n",
       "   commit_counts  code_changes_counts           created_at  \\\n",
       "0 -0.500975       1                    2013-12-25 04:04:41   \n",
       "1 -0.500975       9                    2015-05-08 09:07:16   \n",
       "2 -0.500975       1                    2012-10-19 19:34:23   \n",
       "3 -0.500975       1                    2013-10-03 19:34:04   \n",
       "4 -0.500975       3                    2017-04-19 18:56:34   \n",
       "\n",
       "             closed_at author_country closer_country author_continent  \\\n",
       "0  2013-12-25 05:41:54  \\N             \\N             \\N                \n",
       "1  2015-05-11 01:53:15  \\N             china          \\N                \n",
       "2  2012-10-30 19:46:43  france         united states  Europe            \n",
       "3  2013-10-03 19:48:05  indonesia      spain          Asia              \n",
       "4  2017-04-20 03:23:50  russia         germany        Asia              \n",
       "\n",
       "  same_country author_eth closer_eth  same_eth  prs_white   prs_api  \\\n",
       "0  0            Unknown    API        0         0.889200   0.008001   \n",
       "1  0            Unknown    Unknown    0         0.889200   0.008001   \n",
       "2  0            White      White      1         0.982306   0.003467   \n",
       "3  0            API        White      0         0.024666   0.975110   \n",
       "4  0            White      White      1         0.990941   0.000334   \n",
       "\n",
       "   prs_black  prs_hispanic  pri_white  pri_black   pri_api  pri_hispanic  \\\n",
       "0  0.088110   0.014689      0.059421   0.003402   0.933594  0.001673       \n",
       "1  0.088110   0.014689      0.569895   0.032570   0.367695  0.028239       \n",
       "2  0.010741   0.002705      0.930962   0.031869   0.009878  0.025256       \n",
       "3  0.000109   0.000099      0.996368   0.002142   0.000852  0.000634       \n",
       "4  0.000025   0.008697      0.992539   0.000581   0.003632  0.002701       \n",
       "\n",
       "  prs_eth_8 prs_eth_7 prs_eth_9 prs_eth_diff prs_eth_diff_2  \\\n",
       "0  Unknown   White     Unknown   White        White           \n",
       "1  Unknown   White     Unknown   White        White           \n",
       "2  White     White     White     White        White           \n",
       "3  API       API       API       API          API             \n",
       "4  White     White     White     White        White           \n",
       "\n",
       "  prs_pri_same_nationality  prs_experience  prs_succ_rate  prs_popularity  \\\n",
       "0  0                        1.915057        1.150350      -0.444593         \n",
       "1  0                        2.676846        0.764089      -0.161012         \n",
       "2  0                        0.995788        1.083482       0.968358         \n",
       "3  0                        1.759672        0.880055       1.906032         \n",
       "4  0                        0.105514       -1.103914      -0.997446         \n",
       "\n",
       "   prs_watched_repo  prs_followed_pri  prs_tenure_mnth  prs_main_team_member  \\\n",
       "0  0                 0                 0.077583         0                      \n",
       "1  0                 0                 0.488885         0                      \n",
       "2  1                 0                -1.253013         0                      \n",
       "3  1                 1                 0.279995         0                      \n",
       "4  1                 1                -1.017751         0                      \n",
       "\n",
       "   repo_pr_tenure_mnth  repo_pr_popularity  repo_pr_team_size  \\\n",
       "0  0.224940             1.028133            0.992756            \n",
       "1  0.608178             1.292924            1.375811            \n",
       "2 -0.069841             1.172173            0.886383            \n",
       "3  0.280881             1.227766            1.307105            \n",
       "4  1.009221             1.516362            1.220494            \n",
       "\n",
       "   perc_external_contribs  pr_opened_at  pr_files_changed  pr_lines_changed  \\\n",
       "0 -0.699726                1387940681   -1.047192         -1.251865           \n",
       "1 -0.232106                1431068836   -1.047192         -1.251865           \n",
       "2  0.179764                1350668063   -1.047192         -1.251865           \n",
       "3  0.144283                1380821644   -1.047192         -1.251865           \n",
       "4 -0.886764                1492628194   -1.047192         -1.251865           \n",
       "\n",
       "   intra_branch  \n",
       "0  0             \n",
       "1  0             \n",
       "2  0             \n",
       "3  0             \n",
       "4  0             "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocessing\n",
    "only keep the values that are important to us and are used in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the two datasets and only add the manual analysis column\n",
    "df = pd.concat([df, df_nonmerged['manual_analysis']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all columns except for commit_counts + prs_experience + prs_succ_rate + prs_popularity + prs_followed_pri + prs_watched_repo + prs_tenure_mnth + prs_main_team_member + repo_pr_tenure_mnth + repo_pr_popularity + repo_pr_team_size + perc_external_contribs +intra_branch + pr_files_changed + pr_lines_changed + (1 | repo_id) + (1 | author_id)\n",
    "df = df[['pr_id', 'commit_counts', 'prs_experience', 'prs_succ_rate', 'prs_popularity', 'prs_followed_pri', 'prs_watched_repo', 'prs_tenure_mnth', 'prs_main_team_member', 'repo_pr_tenure_mnth', 'repo_pr_popularity', 'repo_pr_team_size', 'perc_external_contribs', 'intra_branch', 'pr_files_changed', 'pr_lines_changed', 'repo_id','status', 'manual_analysis']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_id</th>\n",
       "      <th>commit_counts</th>\n",
       "      <th>prs_experience</th>\n",
       "      <th>prs_succ_rate</th>\n",
       "      <th>prs_popularity</th>\n",
       "      <th>prs_followed_pri</th>\n",
       "      <th>prs_watched_repo</th>\n",
       "      <th>prs_tenure_mnth</th>\n",
       "      <th>prs_main_team_member</th>\n",
       "      <th>repo_pr_tenure_mnth</th>\n",
       "      <th>repo_pr_popularity</th>\n",
       "      <th>repo_pr_team_size</th>\n",
       "      <th>perc_external_contribs</th>\n",
       "      <th>intra_branch</th>\n",
       "      <th>pr_files_changed</th>\n",
       "      <th>pr_lines_changed</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>status</th>\n",
       "      <th>manual_analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11811</th>\n",
       "      <td>83434</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>-1.532904</td>\n",
       "      <td>-1.714328</td>\n",
       "      <td>-1.135762</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.103728</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.734906</td>\n",
       "      <td>-0.827321</td>\n",
       "      <td>-2.470590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488071</td>\n",
       "      <td>-0.857099</td>\n",
       "      <td>4416</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13035</th>\n",
       "      <td>112871</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>-1.532904</td>\n",
       "      <td>-1.714328</td>\n",
       "      <td>-1.555667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.555457</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.734906</td>\n",
       "      <td>-1.938174</td>\n",
       "      <td>-2.470590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.195553</td>\n",
       "      <td>-1.357043</td>\n",
       "      <td>6286</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14055</th>\n",
       "      <td>550093</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>-0.724022</td>\n",
       "      <td>0.790595</td>\n",
       "      <td>0.871954</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.639497</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.734906</td>\n",
       "      <td>-0.712193</td>\n",
       "      <td>-0.572532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.195553</td>\n",
       "      <td>-1.357043</td>\n",
       "      <td>8623</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14486</th>\n",
       "      <td>711063</td>\n",
       "      <td>1.554526</td>\n",
       "      <td>-1.532904</td>\n",
       "      <td>-1.714328</td>\n",
       "      <td>0.631808</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.043169</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.543178</td>\n",
       "      <td>0.317436</td>\n",
       "      <td>-0.310316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.219410</td>\n",
       "      <td>0.752076</td>\n",
       "      <td>9703</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14657</th>\n",
       "      <td>279617</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>-0.375655</td>\n",
       "      <td>0.726262</td>\n",
       "      <td>0.543858</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.089816</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.734906</td>\n",
       "      <td>-1.027982</td>\n",
       "      <td>-1.323155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488071</td>\n",
       "      <td>-0.226240</td>\n",
       "      <td>10102</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52719</th>\n",
       "      <td>150397</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>0.380274</td>\n",
       "      <td>0.775170</td>\n",
       "      <td>0.043060</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.701892</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.983010</td>\n",
       "      <td>-1.465002</td>\n",
       "      <td>-2.470590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488071</td>\n",
       "      <td>-0.624638</td>\n",
       "      <td>287583</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52763</th>\n",
       "      <td>196520</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>-1.532904</td>\n",
       "      <td>-1.714328</td>\n",
       "      <td>-1.135762</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-3.555457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121783</td>\n",
       "      <td>-1.234648</td>\n",
       "      <td>-2.470590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488071</td>\n",
       "      <td>-0.357155</td>\n",
       "      <td>44939</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52764</th>\n",
       "      <td>1148556</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>-0.108968</td>\n",
       "      <td>0.881928</td>\n",
       "      <td>0.647964</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132722</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.791282</td>\n",
       "      <td>-0.414212</td>\n",
       "      <td>-2.470590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.488071</td>\n",
       "      <td>-0.067737</td>\n",
       "      <td>404631</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52814</th>\n",
       "      <td>1762565</td>\n",
       "      <td>-0.540434</td>\n",
       "      <td>-0.980756</td>\n",
       "      <td>-1.714328</td>\n",
       "      <td>-0.580678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.160921</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.624066</td>\n",
       "      <td>-1.676416</td>\n",
       "      <td>-2.470590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.926891</td>\n",
       "      <td>-0.124695</td>\n",
       "      <td>2245795</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52827</th>\n",
       "      <td>3174234</td>\n",
       "      <td>-1.587914</td>\n",
       "      <td>-1.184537</td>\n",
       "      <td>-1.714328</td>\n",
       "      <td>0.288689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708682</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.120274</td>\n",
       "      <td>-2.262391</td>\n",
       "      <td>-1.822777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.195553</td>\n",
       "      <td>-1.357043</td>\n",
       "      <td>7415938</td>\n",
       "      <td>merged</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>488 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pr_id  commit_counts  prs_experience  prs_succ_rate  prs_popularity  \\\n",
       "11811  83434   -0.540434      -1.532904       -1.714328      -1.135762         \n",
       "13035  112871  -0.540434      -1.532904       -1.714328      -1.555667         \n",
       "14055  550093  -0.540434      -0.724022        0.790595       0.871954         \n",
       "14486  711063   1.554526      -1.532904       -1.714328       0.631808         \n",
       "14657  279617  -0.540434      -0.375655        0.726262       0.543858         \n",
       "...       ...        ...            ...             ...            ...         \n",
       "52719  150397  -0.540434       0.380274        0.775170       0.043060         \n",
       "52763  196520  -0.540434      -1.532904       -1.714328      -1.135762         \n",
       "52764  1148556 -0.540434      -0.108968        0.881928       0.647964         \n",
       "52814  1762565 -0.540434      -0.980756       -1.714328      -0.580678         \n",
       "52827  3174234 -1.587914      -1.184537       -1.714328       0.288689         \n",
       "\n",
       "       prs_followed_pri  prs_watched_repo  prs_tenure_mnth  \\\n",
       "11811  1                 1                 0.103728          \n",
       "13035  0                 1                -3.555457          \n",
       "14055  0                 0                -0.639497          \n",
       "14486  1                 0                 0.043169          \n",
       "14657  0                 1                -0.089816          \n",
       "...   ..                ..                      ...          \n",
       "52719  0                 1                -0.701892          \n",
       "52763  0                 1                -3.555457          \n",
       "52764  0                 0                 0.132722          \n",
       "52814  0                 0                 0.160921          \n",
       "52827  1                 0                 0.708682          \n",
       "\n",
       "       prs_main_team_member  repo_pr_tenure_mnth  repo_pr_popularity  \\\n",
       "11811  0                    -3.734906            -0.827321             \n",
       "13035  0                    -3.734906            -1.938174             \n",
       "14055  0                    -3.734906            -0.712193             \n",
       "14486  0                    -2.543178             0.317436             \n",
       "14657  0                    -3.734906            -1.027982             \n",
       "...   ..                          ...                  ...             \n",
       "52719  0                    -2.983010            -1.465002             \n",
       "52763  0                     0.121783            -1.234648             \n",
       "52764  0                    -1.791282            -0.414212             \n",
       "52814  0                    -1.624066            -1.676416             \n",
       "52827  0                    -0.120274            -2.262391             \n",
       "\n",
       "       repo_pr_team_size  perc_external_contribs  intra_branch  \\\n",
       "11811 -2.470590          NaN                      0              \n",
       "13035 -2.470590          NaN                      0              \n",
       "14055 -0.572532          NaN                      1              \n",
       "14486 -0.310316          NaN                      0              \n",
       "14657 -1.323155          NaN                      0              \n",
       "...         ...           ..                     ..              \n",
       "52719 -2.470590          NaN                      0              \n",
       "52763 -2.470590          NaN                      0              \n",
       "52764 -2.470590          NaN                      0              \n",
       "52814 -2.470590          NaN                      0              \n",
       "52827 -1.822777          NaN                      0              \n",
       "\n",
       "       pr_files_changed  pr_lines_changed  repo_id  status manual_analysis  \n",
       "11811 -0.488071         -0.857099          4416     merged  NaN             \n",
       "13035 -1.195553         -1.357043          6286     merged  NaN             \n",
       "14055 -1.195553         -1.357043          8623     merged  NaN             \n",
       "14486  0.219410          0.752076          9703     merged  NaN             \n",
       "14657 -0.488071         -0.226240          10102    merged  NaN             \n",
       "...         ...               ...            ...       ...  ...             \n",
       "52719 -0.488071         -0.624638          287583   merged  NaN             \n",
       "52763 -0.488071         -0.357155          44939    merged  NaN             \n",
       "52764 -0.488071         -0.067737          404631   merged  NaN             \n",
       "52814  0.926891         -0.124695          2245795  merged  NaN             \n",
       "52827 -1.195553         -1.357043          7415938  merged  NaN             \n",
       "\n",
       "[488 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show rows with NaN values\n",
    "df[df.isna().any(axis=1)]\n",
    "#how many of the rows in perc_external_contrib are NaN \n",
    "df['perc_external_contribs'].isna().sum()\n",
    "#show where perc_external_contribs and manual_analysis are NaN\n",
    "df[df['perc_external_contribs'].isna() & df['manual_analysis'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make status column binary, non-merged = 1 and merged = 0\n",
    "df['status'] = df['status'].replace('merged', 0)\n",
    "df['status'] = df['status'].replace('not-merged', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the duplicate rows\n",
    "df = df.drop_duplicates(subset=['pr_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category to encoded number mapping:\n",
      "Chaotic: 0\n",
      "Duplicate: 1\n",
      "Merge Conflict: 2\n",
      "No Comment: 3\n",
      "No Reason: 4\n",
      "Not PR: 5\n",
      "Quality: 6\n",
      "Replaced: 7\n",
      "Resolved: 8\n",
      "Stale: 9\n",
      "Successful: 10\n",
      "Unnecessary: 11\n",
      "nan: 12\n"
     ]
    }
   ],
   "source": [
    "#encode the manual_analysis column using one-hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['manual_analysis'] = label_encoder.fit_transform(df['manual_analysis'])\n",
    "#show what is encoded to what\n",
    "\n",
    "encoded_classes = label_encoder.classes_\n",
    "encoded_values = label_encoder.transform(label_encoder.classes_)\n",
    "class_to_number_mapping = dict(zip(encoded_classes, encoded_values))\n",
    "\n",
    "# Displaying the mapping\n",
    "print(\"Category to encoded number mapping:\")\n",
    "for category, num in class_to_number_mapping.items():\n",
    "    print(f\"{category}: {num}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pr_id                     52778\n",
       "commit_counts             52778\n",
       "prs_experience            52778\n",
       "prs_succ_rate             52778\n",
       "prs_popularity            52778\n",
       "prs_followed_pri          52778\n",
       "prs_watched_repo          52778\n",
       "prs_tenure_mnth           52778\n",
       "prs_main_team_member      52778\n",
       "repo_pr_tenure_mnth       52778\n",
       "repo_pr_popularity        52778\n",
       "repo_pr_team_size         52778\n",
       "perc_external_contribs    52060\n",
       "intra_branch              52778\n",
       "pr_files_changed          52778\n",
       "pr_lines_changed          52778\n",
       "repo_id                   52778\n",
       "status                    52778\n",
       "manual_analysis           52778\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdIAAAPdCAYAAACOcJpIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADkW0lEQVR4nOzde3ycZZk//utJ0s6T0NJSTgV6AlTkfFTkXGARAiLGAyCKZQFZga4Komvdn5wRhUXQRQ67KlVZKyIEcXFADoKwgAtIYV0VhS8FlCLQCoXqTNvk+f3RbUho++Q0ycwk7/frlVfncM89V56kmeQz93PdSZZlWQAAAAAAAGvUUO0CAAAAAACglgnSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAEa5uXPnRpIkPT423HDDmDlzZvznf/5ntcvrMmPGjDjuuOP6/bi//vWvcfbZZ8fdd99d8Zr64s4774zddtst1llnnUiSJG666aY1jluwYMFqX4dVH7vtttuQ1FbtYzNYd999dyRJEj/60Y+G/Ll++ctfRltbW0ybNi0KhUJsvPHGsccee8RnPvOZHuOuuOKKmDt37qCe60tf+tJav08AAKiOpmoXAABAbbjmmmvi7W9/e2RZFi+88EJcfvnlcfjhh8fNN98chx9+eLXLG7C//vWvcc4550RExMyZM4f1ubMsiyOPPDLe9ra3xc033xzrrLNObLXVVrmP+cd//Mc45phjetw2bty4Iamvmsemntxyyy3x3ve+N2bOnBkXXXRRbLLJJrFw4cJ4+OGH4wc/+EFccsklXWOvuOKK2GCDDQb0ps8qX/rSl+KDH/xgvO997xt88QAAVIQgHQCAiIjYbrvteqx8PuSQQ2K99daLefPm1XWQXk3PP/98LF68ONra2uLAAw/s02OmTZsW73rXu4a4sqGVZVmUSqVobm6udikVcdFFF8Xmm28et912WzQ1vfEn1NFHHx0XXXRRFSsDAGC4aO0CAMAapWkaY8eOjTFjxvS4ffHixXHKKafEZpttFmPHjo0tttgi/vmf/znK5XJERJRKpdh5553jLW95S7z66qtdj3vhhRdi8uTJMXPmzOjo6IiIiOOOOy7GjRsX//u//xsHHnhgrLPOOrHhhhvG7Nmz469//WuvNT777LPx0Y9+NDbaaKMoFAqx9dZbxyWXXBKdnZ0RsbJdyoYbbhgREeecc05Xq5RVq4VfeumlOOmkk2Lq1KlRKBRiww03jL322ivuuOOOXp/7vvvuiwMPPDDGjx8fLS0tseeee8Ytt9zSdf/ZZ58dU6ZMiYiIf/qnf4okSWLGjBm9ztubhx9+ON773vfGpEmTIk3T2HnnneOHP/xhjzEvvfRSnHLKKbHNNtvEuHHjYqONNooDDjgg7r333q4xvR2b4447bo31nn322ZEkSY/bkiSJ2bNnx1VXXRVbb711FAqF+M53vhMREX/4wx/imGOO6fE1+sY3vtHj8Z2dnXH++efHVlttFc3NzTFx4sTYYYcd4mtf+1qfjkmpVIrTTz89Jk+eHM3NzbHffvvFo48+2nX/9773vUiSJB544IHVHnvuuefGmDFj4vnnn1/r/IsWLYoNNtigR4i+SkPDG39SzZgxI/73f/837rnnnq7jueoYlkql+MxnPhM77bRTTJgwISZNmhR77LFH/PjHP+4xX5IksXTp0vjOd77TNceqswXWdOwj3mjPtGDBgq7b7rrrrpg5c2asv/760dzcHNOmTYsPfOADffp/BQDA6qxIBwAgIiI6OjpixYoVkWVZ/PnPf46LL744li5d2qPNSKlUiv333z+eeuqpOOecc2KHHXaIe++9Ny688MKYP39+3HLLLZGmafzwhz+MXXfdNY4//vi44YYborOzMz7ykY9ElmUxb968aGxs7Jpz+fLlceihh8Y//MM/xOc///m4//774/zzz49nnnkmfvKTn6y13pdeein23HPPWLZsWZx33nkxY8aM+M///M8444wz4qmnnoorrrgiNtlkk7j11lvjkEMOiRNOOCFOPPHEiIiuAPnYY4+NX/3qV3HBBRfE2972tnjllVfiV7/6VSxatCj3WN1zzz1x0EEHxQ477BDf+ta3olAoxBVXXBGHH354zJs3L4466qg48cQTY8cdd4z3v//9Xe1aCoVCr1+Hzs7OWLFiRY/bGhsbI0mS+PnPfx6HHHJI7L777nHVVVfFhAkT4gc/+EEcddRR8de//rUrBF+8eHFERJx11lkxefLkeP3116O9vT1mzpwZd955Z8ycObPXY9NfN910U9x7771x5plnxuTJk2OjjTaK3/zmN7HnnnvGtGnT4pJLLonJkyfHbbfdFp/85Cfj5ZdfjrPOOisiVq74Pvvss+P/+//+v9h3331j+fLl8bvf/S5eeeWVPj33F77whdhll13im9/8Zrz66qtx9tlnx8yZM+PRRx+NLbbYIo466qj43Oc+F9/4xjdijz326HrcihUr4uqrr462trbYdNNN1zr/HnvsEd/85jfjk5/8ZHzkIx+JXXbZZbU3mCIi2tvb44Mf/GBMmDAhrrjiioiIrq95uVyOxYsXxxlnnBGbbbZZLFu2LO644454//vfH9dcc0187GMfi4iIBx54IA444IDYf//944tf/GJERKy77rp9Og6rLFiwIA477LDYZ5994tvf/nZMnDgx/vSnP8Wtt94ay5Yti5aWln7NBwBARGQAAIxq11xzTRYRq30UCoXsiiuu6DH2qquuyiIi++EPf9jj9q985StZRGQ/+9nPum677rrrsojILrvssuzMM8/MGhoaetyfZVk2a9asLCKyr33taz1uv+CCC7KIyO67776u26ZPn57NmjWr6/rnP//5LCKyX/7ylz0ee/LJJ2dJkmRPPPFElmVZ9tJLL2URkZ111lmrfe7jxo3LPv3pT/d+kN7kXe96V7bRRhtlr732WtdtK1asyLbbbrtsypQpWWdnZ5ZlWfb0009nEZFdfPHFvc65auyaPm6//fYsy7Ls7W9/e7bzzjtny5cv7/HY97znPdkmm2ySdXR0rHHuFStWZMuXL88OPPDArK2trev2vGMza9asbPr06avdftZZZ2Vv/jMiIrIJEyZkixcv7nH7wQcfnE2ZMiV79dVXe9w+e/bsLE3TrvHvec97sp122mnNBybHz3/+8ywisl122aXrmGdZli1YsCAbM2ZMduKJJ/aoe+zYsdmf//znrttWfY/ec889uc/z8ssvZ3vvvXfX12PMmDHZnnvumV144YU9vgeyLMu23XbbbL/99uu19lVfkxNOOCHbeeede9y3zjrr9Phe7/45rOlPuFX/h59++uksy7LsRz/6URYR2fz583utAwCAvtHaBQCAiIj47ne/Gw899FA89NBDUSwWY9asWXHqqafG5Zdf3jXmrrvuinXWWSc++MEP9njsqpXQd955Z9dtRx55ZJx88snx2c9+Ns4///z4whe+EAcddNAan/sjH/lIj+urVsH//Oc/X2u9d911V2yzzTbxzne+c7VasiyLu+66q9fP+Z3vfGfMnTs3zj///HjwwQdj+fLlvT5m6dKl8ctf/jI++MEP9tgEtLGxMY499tj44x//GE888USv86zNpz71qa6vw6qP3XffPZ588sn43e9+13WsVqxY0fVx6KGHxsKFC3s871VXXRW77LJLpGkaTU1NMWbMmLjzzjvjt7/97YBry3PAAQfEeuut13W9VCrFnXfeGW1tbdHS0rJavaVSKR588MGIWPl1eOyxx+KUU06J2267LZYsWdKv5z7mmGN6tDyZPn167Lnnnj2+f04++eSIiPj3f//3rtsuv/zy2H777WPffffNnX/99dePe++9Nx566KH48pe/HEcccUT8/ve/jzlz5sT2228fL7/8cp/qvP7662OvvfaKcePGdX1NvvWtb1X8a7LTTjvF2LFj46STTorvfOc78f/+3/+r6PwAAKORIB0AgIiI2HrrrWO33XaL3XbbLQ455JC4+uqr493vfnd87nOf62qxsWjRopg8efJqfZo32mijaGpqWq0lyvHHHx/Lly+Ppqam+OQnP7nG521qaor111+/x22TJ0/uer61WbRoUWyyySar3b6qRUdv7VkiIq677rqYNWtWfPOb34w99tgjJk2aFB/72MfihRdeWOtj/vKXv0SWZYN+7rWZMmVK19dh1cf48ePjz3/+c0REnHHGGTFmzJgeH6ecckpERFeg+9WvfjVOPvnk2H333eOGG26IBx98MB566KE45JBD4m9/+9uAa8vz5uOxaNGiWLFiRfzrv/7ravUeeuihPeqdM2dO/Mu//Es8+OCD0draGuuvv34ceOCB8fDDD/fpuVd9v7z5tu5fh4033jiOOuqouPrqq6OjoyMef/zxuPfee2P27Nl9/hx32223+Kd/+qe4/vrr4/nnn4/TTjstFixY0KcNR2+88cY48sgjY7PNNotrr702HnjggXjooYfi+OOPj1Kp1Oca+mLLLbeMO+64IzbaaKM49dRTY8stt4wtt9yyzz3nAQBYnR7pAACs1Q477BC33XZb/P73v493vvOdsf7668cvf/nLyLKsR5j+4osvxooVK2KDDTboum3p0qVx7LHHxtve9rb485//HCeeeOJqGytGrFxZvWjRoh5h+qog+80Be3frr79+LFy4cLXbV20a2b2Wtdlggw3isssui8suuyyeffbZuPnmm+Pzn/98vPjii3Hrrbeu8THrrbdeNDQ0DPq5+2vVnHPmzIn3v//9axyz1VZbRUTEtddeGzNnzowrr7yyx/2vvfZan58vTdOuDWS7W9vq6ze/ubLeeut1rdI/9dRT1/iYzTffPCJWvply+umnx+mnnx6vvPJK3HHHHfGFL3whDj744Hjuued67em9pjc+XnjhhdW+fz71qU/F9773vfjxj38ct956a0ycOHG1syH6asyYMXHWWWfFpZdeGr/+9a97HX/ttdfG5ptvHtddd12PY7WmY7w2aZp2PaZ7v/01fU322Wef2GeffaKjoyMefvjh+Nd//df49Kc/HRtvvHEcffTRfX5OAABWsiIdAIC1mj9/fkS8sQHlgQceGK+//nrcdNNNPcZ997vf7bp/lU984hPx7LPPxo033hjf+ta34uabb45LL710jc/zH//xHz2uf//734+IiJkzZ661tgMPPDB+85vfxK9+9avVakmSJPbff/+IeGOzx95WYk+bNi1mz54dBx100GpzdrfOOuvE7rvvHjfeeGOPOTs7O+Paa6+NKVOmxNve9rbc5xqIrbbaKt761rfGY489ttqK9e4r1yNWhtpv3tj08ccfjwceeKDHbXnHZsaMGfHiiy92rYSPiFi2bFncdtttfaq3paUl9t9//3j00Udjhx12WGO9a3qjZOLEifHBD34wTj311Fi8eHEsWLCg1+eaN29eZFnWdf2ZZ56J+++/f7Xvn1133TX23HPP+MpXvhL/8R//Eccdd1yss846vc6/pjdNIqKrJUv3jUoLhcIaj2eSJDF27NgeIfoLL7ywxjeX1jbHjBkzImLl17K7vE15GxsbY/fdd49vfOMbERG539sAAKydFekAAERExK9//etYsWJFRKxsy3HjjTfG7bffHm1tbV0rhz/2sY/FN77xjZg1a1YsWLAgtt9++7jvvvviS1/6Uhx66KHxd3/3dxER8c1vfjOuvfbauOaaa2LbbbeNbbfdNmbPnh3/9E//FHvttVePvuZjx46NSy65JF5//fV4xzveEffff3+cf/750draGnvvvfda6z3ttNPiu9/9bhx22GFx7rnnxvTp0+OWW26JK664Ik4++eSuMHv8+PExffr0+PGPfxwHHnhgTJo0KTbYYINYb731Yv/9949jjjkm3v72t8f48ePjoYceiltvvXWtK75XufDCC+Oggw6K/fffP84444wYO3ZsXHHFFfHrX/865s2bt9rq7Eq5+uqro7W1NQ4++OA47rjjYrPNNovFixfHb3/72/jVr34V119/fUREvOc974nzzjsvzjrrrNhvv/3iiSeeiHPPPTc233zzrq9x3rGZMWNGHHXUUXHmmWfG0UcfHZ/97GejVCrF17/+9ejo6OhzvV/72tdi7733jn322SdOPvnkmDFjRrz22mvx5JNPxk9+8pOuPvaHH354bLfddrHbbrvFhhtuGM8880xcdtllMX369HjrW9/a6/O8+OKL0dbWFh//+Mfj1VdfjbPOOivSNI05c+asNvZTn/pUHHXUUZEkSVdLnN4cfPDBMWXKlDj88MPj7W9/e3R2dsb8+fPjkksuiXHjxsWnPvWprrHbb799/OAHP4jrrrsutthii0jTNLbffvt4z3veEzfeeGOccsop8cEPfjCee+65OO+882KTTTaJP/zhDz2eb/vtt4+77747fvKTn8Qmm2wS48ePj6222ioOPfTQmDRpUpxwwglx7rnnRlNTU8ydOzeee+65Ho+/6qqr4q677orDDjsspk2bFqVSKb797W9HRHT9HwUAoJ+qu9cpAADVds0112QR0eNjwoQJ2U477ZR99atfzUqlUo/xixYtyj7xiU9km2yySdbU1JRNnz49mzNnTte4xx9/PGtubs5mzZrV43GlUinbddddsxkzZmR/+ctfsizLslmzZmXrrLNO9vjjj2czZ87Mmpubs0mTJmUnn3xy9vrrr/d4/PTp01eb85lnnsmOOeaYbP3118/GjBmTbbXVVtnFF1+cdXR09Bh3xx13ZDvvvHNWKBSyiMhmzZqVlUql7BOf+ES2ww47ZOuuu27W3NycbbXVVtlZZ52VLV26tNfjdu+992YHHHBAts4662TNzc3Zu971ruwnP/lJjzFPP/10FhHZxRdf3Ot8fR372GOPZUceeWS20UYbZWPGjMkmT56cHXDAAdlVV13VNaZcLmdnnHFGttlmm2Vpmma77LJLdtNNN2WzZs3Kpk+f3uuxWeWnP/1pttNOO2XNzc3ZFltskV1++eXZWWedlb35z4iIyE499dS1fl7HH398ttlmm2VjxozJNtxww2zPPffMzj///K4xl1xySbbnnntmG2ywQTZ27Nhs2rRp2QknnJAtWLAg91j8/Oc/zyIi+973vpd98pOfzDbccMOsUChk++yzT/bwww+v8THlcjkrFArZIYcckjt3d9ddd112zDHHZG9961uzcePGZWPGjMmmTZuWHXvssdlvfvObHmMXLFiQvfvd787Gjx+fRUSP4/3lL385mzFjRlYoFLKtt946+/d///c1Hs/58+dne+21V9bS0pJFRLbffvt13fff//3f2Z577pmts8462WabbZadddZZ2Te/+c0sIrKnn346y7Ise+CBB7K2trZs+vTpWaFQyNZff/1sv/32y26++eY+f84AAPSUZFm3cyABAGAYHXfccfGjH/0oXn/99WqXwijxk5/8JN773vfGLbfc0rXpKQAA9EZrFwAAYMT7zW9+E88880x85jOfiZ122ilaW1urXRIAAHXEZqMAAMCId8opp8R73/veWG+99Ya0jz0AACOT1i4AAAAAAJDDinQAAAAAAMghSAcAAAAAgByjarPRzs7OeP7552P8+PF6IgIAAAAAjGJZlsVrr70Wm266aTQ05K85H1VB+vPPPx9Tp06tdhkAAAAAANSI5557LqZMmZI7ZlQF6ePHj4+IlQdm3XXXrXI1AAAAAABUy5IlS2Lq1KlduXGeURWkr2rnsu666wrSAQAAAADoUxtwm40CAAAAAEAOQToAAAAAAOQQpAMAAAAAQI5R1SO9rzo6OmL58uXVLmNIjBkzJhobG6tdBgAAAABA3RCkd5NlWbzwwgvxyiuvVLuUITVx4sSYPHlyn5roAwAAAACMdoL0blaF6BtttFG0tLSMuKA5y7L461//Gi+++GJERGyyySZVrggAAAAAoPYJ0v9PR0dHV4i+/vrrV7ucIdPc3BwRES+++GJstNFG2rwAAAAAAPTCZqP/Z1VP9JaWlipXMvRWfY4jtQ88AAAAAEAlCdLfZKS1c1mT0fA5AgAAAABUiiAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0vvpxRdfjH/4h3+IadOmRaFQiMmTJ8fBBx8cDzzwQESs7D9+00039XveGTNmxGWXXVbZYgEAAAAAGLSmahdQbz7wgQ/E8uXL4zvf+U5sscUW8ec//znuvPPOWLx4cbVLAwAAAABgCFiR3g+vvPJK3HffffGVr3wl9t9//5g+fXq8853vjDlz5sRhhx0WM2bMiIiItra2SJKk6/pTTz0VRxxxRGy88cYxbty4eMc73hF33HFH17wzZ86MZ555Jk477bRIkiSSJImIiLPPPjt22mmnHjVcdtllXfNGRNx9993xzne+M9ZZZ52YOHFi7LXXXvHMM88M5WEAAAAAABhVBOn9MG7cuBg3blzcdNNNUS6XV7v/oYceioiIa665JhYuXNh1/fXXX49DDz007rjjjnj00Ufj4IMPjsMPPzyeffbZiIi48cYbY8qUKXHuuefGwoULY+HChX2qZ8WKFfG+970v9ttvv3j88cfjgQceiJNOOqkriAcAAAAAYPC0dumHpqammDt3bnz84x+Pq666KnbZZZfYb7/94uijj44ddtghNtxww4iImDhxYkyePLnrcTvuuGPsuOOOXdfPP//8aG9vj5tvvjlmz54dkyZNisbGxhg/fnyPx/VmyZIl8eqrr8Z73vOe2HLLLSMiYuutt67QZwsAAAAAQIQV6f32gQ98IJ5//vm4+eab4+CDD4677747dtlll5g7d+5aH7N06dL43Oc+F9tss01MnDgxxo0bF7/73e+6VqQP1KRJk+K4447rWuH+ta99rc+r2QEAAAAA6BtB+gCkaRoHHXRQnHnmmXH//ffHcccdF2edddZax3/2s5+NG264IS644IK49957Y/78+bH99tvHsmXLcp+noaEhsizrcdvy5ct7XL/mmmvigQceiD333DOuu+66eNvb3hYPPvjgwD85AAAAAAB6EKRXwDbbbBNLly6NiIgxY8ZER0dHj/vvvffeOO6446KtrS223377mDx5cixYsKDHmLFjx672uA033DBeeOGFHmH6/PnzV3v+nXfeOebMmRP3339/bLfddvH973+/Mp8YAAAAAACC9P5YtGhRHHDAAXHttdfG448/Hk8//XRcf/31cdFFF8URRxwREREzZsyIO++8M1544YX4y1/+EhERb3nLW+LGG2+M+fPnx2OPPRbHHHNMdHZ29ph7xowZ8Ytf/CL+9Kc/xcsvvxwRETNnzoyXXnopLrroonjqqafiG9/4RhSLxa7HPP300zFnzpx44IEH4plnnomf/exn8fvf/16fdAAAAACAChKk98O4ceNi9913j0svvTT23Xff2G677eKLX/xifPzjH4/LL788IiIuueSSuP3222Pq1Kmx8847R0TEpZdeGuutt17sueeecfjhh8fBBx8cu+yyS4+5zz333FiwYEFsueWWXZuWbr311nHFFVfEN77xjdhxxx3jv//7v+OMM87oekxLS0v87ne/iw984APxtre9LU466aSYPXt2/MM//MMwHREAAAAAgJEvyd7chHsEW7JkSUyYMCFeffXVWHfddXvcVyqV4umnn47NN9880jStUoXDYzR9rgAAAAAAa5KXF7+ZFekAAAAAAJBDkA4AAAAAADkE6QAAAAAAkEOQDgAAAAAAOQTpAAAAAACQQ5AOAAAAAAA5mqpdAPRHlmVRKpV6HVMulyMiolAoRJIkuePTNO11DAAAAAAwegnSqSulUilaW1srOmexWIzm5uaKzgkAAAAAjByC9F50dHRElmXD9nxJkkRjY+OwPR8AAAAAAPkE6Tk6Ojri/R/8ULz6l8XD9pwT1psUN/7oemH6WqRpGsViMXdMqVSKtra2iIhob2+PNE17nRMAAAAAYG0E6TmyLItX/7I4XtvlYxHJMOzLmnVG/Oq7A1oBf8UVV8TFF18cCxcujG233TYuu+yy2GeffYagyOpKkqRfbVjSNNW2BQAAAAAYlGFIh0eApCGiYRg+BhjWX3fddfHpT386/vmf/zkeffTR2GeffaK1tTWeffbZCh8IAAAAAIDRR5A+Anz1q1+NE044IU488cTYeuut47LLLoupU6fGlVdeWe3SAAAAAADqntYudW7ZsmXxyCOPxOc///ket7/73e+O+++/v0pVjS5ZlkWpVOrTuHK5HBERhUIhkiTJHZ+maa9jAAAAAIChJ0ivcy+//HJ0dHTExhtv3OP2jTfeOF544YUqVTW6lEqlaG1trfi8xWJRf3cAAAAAqAFau4wQb165nGWZ1cwAAAAAABVQNyvSr7zyyrjyyitjwYIFERGx7bbbxplnnjkkK4HryQYbbBCNjY2rrT5/8cUXV1ulztBI0zSKxWKv40qlUrS1tUVERHt7e6Rp2uu8AAAAAED11U2QPmXKlPjyl78cb3nLWyIi4jvf+U4cccQR8eijj8a2225b5eqqZ+zYsbHrrrvG7bff3hXSRkTcfvvtccQRR1SxstEjSZJ+t2BJ01TbFgAAAACoE3UTpB9++OE9rl9wwQVx5ZVXxoMPPjj0QXrWGdE5tE/R9TwDcPrpp8exxx4bu+22W+yxxx7xb//2b/Hss8/GJz7xiQoXCAAAAAAw+tRNkN5dR0dHXH/99bF06dLYY4891jquXC5HuVzuur5kyZJ+PU+SJDFhvUkRv/rugGvtrwnrTep3b/OjjjoqFi1aFOeee24sXLgwtttuu/jpT38a06dPH6IqAQAAAABGj7oK0v/nf/4n9thjjyiVSjFu3Lhob2+PbbbZZq3jL7zwwjjnnHMG/HyNjY1x44+ujyzLBjxHfyVJEo2Njf1+3CmnnBKnnHLKEFQEAAAAADC61VWQvtVWW8X8+fPjlVdeiRtuuCFmzZoV99xzz1rD9Dlz5sTpp5/edX3JkiUxderUfj3nQEJtAAAAAABGjroK0seOHdu12ehuu+0WDz30UHzta1+Lq6++eo3jC4VCFAqF4SwRAAAAAIARpqHaBQxGlmU9eqADAAAAAECl1c2K9C984QvR2toaU6dOjddeey1+8IMfxN133x233nprtUsDAAAAAGAEq5sg/c9//nMce+yxsXDhwpgwYULssMMOceutt8ZBBx1U7dIAAAAAABjB6iZI/9a3vlXtEgAAAAAAGIXqukc6AAAAAAAMtbpZkQ4wGmVZFqVSqdcxqzZeLhQKkSRJr/OmadqncQAAAAAI0nvV0dERWZYN2/MlSRKNjY3D9nxAbSuVStHa2lrxeYvFYjQ3N1d8XgAAAICRSJCeo6OjI4760Pvj5cWvDttzbjBpQlx3/Y3CdAAAAACAGiFIz5FlWby8+NX49/0WReMwdEDoyCI+fk/0ewX8L37xi7j44ovjkUceiYULF0Z7e3u8733vG5oigWGVpmkUi8XcMaVSKdra2iIior29PdI07dO8AAAAAPSNIL0PGpOIpuHYlrVzYA9bunRp7LjjjvH3f//38YEPfKCyNQFVlSRJv1qwpGmqZQsAAABAhQnSR4DW1tYh6aEMAAAAAEDEcKyzBgAAAACAuiVIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMjRVO0C6kFHFhGdw/Q8A/D666/Hk08+2XX96aefjvnz58ekSZNi2rRpFaoOAAAAAKhVWZZFqVTq07hyuRwREYVCIZIkyR2fpmmvY0YDQXqOJElig0kT4uP3DN9zbjBpQr+/MR9++OHYf//9u66ffvrpERExa9asmDt3biXLA4iIvr04e2EGAACA4VMqlaK1tbXi8xaLxWhubq74vPVGkJ6jsbExrrv+xsiyAS4VH4AkSaKxsbFfj5k5c+aw1ggwFC/OXpgBAACAWiVI70V/Q20AAAAAgOGWpmkUi8Vex5VKpWhra4uIiPb29kjTtNd5EaQDMAB9eXH2wgwAAADDJ0mSfp/pnaaps8P7SJAOQL/198XZCzMAAABQzxqqXQAAAAAAANQyQfqbdHZ2VruEITcaPkcAAAAAgErR2uX/jB07NhoaGuL555+PDTfcMMaOHRtJklS7rIrKsiyWLVsWL730UjQ0NMTYsWOrXRIAAAAAQM0TpP+fhoaG2HzzzWPhwoXx/PPPV7ucIdXS0hLTpk2LhgYnJAAAAAAA9EaQ3s3YsWNj2rRpsWLFiujo6Kh2OUOisbExmpqaRtxqewAAAACAoSJIf5MkSWLMmDExZsyYapcCAAAAAEAN0NsDAAAAAAByWJEOAAAAo0CWZVEqlXodUy6XIyKiUCj02hY0TVOtQwEYFQTpAAAAMAqUSqVobW2t6JzFYjGam5srOicAI0tf3shdNa6W38wVpAMAAAAAMCSG4o3ciOF/M1eQDgAAAKNAmqZRLBZzx5RKpWhra4uIiPb29kjTtNc5AWA0EKQDAADAKJAkSb9W7qVpqm0LAIPWlzdyI2r/zVxBOgAAAAAAQ6K/b+RG1OabuQ3VLgAAAAAAAGqZIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAActhsFAAAAKiaLMuiVCr1OqZcLkdERKFQiCRJcsenadrrGADoD0E6AAAAUDWlUilaW1srOmexWIzm5uaKzgnA6Ka1CwAAAAAA5LAiHQAAAKiaNE2jWCzmjimVStHW1hYREe3t7ZGmaa9zAkAlCdIBAACAqkmSpF9tWNI01bYFgGGntQsAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABADkE6AAAAAADkEKQDAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABADkE6AAAAAADkEKQDAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5GiqdgEAAACMHlmWRalU6nVMuVyOiIhCoRBJkvQ6b5qmfRoHADAQgnQAAACGTalUitbW1orPWywWo7m5ueLzAgBEaO0CAAAAAAC5rEgHAABg2KRpGsViMXdMqVSKtra2iIhob2+PNE37NC8AwFARpAMAADBskiTpVwuWNE21bAEAqk5rFwAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcTdUuAAAAAKoty7IolUq9jimXyxERUSgUIkmS3PFpmvY6BgCoD4J0AAAARr1SqRStra0VnbNYLEZzc3NF5wQAqkNrFwAAAAAAyGFFOgAAAKNemqZRLBZzx5RKpWhra4uIiPb29kjTtNc5AYCRQZAOAADAqJckSb/asKRpqm0LAIwiWrsAAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABADkE6AAAAAADkEKQDAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABADkE6AAAAAADkEKQDAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABADkE6AAAAAADkEKQDAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABADkE6AAAAAADkEKQDAAAAAEAOQToAAAAAAOSomyD9wgsvjHe84x0xfvz42GijjeJ973tfPPHEE9UuCwAAAACAEa5ugvR77rknTj311HjwwQfj9ttvjxUrVsS73/3uWLp0abVLAwAAAABgBGuqdgF9deutt/a4fs0118RGG20UjzzySOy7775rfEy5XI5yudx1fcmSJUNaIwAAAAAAI0/drEh/s1dffTUiIiZNmrTWMRdeeGFMmDCh62Pq1KnDVR4AAAAAACNEXQbpWZbF6aefHnvvvXdst912ax03Z86cePXVV7s+nnvuuWGsEgAAAACAkaBuWrt0N3v27Hj88cfjvvvuyx1XKBSiUCgMU1UAAAAAAIxEdRek/+M//mPcfPPN8Ytf/CKmTJlS7XIAAAAAABjh6iZIz7Is/vEf/zHa29vj7rvvjs0337zaJQEAAAAAMArUTZB+6qmnxve///348Y9/HOPHj48XXnghIiImTJgQzc3NVa4OAAAAAICRqm42G73yyivj1VdfjZkzZ8Ymm2zS9XHddddVuzQAAAAAAEawulmRnmVZtUsAAAAAAGAUqpsV6QAAAAAAUA2CdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgBxN1S4AAAAAABg5siyLUqnU65hyuRwREYVCIZIkyR2fpmmvY2AoCdIBAAAAgIoplUrR2tpa0TmLxWI0NzdXdE7oD61dAAAAAAAghxXpAAAAAEDFpGkaxWIxd0ypVIq2traIiGhvb480TXudE6pJkA4AAAAAVEySJP1qw5KmqbYt1DytXQAAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHI0VbsAAAAAVsqyLEqlUp/GlcvliIgoFAqRJEnu+DRNex0DAMDaCdIBAABqRKlUitbW1orPWywWo7m5ueLzAgCMFlq7AAAAAABADivSAQAAakSaplEsFnsdVyqVoq2tLSIi2tvbI03TXucFAGDgBOkAAAA1IkmSfrdgSdNU2xYAgCEmSAcAAEYdm3oCANAfgnQAAGDUsaknAAD9YbNRAAAAAADIYUU6AAAw6tjUEwBGn760dtPWjbURpAMAAKOOTT0BYPQZitZu2rqNHlq7AAAAAABADivSAQAAAIARry+t3bR1Y20E6QAAAADAiNff1m7autGdIB0AgCHZeCnC5ksAAMDIIEgHAGBINl6KsPkSAAAwMgjSAQCoWUOxUt4qeQAAoL8E6QAADMnGS6vmHYyhWClvlTwAANBfgnQAAGy8BAAAkEOQDgBAzRqKlfKDXSUPAACMPoJ0AABqlpXyAABALWiodgEAAAAAAFDLrEgfQbIsi1Kp1OuYcrkcERGFQiGSJMkdn6Zpr2MAAAAAAEYyQfoIUiqVorW1taJzFotFp0cDAAAAAKOa1i4AAAAAAJDDivQRJE3TKBaLuWNKpVK0tbVFRER7e3ukadrrnAAAAAAAo5kgfQRJkqRfbVjSNNW2BQAAAACgF1q7AAAAAABADkE6AAAAAADkEKQDAAAAAEAOPdKBupVlWZRKpV7HlMvliIgoFAqRJEmv86Zp2qdxAAAAAIwOgnSgbpVKpWhtba34vMVi0Ua8AAAAAHTR2gUAAAAAAHJYkQ7UrTRNo1gs5o4plUrR1tYWERHt7e2Rpmmf5gUAAACAVQTpQN1KkqRfLVjSNNWyBQAAAIB+09oFAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAgR10F6b/4xS/i8MMPj0033TSSJImbbrqp2iUBAAAAADDC1VWQvnTp0thxxx3j8ssvr3YpAAAAAACMEk3VLqA/Wltbo7W1tdplAMMgy7IolUqDnqf7HJWYb5U0TSNJkorNB6NBX/5fZ1kW5XK54s9dKBTW+n921XP2Zcxw1rWKnzcAAADVV1dBen+Vy+Uef/QuWbKkitUA/VEqlSr+xllbW1vF5ioWi9Hc3Fyx+WA0GIr/16OBnzcAAADVV1etXfrrwgsvjAkTJnR9TJ06tdolAQAAAABQZ0b0ivQ5c+bE6aef3nV9yZIlwnSoQ5fvvTgKjdmAHptlEcs6V14e2xAxmO4I5Y4kZt83aeATAF1e3+nDkTWs4deQLIvoXFH5J2xoWuMPgKRzRYybP6/r+tp+3nT/WVJJa/u55OcNAABAbRnRQXqhUIhCoVDtMoBBKjRmUWgc+OPTilUysDAfWF3W0BTROGYt944dvjredD3v503lfpb0hZ83AAAAtWREB+lAZfR148/um/HZQA8AAACAkaKugvTXX389nnzyya7rTz/9dMyfPz8mTZoU06ZNq2JlMLIN1QaBNtADAAAAoB7UVZD+8MMPx/777991fVX/81mzZsXcuXOrVBUAAAAAACNZXQXpM2fOjCzTMxSGW5qmUSwWex1XKpWira0tIiLa29sjTfM7Cvd2PwAAAADUgroK0oHqSJKk3y1Y0jTVtgUAAACAEaGh2gUAAAAAAEAtE6QDAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5GiqdgEQEZFlWZRKpYrM1X2eSs2ZpmkkSVKRuQAAAACA+iJIpyaUSqVobW2t+LxtbW0VmadYLEZzc3NF5gIAAAAA6ovWLgAAAAAAkMOK9AHoSxuSLMuiXC5HREShUOi1LYjWIW94facPR9YwiG/NLIvoXLHyckNTxACPa9K5IsbNnzfwOgAAAACAEUGQPgBD0YZE65A3ZA1NEY1jBjnL2MHXMegZAAAAAICRQGsXAAAAAADIYUX6AKRpGsViMXdMqVTq2uiyvb090jTtdU4AAAAAAGqPIH0AkiTpVxuWNE21bQEAAAAAqFOCdBjl+rJ5bl91n2ewc1aqJgAAAAAYLEE6jHJDsXluRHS1NgIAAACAemezUQAAAAAAyGFFOtDl9Z0+HFnDIH4sZFlE54qVlxuaIpJkQNMknSti3Px5A68DAAAAACpIkA50yRqaIhrHDHKWsYOvY9AzAABQDZXaf6eSe+90l6ZpJANc7AEAjG6CdAAAACpiKPbfqeTeO8ViMZqbmys2HwAwegjSAQAAGBUGu7rdSnkAGL0E6QBV4tRnABgalXqNjRia19nR8ho7qP13KrT3TkTP/XcqubrdSnkAGF0E6QBV4tRnABgaQ/EaG1G519nR8ho7+P13Br/3ToT9dwCAyhCkAwCMcM6AAXjD5XsvjkLjwOL1LItY1rny8tiGQS2Uj3JHErPvmzTwCQCAYSVIhz6o1fBB8DBy1OKpz8DI4QwYRrNBvcZGVOx11mts7Sg0ZlFoHPjj04pVYq08ANQTQTr0QSXDgkrOJ3gYOZz6DABDY/CvsRGVeJ3t/hprkQYAQP0RpAMAjCK1eAbMYENALWeoNxZpAADUH0E69NFgeilGVK6fol6KAAxGLZ4BU8lQUcsZgNpRqT06IpyFAUD1CdKhjwbbSzGiUv0UNd8AAKh3FmlQSbUaWJdKpYqfgRHhLAwAqkOQDsAaabUADKfBhIqVChQjhIoMH4s0qKSh2FQ6ovJtiACgngnSAVgjrRaA4TTYULEygWKEUBFgaDgLA4B6J0gHAACAEWJQm0pHVHZj6eWlGPc/10eEszAAqH+CdADWSqsFAID6MvhNpSMqtrF0x/KKzAMAtUCQDsBaabUAAAAAENFQ7QIAAAAAAKCWCdIBAAAAACCH1i4AAAAAADUsy7IolUoVmav7PJWaM03TSAazOVodEKQDAAAAANSwUqkUra2tFZ+3ra2tIvO0t7dHmg5up7RaD/gF6QAAAAAADFilAvlKz1csFqO5ubkicwnSAQAAAADqxOs7fTiyhkHEulkW0bli5eWGpogBrthOOlfEuPnzBl5HnRGkAwAAAADUiayhKaJxzCBnGTv4Ot50/fK9F0eh8c239mO+LGJZ58rLYxsGnO9HuSOJ2fdNGnAdayNIBwAAAABgUAqNWRQaBzfH4LqsrzLwMD9Pw5DMCgAAAAAAI4QV6TDKZVm3d+k6llevkO5qpQ4AAAAACEE6jHrlcrnr8vjHflDFSgAAAACgNmntAgAAAAAAOaxIh1GuUCh0XX5tx6MrsOtzBXQstzoeAAAAgJohSIdRLkmSN640jqmNIB0AAAAAaojWLgAAAAAAkEOQDgAAAAAAOQTpAAAAAACQQ5AOAAAAAAA5BOkAAAAAAJBDkA4AAAAAADkE6QAAAAAAkKOp2gUAAAAAALUvy7IolUoVmav7PJWaMyIiTdNIkqRi88EqgnQAAAAAoFelUilaW1srPm9bW1vF5ioWi9Hc3Fyx+WAVrV0AAAAAACCHFekAAAAAQL+8vtOHI2sYRLSYZRGdK1ZebmiKGEQ7lqRzRYybP2/gtUAfCNIBAAAAgH7JGpoiGscMcpaxlamlIrNAPq1dAAAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIEdTtQsAAAAAABiwLOu6WCqVBjVV98cPdq5V0jSNJEkqMhfVI0gHAAAAAOpX54qui21tbRWbtlJzFYvFaG5urshcVI8gHQAAAGAAsizrdcVqlmVRLpcr/tyFQqHXFa5WwQJUjiAdAAAAYABKpVK0trZWu4y1sgqW0ejyvRdHoTHrfeBaZFnEss6Vl8c2RAz0vahyRxKz75s04DqoPYJ0AAAAAGBEKDRmUWgc3BxpRSoZeJhPbRpwkP7kk0/GU089Ffvuu280NzdHlmVOFwIAAABGpdd3+nBkDWuIWbKsR//mimloWuNS2aRzRYybP6/yzwcwyvU7SF+0aFEcddRRcdddd0WSJPGHP/whtthiizjxxBNj4sSJcckllwxFnQAAAAA1K2toimgcs5Z7xw5fHcP2TACjS0N/H3DaaadFU1NTPPvss9HS0tJ1+1FHHRW33nprRYsDAAAAAIBq6/eK9J/97Gdx2223xZQpU3rc/ta3vjWeeeaZihUGAAAAAAC1oN9B+tKlS3usRF/l5ZdfjkKhUJGi6CnLsiiVShWZq/s8lZozIiJNUz3yAaBGZVm3k7w7llevkO5qpQ4AGIRaf43tUR8Ag9LvIH3fffeN7373u3HeeedFRESSJNHZ2RkXX3xx7L///hUvkJWBd2tra8XnbWtrq9hcxWIxmpubKzYfAFA55XK56/L4x35QxUrWrtxR7QpW6l6H8AGA3tT6a+yrr7661kVvWZb1qL9SCoVCrwvtLMYD6lG/g/SLL744Zs6cGQ8//HAsW7YsPve5z8X//u//xuLFi+O//uu/hqJGAABGuNn3rV/tElZTLpfXeCYmANSLD3/4w9UuYY0sxgPqUb+D9G222SYef/zxuPLKK6OxsTGWLl0a73//++PUU0+NTTbZZChqpJvL914chcaBr47KsohlnSsvj22IGMwbwOWOJGbfN2ngE0AfWaUIMDjd2++9tuPREY1jqljN/+lYXpMr9xgZar3VAjByeI0FGD36HaRHREyePDnOOeecStdCHxQasyg0Dm6OtDKlRIQgkeFhlSLA4PQ4dbpxTG38kf8ml++9aNC/41RCueON1x37/9SvWm+1AIwc9fEau+YFed0X2lXS2hbtWYwH1Lt+B+m/+MUvcu/fd999B1wMAACjU6ExaiJI707vVgBGhjUvgkuS4X7tfaMOZ/gC9ajfQfrMmTNXu637HxkdHTXSgwEYMaxSBAD6Q6sFgDc4wxegMvodpP/lL3/pcX358uXx6KOPxhe/+MW44IILKlYYwCpWKQIA/VEPrRbsAQMAUF/6HaRPmDBhtdsOOuigKBQKcdppp8UjjzxSkcIAAABGKitEgeHiDF+AyhjQZqNrsuGGG8YTTzxRqekAAAAAGCRn+AJURr+D9Mcff7zH9SzLYuHChfHlL385dtxxx4oVBgAAMFJZIQoAUF/6HaTvtNNOkSTJav3z3vWud8W3v/3tihUGAAAwUlkhCgBQX/odpD/99NM9rjc0NMSGG24YaZpWrCgAAAAAAKgV/Q7Sp0+fPhR1AAAAAABATepTkP71r3+9zxN+8pOfHHAxAAAAAABQa/oUpF966aV9mixJEkE6AAAAAAAjSp+C9Df3RQcAAAAAgNGiodoFAAAAAABALev3ZqMREX/84x/j5ptvjmeffTaWLVvW476vfvWrFSkMAAAAAABqQb+D9DvvvDPe+973xuabbx5PPPFEbLfddrFgwYLIsix22WWXoagRAAAAAACqpt+tXebMmROf+cxn4te//nWkaRo33HBDPPfcc7HffvvFhz70oaGoEQAAAAAAqqbfQfpvf/vbmDVrVkRENDU1xd/+9rcYN25cnHvuufGVr3yl4gUCAAAAAEA19bu1yzrrrBPlcjkiIjbddNN46qmnYtttt42IiJdffrmy1TFqZFn2xpWO5dUrpLtaqQMAAAAAqKp+B+nvete74r/+679im222icMOOyw+85nPxP/8z//EjTfeGO9617uGokZGgVVvzkREjH/sB1WsBAAAAACgp34H6V/96lfj9ddfj4iIs88+O15//fW47rrr4i1veUtceumlFS8QAAAAAACqqd9B+nnnnRcf/ehHI8uyaGlpiSuuuGIo6qqaLMuiVCoNep7ucwx2vkrUU+sKhULX5dd2PDqicUwVq/k/HcutjgcAAKCulTuSiMh6Hbc2WRaxrHPl5bENEUkymDoA6le/g/RFixbFYYcdFuuvv34cffTRceyxx8ZOO+00BKVVR6lUitbW1orO2dbWVtH5RqKk+ytx45jaCNIBAACgzs2+b1K1SwAYERr6+4Cbb745XnjhhTjrrLPikUceiV133TW22Wab+NKXvhQLFiwYghIBAAAAAKB6+r0iPSJi4sSJcdJJJ8VJJ50Uf/zjH2PevHnx7W9/O84888xYsWJFpWusmtd3+nBkDQM6RCvPfer8v2PR0DTwc58iIlleinH/c/2AHw8AAACMPu3t7ZGm6aDmKJVKXWfaV2K+iKjIHADDbYAp8UrLly+Phx9+OH75y1/GggULYuONN65UXTUha2gaZIuRsZWpo2N5ReYBakuWdetTWCv/z2ulDgCgLvn9BmpLmqbR3Nxcs/MB1JMBBek///nP4/vf/37ccMMN0dHREe9///vjJz/5SRxwwAGVrg9gxCqXy12XbWwLAIwE9fD7Tbmj2hWs1L2OHm9AAAA1qd9B+pQpU2LRokVx8MEHx9VXXx2HH364U3IAAACoC7PvW7/aJaymXC5HS0tLtcsAAHL0O0g/88wz40Mf+lCst956Q1FPr6644oq4+OKLY+HChbHtttvGZZddFvvss09VagEYjEKh0HX5tR2PHmQrqQrpWF6zq8cAgNrn9xtGs6RzRQzq3IIK7bWWdI6cvesAakm/g/STTjppKOrok+uuuy4+/elPxxVXXBF77bVXXH311dHa2hq/+c1vYtq0aVWrC2Agku6/GDeOqY0/NAEABqEefr+5fO9FUWisdhUrW7usWh3f/Q0I6te4+fOqXQIAQ2hQm40Ot69+9atxwgknxIknnhgREZdddlncdtttceWVV8aFF15Y5eoAqAdZlkWpVIpSqZQ7rrOzM5YsWVLR51533XWjoaFhrXUlSdL1b63UFbFyU6k0TXPr6ovu/V+T5aU1b6adxRsrsSqpoSliDeUnnT0b5S5ZlkShcfW1ZFkWsayz8mWNbVjzYrNyxxs36ptbv2r5582qPtaFQmGt/7fr+ecN5Ck0Rk0E6d35nof+68vr7FC8lkUM/vf6atQV4XUWBqtugvRly5bFI488Ep///Od73P7ud7877r///jU+plwu99jsZih+SAFQX0qlUrS2tla7jLpTLBajubl5UHN0f00e9z/XD7akIfGZByZVu4TV6Jtbv/y8GZhK/LwBGC5pmkaxWKzIXKVSKdra2iIior29vSL70Y3kPe28zg6M11kYuLoJ0l9++eXo6OiIjTfeuMftG2+8cbzwwgtrfMyFF14Y55xzznCUBwAAAIwySZIMSSiZpqmwE6DG1E2QvsqbTz/JO1Vmzpw5cfrpp3ddX7JkSUydOnVI6wMYScodvY8ZDt3rGGybi1Wrhmqx1UKtt3YZrAkTJkR7e3vumO4tJyqpL+0r+toKY7jqWmXChAkVf16GRy3/vKn11i7ACNHt97aR+Hsl1dWX11mtXXryOguDUzdB+gYbbBCNjY2rrT5/8cUXV1ulvkqhULBpC8AgrNoAq5YMts3FqlVDfVnhs/76tff5R9RuXb1paGiI9dZbr9plrFG9HlNqm583wHDpEQivaQ+SalnxxpvQI/H3Sqqrr6+ztfpaVqt1AWtXN0H62LFjY9ddd43bb7+9q2dYRMTtt98eRxxxRBUrg5Ej6VwRg1qTkWVvbBLY0LTmHfT6WAcAANA33c+aGv/YD6pYCQCMXHUTpEdEnH766XHsscfGbrvtFnvssUf827/9Wzz77LPxiU98otqlwYgwbv68apdAjbl870VRaKx2FStPwV21ismZRgAA9eeSPRbFumOrXYXfKwEYuLoK0o866qhYtGhRnHvuubFw4cLYbrvt4qc//WlMnz692qUBjEiFxqiJIL273vpJAwCMNt0D4dd2PDqicUwVq+lm2d9i/K9/FBER48f4vRKA+lZXQXpExCmnnBKnnHJKtcuAEWPVBi2VUCqVulovtbe3D2oTk+5zAQAAa9cjEG4cUztBeuMb/dpl1gDUu7oL0oHKWrVBS6WlaTok8wIAAADAcGuodgEAAAAAAFDLBOkAAAAAAJBDkA4AAAAAADkE6QAAAAAAkMNmowAAAAAANSzLsjeudCyvXiHd1Uodw0SQDgAAAABQw8rlctfl8Y/9oIqVjF5auwAAAAAAQA4r0gEAAAAAalihUOi6/NqOR0c0jqliNf+nY3mP1fHljirW0k33Onq0xBkkQToAAAAAQA1LkuSNK41jaiNIf5PZ961f7RJWUy6Xo6WlpSJzae0CAAAAAAA5rEgHAAAAAGBQLt97URQaq13FytYuq1bHd2+JM1iCdOijkd7nCQAAAAAGqtAYNRGkd9ejJc4gCdKhj0Z6nycAAAAAYM30SAcAAAAAgBxWpEMfjfQ+TwAAAADAmgnSoY9Gep8nAAAAAGDNtHYBAAAAAIAcVqQDAAAAjDJZlkWpVOp1XPcxfRmfpqmzp4ERSZAOAAAAMMqUSqVobW3t12Pa2tp6HVMsFqO5uXmgZQHULK1dAAAAAAAghxXpAAAAAKNMmqZRLBZ7HZdlWZTL5YiIKBQKvbZtSdO0IvUB1BpBOgAAAMAokyRJn1uwtLS0DHE1ALVPaxcAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcTdUuAACA4ZN0rohsoA/OsojOFSsvNzRFJMmg6gAAAKgXgnQAgFFk3Px51S4BAACg7mjtAgAAAAAAOaxIBwAY4dI0jWKxOOh5SqVStLW1RUREe3t7pGlasfkAAABqmSAdAGCES5IkmpubKzpnmqYVnxMAAKBWCdIBAKi6ckcSMcBtULMsYlnnystjGwa1B+r/1QEAANCTIB0AgKqbfd+kapcAAACwVjYbBQAAAACAHFakAwBQFbW6CeoqlZoHAACof4J0AACqwiaoAABAvdDaBQAAAAAAcliRDgAAMMzKHUlEZAN+fJZFLOtceXlsQ0SSDKYOAAB6I0gHAAAYZrPvm1TtEgAA6AdBOgAAMGIlnSsGse47Vi797lyx8nJD04CXfier5gAAKi9749V+ybIkCo21ddZXlg3qtxFqhCAdAAAYscbNn1ftElbT3t4eaZoOao5SqRRtbW0Vmy8iKjIHAFRFZ0fXxc88UHtnfZXL5Whpaal2GQySIB0AAGAYpWkazc3NNTsfAACrE6QDAAAjSpqmUSwWKzKXld8AUAeaCl0X582bN6jX2lKpFB/+8IcrMtcqEyZMGPQcVJ8gHQAAGFGSJBmSFdpWfgNAjWpo6Lo4ceLEQb1e/+1vf6vYXIwsDb0PAQAAAACA0cuKdAAAAIAhkmVZlEqlXsd1H9OX8WmaRpIkg6oN+ivLsq7LyfJSZB3LBzFZRHSuWHm5oSliEN/OSbfNRrvXCJUkSAcAAAAYIqVSKVpbW/v1mFV7M+QpFotaTjDsyuVy1+Vx/3N9FStZu3K5HC0tLdUugxFIkF4Pur2TtmRZEoXGgb+zlmURyzpXXh7bEDGYN6/LHW882Lt9AAAAAMBIJUivB91OT/nMA5OqWMjaebcPAAAAVpemaRSLxV7HZVnWtdq3UCj02rYlTdOK1Af9MWHChGhvb6/IXKVSKT784Q9HRMS8efMq9j09YcKEiswDbyZIBwAAABgiSZL0uQWLBWrUuoaGhlhvvfUqMtff/va3rssTJ07UqoiaJ0ivB02FrouDfYfOu30AAAAAAP0jSH+TPu0+3H1X4UrJ2Z24+87DEyZMGNQ71N7tAwAAAADoH0H6m9T67sN6kQMAAAAADK+GahcAAAAAAAC1zIr0N+nL7sPdd9KulL7syB2hFzkAAAAAwHATpL9JJXcfBgAAAACg/mntAgAAAAAAOQTpAAAAAACQQ5AOAAAAAAA5BOkAAAAAAJBDkA4AAAAAADkE6QAAAAAAkEOQDgAAAAAAOQTpAAAAAACQo6naBQAAADDyJJ0rIhvog7MsonPFyssNTRFJMqg6AAAGS5AOAABAxY2bP6/aJQAAVIzWLgAAAAAAkMOKdAAAACoiTdMoFouDnqdUKkVbW1tERLS3t0eaphWbr9yRRAyw6UyWRSzrXHl5bMOgOs78Xx2VN6iWOhEVbqvTMZhKAKCmCNIBAACoiCRJorm5uaJzpmla0Tln3zepYnPVIi11AGBoaO0CAAAAAAA5rEgHAABgRKvVljOrDHaeSn1+EZX9HLvPBQD1TpAOAADAiFYPLWcGYyg+v4jKfo6D6U0fUbn+9EPVmx6AkU+QDlADBrUpVEU3hFox4McCAMDajPTe9ACMfIJ0ak6t7DIvUGQ42RQKAAAAoHYJ0qk5AkUAAID6V6u921epVI97AEYHQTpAldTqplc2hQIAoBLqoXc7APSVIJ2aUKsrFQSKDKV62PRqMJtCVWpDqDfqAAAAAKgOQTo1wUoFqE02hQIAAACIaKh2AQAAAAAAUMusSAegh1rt3b6KTaEAAACA4SZIB6CHeujdDgAAADCcBOkAAAAAAAxKuSOJiGzAj8+yiGWdKy+PbYhIksHUUXmCdAAAAAAABmX2fZOqXcKQstkoAAAAAADksCIdAAAAAIABa29vjzRNBzVHqVSKtra2is0XERWZYxVBOgAAAAAAA5amaTQ3N9fsfJUgSIc+GukbJgAAAAAAayZIhz4a6RsmAAAAAABrJkgHAAAAAKgTSeeKQfRMiJVtEzpXrLzc0DTgtgnJqjlGCUE65EjTNIrFYkXmqvUNEwAAAACofePmz6t2CaOSIB1yJEkyJBsb1OKGCQAAAADAmgnSAQAAAABqmK4J1SdIBwAAAACoYbomVF9DtQsAAAAAAIBaJkgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyFE3QfoFF1wQe+65Z7S0tMTEiROrXQ4AAAAAAKNE3QTpy5Ytiw996ENx8sknV7sUAAAAAABGkaZqF9BX55xzTkREzJ07t8+PKZfLUS6Xu64vWbKk0mUBAAAAADDC1c2K9IG48MILY8KECV0fU6dOrXZJAAAAAADUmREdpM+ZMydeffXVro/nnnuu2iUBAAAAAFBnqhqkn3322ZEkSe7Hww8/POD5C4VCrLvuuj0+AAAAAACgP6raI3327Nlx9NFH546ZMWPG8BQDAAAAAABrUNUgfYMNNogNNtigmiUAAAAAAKNAlmVRKpVyx3S/v7exERFpmkaSJIOujdpX1SC9P5599tlYvHhxPPvss9HR0RHz58+PiIi3vOUtMW7cuOoWBwAAAADUtFKpFK2trX0e39bW1uuYYrEYzc3NgymLOlE3QfqZZ54Z3/nOd7qu77zzzhER8fOf/zxmzpxZpaoAAAAAABjp6iZInzt3bsydO7faZcCo1JdTnyKc/gQAAADUrjRNo1gs5o7JsizK5XJERBQKhV5zizRNK1Yfta1ugnSgevp76lOE058AAACA2pIkSZ9yiJaWlmGohnrTUO0CAAAAAACgllmRDvSqL6c+RQzd6U/ljiQisjU8X8Syzj5N0S9jGyLWVPrKOgAAAAAYbQTpQK/6eupTxNCc/jT7vkkVnxMAAAAA+kprFwAAAAAAyGFFOlCT+ruTdiXZlRsAAACA7gTpQE2ykzYAAAAAtUJrFwAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgBxN1S4AAAAAABg5siyLUqmUO6b7/b2NjYhI0zSSJBl0bTBQgnQYpL68OER4gQAAAABGh1KpFK2trX0e39bW1uuYYrEYzc3NgykLBkWQDoPU3xeHCC8QAAAAAFBPBOkAAAAAQMWkaRrFYjF3TJZlUS6XIyKiUCj0elZ+mqYVqw8GQpAOg9SXF4cILxAAAADA6JAkSZ/Osm9paRmGaqAyBOkwSH19cYjwAgEAAAAA9aih2gUAAAAAAEAtsyIdAAAAAIAhkWVZlEqlXsd1H9OX8Wma9to6uZIE6QAAAAAADIlSqRStra39ekxbW1uvY4rFYp/bLVeC1i4AAAAAAJDDinQAAAAAAIZEmqZRLBZ7HZdlWZTL5YiIKBQKvbZtSdO0IvX1lSB9BOlLv6Fa7zUEAAAAAIwcSZL0uQVLS0vLEFczcIL0EaS//YZqsdcQAAAAAECt0SMdAAAAAAByWJE+gvSl31Ct9xoCAAAAAKg1gvQRpK/9hmq51xAAAAAAQK3R2gUAAAAAAHII0gEAAAAAIIcgHQAAAAAAcuiRDgAAAABQ57Isi1Kp1Ou47mP6Mj5N00iSZFC1jQSCdAAAAACAOlcqlaK1tbVfj2lra+t1TLFYjObm5oGWNWJo7QIAAAAAADmsSAcAAAAAqHNpmkaxWOx1XJZlUS6XIyKiUCj02rYlTdOK1FfvBOkAAAAAAHUuSZI+t2BpaWkZ4mpGHq1dAAAAAAAghyAdAAAAAAByaO0CQL9lWRalUil3TPf7exsbsbLnWm992QAAAACqQZAOQL+VSqVobW3t8/i2trZexxSLxT73cgMAAAAYTlq7AAAAAABADivSAei3NE2jWCzmjsmyLMrlckREFAqFXtu2pGlasfoAAAAAKkmQDkC/JUnSpzYsLS0tw1ANAAAAwNDS2gUAAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcjRVuwDojyzLolQq5Y7pfn9vYyMi0jSNJEkGXRsAAAAAMDIJ0qkrpVIpWltb+zy+ra2t1zHFYjGam5sHUxYAAAAAMIIJ0gFq2FCchRHhTAwAAACA/hCkU1fSNI1isZg7JsuyKJfLERFRKBR6DQvTNK1YfVBpQ3EWRoQzMQAAAAD6Q5BOXUmSpE/hX0tLyzBUAwAAAACMBoJ0gBo2FGdhrJoXAAAAgL4RpAPUMGdhAAAAAFRfQ7ULAAAAAACAWiZIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADIIUgHAAAAAIAcgnQAAAAAAMghSAcAAAAAgByCdAAAAAAAyCFIBwAAAACAHIJ0AAAAAADI0VTtAgAAYG2yLItSqZQ7pvv9vY2NiEjTNJIkGXRtAADA6CFIBwCgZpVKpWhtbe3z+La2tl7HFIvFaG5uHkxZAADAKKO1CwAAAAAA5LAiHQCAmpWmaRSLxdwxWZZFuVyOiIhCodBr25Y0TStWHwAAMDoI0gEAqFlJkvSpDUtLS8swVAMAAIxWWrsAAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABADkE6AAAAAADkEKQDAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5GiqdgEAAFRflmVRKpVyx3S/v7exq6RpGkmSDKo2AACAahOkAwAQpVIpWltb+zy+ra2tT+OKxWI0NzcPtCwAAICaoLULAAAAAADksCIdAIBI0zSKxWLumCzLolwuR0REoVDoU8uWNE0rUh8AAEA1CdIBAIgkSfrUgqWlpWUYqgEAAKgtWrsAAAAAAEAOQToAAAAAAOQQpAMAAAAAQA5BOgAAAAAA5BCkAwAAAABAjqZqF9AXCxYsiPPOOy/uuuuueOGFF2LTTTeNj370o/HP//zPMXbs2GqXBwAA1Jksy6JUKvU6rvuYvoxP0zSSJBlxdQEAjHZ1EaT/7ne/i87Ozrj66qvjLW95S/z617+Oj3/847F06dL4l3/5l2qXBwAA1JlSqRStra39ekxbW1uvY4rFYjQ3Nw+0rJqtCwBgtKuLIP2QQw6JQw45pOv6FltsEU888URceeWVuUF6uVyOcrncdX3JkiVDWicAAAAAACNPXQTpa/Lqq6/GpEmTcsdceOGFcc455wxTRQAAQL1I0zSKxWKv47Is61qcUygUem2PkqbpiKwLAGC0q8sg/amnnop//dd/jUsuuSR33Jw5c+L000/vur5kyZKYOnXqUJcHAADUuCRJ+tzqpKWlZYireUOt1gUAMNo1VPPJzz777EiSJPfj4Ycf7vGY559/Pg455JD40Ic+FCeeeGLu/IVCIdZdd90eHwAAAAAA0B9VXZE+e/bsOProo3PHzJgxo+vy888/H/vvv3/sscce8W//9m9DXB0AAAAAAFQ5SN9ggw1igw026NPYP/3pT7H//vvHrrvuGtdcc000NFR1MT0AAAAAAKNEXfRIf/7552PmzJkxbdq0+Jd/+Zd46aWXuu6bPHlyFSsDAAAAAGCkq4sg/Wc/+1k8+eST8eSTT8aUKVN63JdlWZWqAgAAAABgNKiL/ijHHXdcZFm2xg8AAAAAABhKdRGkAwAAAABAtQjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACBHU7ULAAAAAIZelmVRKpVyx3S/v7exERFpmkaSJIOuDQBqnSAdAAAARoFSqRStra19Ht/W1tbrmGKxGM3NzYMpCwDqgtYuAAAAAACQw4p0AAAAGAXSNI1isZg7JsuyKJfLERFRKBR6bduSpumg69JyBoB6IEgHAACAUSBJkj61YWlpaRmGat6g5QwA9UBrFwAAAAAAyGFFOgAAAFA1tdpyBgC6E6QDAAAAVVOrLWcAoDutXQAAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACBHU7ULAAAAYPTIsixKpVLumO739zZ2lTRNI0mSQdUGALA2gnQAAACGTalUitbW1j6Pb2tr69O4YrEYzc3NAy0LACCX1i4AAAAAAJDDinQAAACGTZqmUSwWc8dkWRblcjkiIgqFQp9atqRpWpH6AADWRJAOAADAsEmSpE8tWFpaWoahGgCAvtHaBQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAgR1O1CwAAAIBqy7IsSqVS7pju9/c2NiIiTdNIkmTQtQEA1SdIBwAAYNQrlUrR2tra5/FtbW29jikWi9Hc3DyYsgCAGqG1CwAAAAAA5LAiHQAAgFEvTdMoFou5Y7Isi3K5HBERhUKh17YtaZpWrD4AoLoE6QAAAIx6SZL0qQ1LS0vLMFQDANQarV0AAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjSAQAAAAAghyAdAAAAAAByNFW7gOGUZVlERCxZsqTKlQAAAAAAUE2rcuJVuXGeURWkv/baaxERMXXq1CpXAgAAAABALXjttddiwoQJuWOSrC9x+wjR2dkZzz//fIwfPz6SJKl2Of2yZMmSmDp1ajz33HOx7rrrVrucUcWxrw7HvXoc++px7KvHsa8Ox716HPvqceyrw3GvHse+ehz76nDcq8exr556PvZZlsVrr70Wm266aTQ05HdBH1Ur0hsaGmLKlCnVLmNQ1l133br7hhwpHPvqcNyrx7GvHse+ehz76nDcq8exrx7Hvjoc9+px7KvHsa8Ox716HPvqqddj39tK9FVsNgoAAAAAADkE6QAAAAAAkEOQXicKhUKcddZZUSgUql3KqOPYV4fjXj2OffU49tXj2FeH4149jn31OPbV4bhXj2NfPY59dTju1ePYV89oOfajarNRAAAAAADoLyvSAQAAAAAghyAdAAAAAAByCNIBAAAAACCHIB0AAAAAAHII0gEAAAAAIIcgHQAAAAAAcgjS68wrr7xS7RIAAKgzHR0dcc8998Rf/vKXapcCAAB1SZBew77yla/Edddd13X9yCOPjPXXXz8222yzeOyxx6pYGQytV155Jb75zW/GnDlzYvHixRER8atf/Sr+9Kc/VbmykWvp0qXVLgGAIdTY2BgHH3ywRRmMOnfffXe1SxjVnnzyybjtttvib3/7W0REZFlW5YpGJz/7ASojybyS1awtttgirr322thzzz3j9ttvjyOPPDKuu+66+OEPfxjPPvts/OxnP6t2iSPa9773vbjqqqvi6aefjgceeCCmT58el112WWy++eZxxBFHVLu8Eevxxx+Pv/u7v4sJEybEggUL4oknnogtttgivvjFL8YzzzwT3/3ud6td4og0bty4OPLII+P444+Pvffeu9rljHhf//rX46STToo0TePrX/967thPfvKTw1TV6NTR0RE33XRT/Pa3v40kSWLrrbeOI444IhobG6td2oh35513xp133hkvvvhidHZ29rjv29/+dpWqGtne8Y53xJe//OU48MADq13KqLN06dL48pe/vNbv+f/3//5flSob+dI0jc022yz+/u//PmbNmhVTp06tdkmjwqJFi+Koo46Ku+66K5IkiT/84Q+xxRZbxAknnBATJ06MSy65pNoljlhf+cpXYsaMGXHUUUdFxMoFeTfccENMnjw5fvrTn8aOO+5Y5QpHro6Ojpg7d+5af9bfddddVaps5Hn/+9/f57E33njjEFYy+vT292t3I/Fv2aZqF8DaLVy4sOsXvf/8z/+MI488Mt797nfHjBkzYvfdd69ydSPblVdeGWeeeWZ8+tOfjgsuuCA6OjoiImLixIlx2WWXCdKH0Omnnx7HHXdcXHTRRTF+/Piu21tbW+OYY46pYmUj27x582Lu3Llx4IEHxvTp0+P444+Pj33sY7HppptWu7QR6dJLL42PfOQjkaZpXHrppWsdlyTJiPzlo1Y8+eSTcdhhh8Uf//jH2GqrrSLLsvj9738fU6dOjVtuuSW23HLLapc4Yp1zzjlx7rnnxm677RabbLJJJElS7ZJGhQsuuCDOOOOMOO+882LXXXeNddZZp8f96667bpUqG/lOPPHEuOeee+LYY4/1PT/Mnn/++bj22mtj7ty5cfbZZ8eBBx4YJ5xwQrzvfe+LsWPHVru8Eeu0006LpqamePbZZ2Prrbfuuv2oo46K0047TZA+hK6++uq49tprIyLi9ttvj9tvvz2KxWL88Ic/jM9+9rMW5A2hT33qUzF37tw47LDDYrvttvOzfghNmDCh63KWZdHe3h4TJkyI3XbbLSIiHnnkkXjllVf6FbjTN2/++/Wll16Kv/71rzFx4sSIWHkGTEtLS2y00UYj8m9ZK9Jr2Kabbho/+tGPYs8994ytttoqzj///PjQhz4UTzzxRLzjHe+IJUuWVLvEEWubbbaJL33pS/G+970vxo8fH4899lhsscUW8etf/zpmzpwZL7/8crVLHLEmTJgQv/rVr2LLLbfsceyfeeaZ2GqrraJUKlW7xBFt0aJF8d3vfjfmzp0bv/nNb+Lggw+O448/Pt773vdGU5P3XhlZDj300MiyLP7jP/4jJk2aFBEr/w989KMfjYaGhrjllluqXOHItckmm8RFF10Uxx57bLVLGVUaGt7o6tj9j/ssyyJJkq6FA1TexIkT45Zbbom99tqr2qWMavPnz49vf/vbMW/evOjs7IyPfOQjccIJJ1ihOwQmT54ct912W+y44449fqd/+un/v737joryatuGfwxIFRQU7EgRJCKgFHvEktgTLElsKBaMsSGiWFLA3guWJIqCRjT2qEmMXWwgFhRsoBRB1NjAECKolJnvDz/mzWSIyf1kho3XHL+1sl7YM8+9jncyuZg5r73PMxNubm54/vy56IiSZWJiotwYEBQUhJcvXyIiIgKpqalo1aoVZ2VokZWVFaKjo9GzZ0/RUXTK9OnT8ezZM6xbt055qrS0tBTjxo1DtWrVsHTpUsEJpWvbtm349ttvERUVBWdnZwDA7du38emnn+Kzzz6Dn5+f4ISaxx7plVi/fv0wePBgdOnSBbm5uejRoweA1x8AHR0dBaeTtszMTHh4eKitGxkZsZe0lhkbG5d7k+j27duwtrYWkEi31KxZE8HBwbh69SpWrFiB48eP4+OPP0a9evUQFhaGwsJC0RElpbi4GA4ODkhOThYdRSedPn0aS5YsURbRgdf/DSxatAinT58WmEz6ioqK0LZtW9ExdM7JkyeV/8TExCj/KfudtMfS0lLlWkNiNG/eHDNmzMD48eNRUFCAjRs3wsvLC+3bt8fNmzdFx5OUgoICmJqaqq3n5OTAyMhIQCLdYWlpiXv37gEADh8+jPfffx/A65umvGGqXYaGhqzVCLBx40aEhISotGbU19fH5MmT2S5Qy0JDQ7FmzRplER0AnJ2dER4ejq+++kpgMu1hIb0SCw8Px4QJE+Di4oJjx47BzMwMwOuWL+PGjROcTtrs7e2RlJSktn7o0CG4uLhUfCAd0rt3b8yZMwfFxcUAXu+Yy87OxowZM/DRRx8JTid9jx49wpIlS9CkSRPMmDEDH3/8MU6cOIHw8HDs27cPffr0ER1RUgwMDPDq1Sse+xTEyMgIf/zxh9r68+fPedxfy0aNGoVt27aJjqFzOnTo8MZ/SHvmzp3LG9ICFRcXY8+ePejZsydsbW1x5MgRfP3113j8+DEyMzNhY2ODTz75RHRMSfHx8VGZbSSTySCXy7F06VJ06tRJYDLp44Y8caZMmYJVq1ZxqG4FKykpQUpKitp6SkqKWp960qyHDx8qazd/VlpaisePHwtIpH08p1+JxcfHY9KkSWrtFCZMmIBz584JSqUbpk6divHjx+Ply5dQKBS4ePEitm/fjoULFyIyMlJ0PElbtmwZevbsiVq1auHFixfo0KEDHj16hDZt2mD+/Pmi40nW3r17sWnTJhw5cgQuLi4YP348hgwZouxzBrzexVXeSQ36bwIDA7F48WJERkayfU4F++CDDzB69GhERUWhZcuWAIALFy5gzJgx8PX1FZxOeiZPnqz8WS6XY/369Th+/Djc3d1hYGCg8twVK1ZUdDydcfbsWURERODOnTvYvXs36tevjy1btsDe3p7DpjXMw8ND5UZpeno6ateuDTs7O7X3/JUrVyo6ns4IDAzE9u3bAQBDhgzBkiVL4Orqqny8atWqWLRoEezs7AQllKalS5eiY8eOSEhIQFFREaZNm4abN2/i2bNniIuLEx1P0sLDw2FnZ4d79+5hyZIl3JCnZX/twR0TE4NDhw6hadOmatd6Dr3UjhEjRmDkyJFIT09H69atAQDnz5/HokWLMGLECMHppO29997Dp59+iqioKHh5eUEmkyEhIQGfffaZ8jSM1LBHeiWmr6+Phw8folatWirrubm5qFWrFo9ladmGDRswb9485bG4+vXrY9asWQgICBCcTDfExMTgypUrkMvl8PT0lOxFuLKoXr06Bg4ciFGjRqFFixblPufFixdYsmQJZs6cWcHppK1v3744ceIEzMzM4Obmpjb8jx+4tScvLw/Dhg3Dzz//rPyiU1JSAl9fX3z33XcqQ4zov/tfdiCePHlSi0l01w8//IChQ4fCz88PW7ZsQXJyMhwcHPDtt9/iwIEDOHjwoOiIkjJ79ux//Vz+bdWe9957D6NGjcJHH330t6eNSkpKEBcXx5MZGvbw4UOsW7cOly9fVn6mHz9+POrWrSs6GpHG/C+F2k2bNmkxie6Sy+VYtmwZVq1ahYcPHwJ4PY8nKCgIU6ZMUWn5Qpr19OlTDBs2DIcPH1b5PtWtWzd89913avVMKWAhvRLT09PD48eP1fpCp6amwtvbm8NGK0hOTg7kcrkkLwCVUXR0NAYMGKDWO7GoqAg7duyAv7+/oGTSVlhYWG4fS9K+f/rwzQ/c2peWlqY8Duri4sJjzyRZHh4eCA4Ohr+/v8rwv6SkJHTv3h2PHj0SHZFI486cOYO2bduqnfoqKSnBuXPn4OPjIygZkfbcvn0ba9asQUpKCmQyGd555x0EBgaq9DEmkqKyOlm1atUEJ9EtqampuHXrFhQKBZo0aYLGjRuLjqQ1LKRXQmVHg3788Ud0795dpaBYWlqKa9euwdnZGYcPHxYVUfIyMzNRUlICJycnlfW0tDQYGBjw6KcW8SSGGHzdSdeVfRxiv/qKMXLkSKxatQrm5uYq6wUFBQgMDORgKC0xNTVFcnIy7OzsVArpd+7cgYuLC16+fCk6omQ5ODjg0qVLqFmzpsp6Xl4ePD09cefOHUHJpI+fccRwcHBAhw4dsG7dOpXvszk5OWjZsiXf81q0Z88eDBo0CN7e3mjTpg2A120uLl26hG3btnEegBaxjiBOSUkJTp06hYyMDAwePBjm5ub49ddfUa1aNWV7I9KeoqIiZGZmolGjRpJvV8pho5VQ9erVUb16dSgUCpibmyt/r169OurUqYPRo0dj69atomNK2vDhw8vtQ3/hwgUMHz684gPpEIVCUW4h6/79+2yzoEV/d0/11atXHLpYQZ48eYKzZ88iNjYWT548ER1HZ0RFRcHV1RXGxsYwNjaGq6srZ2FUgM2bN+PFixdq6y9evFAZTkeaVbduXaSnp6utx8bGwsHBQUAi3ZGVlVVuwfbVq1e4f/++gES64+8+W+bm5qq1UyPNycrKQlxcHNq3b69stQC83hh29+5dgcmkb9q0afj8888RHx+PFStWYMWKFTh37hy++OILTJ8+XXQ8SWMdQYy7d+/Czc0NvXv3xvjx4/H06VMAwJIlSxASEiI4nbQVFhYiICAApqamaNq0KbKzswEAEydOxKJFiwSn0w5p3yZ4S5Ud47ezs0NISAg/4AmQmJiIdu3aqa23bt0aEyZMEJBI+soGcslkMrz33nsqdzFLS0uRmZmJ7t27C0woTatXrwbwehduZGSkyt360tJSnDlzBu+8846oeDohPz8f48ePx44dO5RFFn19fQwYMADffPMNbyBpUWhoKMLDwxEYGKjcsRUfH4/g4GBkZWVh3rx5ghNKT35+PhQKBRQKBf744w8YGxsrHystLcXBgwfZSk2LPvvsMwQFBWHjxo2QyWT49ddfER8fj5CQEISFhYmOJ0k//fST8ucjR46oXNNLS0tx4sQJ2Nvbi4gmeWWnfGUyGYYPH17uKd+2bduKiid5MpkMhw8fRkhICLy9vbF///6/ncNDmvXo0aNy22EOGTIES5cuFZBId7COIEZQUBC8vb1x9epVlZNfffv2xahRowQmk77PP/8cV69exalTp1TqNe+//z5mzpyJGTNmCEynHSykV2IcOiSOTCbDH3/8obb++++/8/inlvTp0wcAkJSUhG7duqkUdA0NDWFnZ4ePPvpIUDrpCg8PB/B6t9a6detUBrGUve7r1q0TFU8njBo1CklJSThw4ADatGkDmUyGc+fOISgoCJ9++il27dolOqJkrV27Fhs2bMCgQYOUa76+vnB3d0dgYCAL6VpgYWGhvGlaXu9EmUz2Pw1opP/NtGnT8Pvvv6NTp054+fIlfHx8YGRkhJCQEH7B15KyzzcymQzDhg1TeazsmP/y5csFJJO+spsWZad8TUxMlI8ZGhqidevW+PTTT0XFkzyFQgEzMzPs3bsXn3/+OTp06ID169ejS5cuoqNJXseOHXH27Fm1mS+xsbFo3769oFS6gXUEMWJjYxEXF6d2ktrW1hYPHjwQlEo37N+/Hzt37kTr1q1VTn+5uLggIyNDYDLtYSG9Env8+DFCQkJw4sQJPHnyRK31Ai/E2tO+fXssXLgQ27dvVxYWS0tLsXDhQrz77ruC00lT2Y0jOzs7DBgwQGWXImlPZmYmAKBTp07Yu3cvLC0tBSfSPb/88guOHDmicm3p1q0bNmzYwFMYWlZaWgpvb2+1dS8vL5SUlAhIJH0nT56EQqFA586d8cMPP6BGjRrKxwwNDWFra4t69eoJTCh98+fPx5dffonk5GTI5XK4uLiwd6gWyeVyAIC9vT0uXboEKysrwYl0B0/5ivXngsrChQvRtGlTfPrppyo3r0lz/nz6xdfXF9OnT8fly5fRunVrAK97pO/evZs3q7WMdQQx5HJ5ufWx+/fvq83jIc16+vRpuadJCwoKJDt7isNGK7EePXogOzsbEyZMQN26ddXehL179xaUTPqSk5Ph4+MDCwsL5V37s2fPIj8/HzExMXB1dRWckIikomHDhvjll1/g5uamsn7t2jX07NmTvXO1KDAwEAYGBlixYoXKekhICF68eIFvvvlGUDLpu3v3LmxsbKCnx3E9oty7dw8ymQwNGjQQHYWIJEhPTw+PHj1SKbDEx8ejb9++ePr0KTeFadi//Xsqk8n42msR6whiDBgwANWrV8f69ethbm6Oa9euwdraGr1790bDhg2VN1ZJ8zp06ICPP/4YgYGBytfe3t4eEyZMQHp6Og4fPiw6osaxkF6JmZub4+zZs2jevLnoKDrp119/xddff42rV6/CxMQE7u7umDBhgsruOdK80tJShIeHY9euXcjOzkZRUZHK48+ePROUTHomT56MuXPnomrVqpg8efIbn/vXQiNpzvr167F7925ER0ejbt26AF73thw2bBj69euHzz77THBC6QoMDER0dDRsbGxUdmzdu3cP/v7+MDAwUD6X/w1oXl5eHi5evIgnT54od+2WKa+3K/13JSUlmD17NlavXo3nz58DAMzMzBAYGIiZM2eqvOdJ806cOKE8afrX9/zGjRsFpZImT09PnDhxApaWlso5PH/nypUrFZiMHj9+jFu3bqFDhw6ioxBpBesIFe/XX39Fp06doK+vj7S0NHh7eyMtLQ1WVlY4c+YM5+9o0blz59C9e3f4+fnhu+++w2effYabN28iPj4ep0+fhpeXl+iIGsfWLpWYjY2NWjsXqjj16tXDggULRMfQObNnz0ZkZCQmT56M0NBQfPnll8jKysL+/fs5CE3DEhMTUVxcDOD1l8i/+5Ip1SNZlcXatWuRnp4OW1tbNGzYEACQnZ0NIyMjPH36FBEREcrn8su+Zt24cQOenp4AoOzhZ21tDWtra9y4cUP5PP43oHk///wz/Pz8UFBQAHNzc5XXWCaTsZCuJRMmTMC+ffuwZMkSlQG7s2bNQk5ODmdiaNHs2bMxZ84ceHt7l3vSlDSrd+/eyuGiZX3qqXKoXbs2ateuLToGkdawjlDx6tWrh6SkJGzfvh1XrlyBXC5HQEAA/Pz8VOZjkOa1bdsWcXFxWLZsGRo1aoSjR4/C09MT8fHxaieupYI70iuxo0ePYvny5YiIiICdnZ3oODqHO+XEaNSoEVavXo1evXrB3NwcSUlJyrXz589j27ZtoiMSadT/0quSQ6hJKho3boyePXtiwYIFMDU1FR1HZ1SvXh07duxAjx49VNYPHTqEgQMH4vfffxeUTPrq1q2LJUuWYOjQoaKj6JTS0lLExsbC3d2dc2AqAE8CiLN69WqMHj0axsbGWL169RufO3HixApKpZtYRyCSNhbSKzFLS0sUFhaipKQEpqamasdt2eJCe/5ppxxfe+2pWrUqUlJS0LBhQ9StWxe//PILPD09cefOHXh4ePBLvhaUlJTA2NgYSUlJ7NtXiW3fvh2+vr4clqYF6enpyMjIgI+PD0xMTKBQKLhbVMuqVq2K69evw8HBQXQUnVK7dm2cOnUKTZo0UVlPSUmBj48Pnj59KiiZ9NWsWRMXL15Eo0aNREfROcbGxkhJSYG9vb3oKJI3e/ZsTJ06Faampv+4UYCbAzTL3t4eCQkJqFmz5hvf6zKZDHfu3KnAZLqFdQQx/jxs989kMhmMjY3h6OjIvwFakp+fX+66TCaDkZERDA0NKziR9rGQXolt3rz5jY8PGzasgpLoHu6UE8fZ2RnR0dFo1aoV2rdvj169emHGjBnYuXMnAgMD8eTJE9ERJalRo0bYu3cvmjVrJjoK/Y1q1aohKSmJhUcNys3NRf/+/XHy5EnIZDKkpaXBwcEBAQEBsLCwwPLly0VHlKx+/fph4MCB6N+/v+goOmXOnDm4desWNm3apGx78erVKwQEBMDJyYmFLS2aPn06zMzMEBoaKjqKzmnRogUWLVqE9957T3QUIpI41hHE0NPTg0wmU2uNXLYmk8nw7rvvYv/+/TydpGFlr/3fadCgAYYPH46ZM2f+66HIlR17pFdiLJSL8+DBA0ycOJF//ATo27cvTpw4gVatWiEoKAiDBg1CVFQUsrOzERwcLDqeZH311Vf4/PPPsXXrVg7CqaR431vzgoODYWBggOzsbJUdugMGDEBwcDAL6VrUq1cvTJ06FcnJyXBzc1M7defr6ysomfT069dP5ffjx4+jQYMGyhunV69eRVFREYuMWvby5UusX78ex48fh7u7u9p7ngONtWf+/PkICQnB3Llz4eXlpXayq1q1aoKSSdu9e/cgk8nQoEEDAMDFixexbds2uLi4YPTo0YLTSVdxcTGcnZ1x4MABuLi4iI6jc1hHEOPYsWP48ssvMX/+fLRs2RLA62vOV199hdDQUFSvXh2fffYZQkJCEBUVJTittHz33Xf48ssvMXz4cLRs2RIKhQKXLl3C5s2b8dVXX+Hp06dYtmwZjIyM8MUXX4iOqxHckV6JZWdnv/HxsqF0pHncKVd5XLhwAXFxcXB0dGRhRYs8PDyQnp6O4uJi2Nraqn3JZB9L8czNzXH16lXuSNegOnXq4MiRI2jWrJnK65uZmQk3Nzc8f/5cdETJetOOFJlMhtLS0gpMI20jRoz418/dtGmTFpPotk6dOv3tYzKZDDExMRWYRrf8+Xrz511zZbsUeb3Rjvbt22P06NEYOnQoHj16hMaNG8PV1RWpqamYOHEiwsLCREeUrPr16+P48eNqbbxI+1hHEMPV1RXr169H27ZtVdbj4uIwevRo3Lx5E8ePH8fIkSP/sc5G/5v33nsPn332mdp7fteuXYiIiMCJEyewZcsWzJ8/H7du3RKUUrO4I70Ss7Oze+MRCX7o0x7ulBOjuLgYo0ePRmhoqLJY2KpVK7Rq1UpwMunr06eP6AhEFa6goKDcHUM5OTnKthekHX8dvkXaw+J45XDy5EnREXQWX3sxbty4odwZumvXLri5uSEuLg5Hjx7FmDFjWEjXosDAQCxevBiRkZGoUoUln4rEOoIYGRkZ5Z4uqlatmnImgJOTE3Jycio6muTFx8dj3bp1auseHh6Ij48HALz77ruSuoHBHemV2NWrV1V+Ly4uRmJiIlasWIH58+erHdUlzeFOOXEsLCxw5coV7rol+gvuSNe8Xr16wdPTE3PnzoW5uTmuXbsGW1tbDBw4EHK5HHv27BEdkYiI6K1kZmaGGzduwM7ODr6+vmjXrh2mT5+O7OxsODs748WLF6IjSlZZq0wzMzO4ubmpnTTdu3evoGTSxzqCGO+++y7Mzc0RHR0Na2trAMDTp0/h7++PgoICnDlzBsePH8e4ceOQmpoqOK20NG7cGP369cOiRYtU1mfMmIF9+/bh9u3bSEhIQO/evfHgwQNBKTWLtycrsfKG/nl7e6NevXpYunQpC+laxJ1y4vTt2xf79+/H5MmTRUchIolbunQpOnbsiISEBBQVFWHatGm4efMmnj17hri4ONHxJO/ixYs4deoUnjx5ovZ3l/2itSM3NxdhYWE4efJkua/7s2fPBCWTvpcvX2LNmjV/+9qzhZr2FRYWIjs7G0VFRSrr7u7ughJJW9OmTbFu3Tr06tULx44dw9y5cwEAv/76K2rWrCk4nbRZWFjgo48+Eh1DJ7GOIEZUVBR69+6NBg0awMbGBjKZDNnZ2XBwcMCPP/4IAHj+/DkHfmvBsmXL8Mknn+DQoUNo0aIFZDIZLl26hFu3bik3JV26dAkDBgwQnFRzuCP9LZSWlobmzZujoKBAdBSd8PLlSxgbG4uOoTPmz5+PZcuW4b333it3INTEiRMFJZO20tJShIeHY9euXeV+yWRxRTxXV1ccOnQINjY2oqNIyqNHj7B27VpcvnwZcrkcnp6eGD9+POrWrSs6mqQtWLAAX331FZydnVG7dm2VVnbsF609PXr0QEZGBgICAtRed4CD7rVp8ODBOHbsGD7++ONyX/uZM2cKSiZ9T58+xYgRI3Do0KFyH+cOUe04deoU+vbti/z8fAwbNgwbN24EAHzxxRe4desWd0UTkUYpFAocOXIEqampUCgUeOedd9ClS5c3nhIgzcjKysK6detUXvvPPvsMdnZ2oqNpBQvplVh+fr7K7wqFAg8fPsSsWbNw69YtJCUliQmmA0pLS7FgwQKsW7cOjx8/RmpqKhwcHBAaGgo7OzsEBASIjihZ9vb2f/uYTCZT9jgjzQoLC0NkZCQmT56M0NBQfPnll8jKysL+/fsRFhbGGxgkOcXFxejatSsiIiLQuHFj0XF0Tu3atbF48WIMHz5cdBSdYm5ujtjY2HJPPZJ2Va9eHQcPHkS7du1ER9E5fn5+yMrKwsqVK9GpUyfs27cPjx8/xrx587B8+XL06tVLdETJKi0tRX5+PiwtLZVrWVlZMDU1Ra1atQC8Hgbo7e3N2SQa1LlzZ+zduxcWFhYq6/n5+ejTpw9vVmtZQUEBTp8+Xe7mJH6nInr7sbVLJWZhYaG2W0WhUMDGxgY7duwQlEo3zJ8/H5s3b8aSJUvw6aefKtfd3NwQHh7OQroWZWZmio6gk77//nts2LABvXr1wuzZszFo0CA0atQI7u7uOH/+PD/0aZilpeUbh0n/GU8DaIeBgQFu3Ljxr/89kGbp6emxoCjAO++8w77EgtSvXx/m5uaiY+ikmJgY/Pjjj2jRogX09PRga2uLLl26oFq1ali4cCEL6Vqkr6+vUkQHoLZDsUePHkhKSuIMGA06deqUWgEXeH3S+uzZswIS6Y7ExET07NkThYWFKCgoQI0aNZCTk6O8ecTvVNpz4sQJnDhxotz2aWUnYkg78vLycPHixXJfe39/f0GptIeF9ErsrxPm9fT0YG1tDUdHR07f1rLo6GisX78e7733HsaMGaNcd3d3x61btwQmozLVqlXjh24NevToEdzc3AC8Hg71+++/AwA++OAD9pLTgpUrVyp/zs3Nxbx589CtWze0adMGwOvp50eOHOFrr2X+/v6IiopSG45D2hccHIxvvvlG5b8F0r5vv/0WM2bMQFhYGFxdXWFgYKDyeLVq1QQlk77ly5dj+vTpWLduHWxtbUXH0SkFBQXK3c81atTA06dP0bhxY7i5ubE3fSXAA/Kac+3aNeXPycnJePTokfL30tJSHD58GPXr1xcRTWcEBwfjww8/xNq1a2FhYYHz58/DwMAAQ4YMQVBQkOh4kjV79mzMmTMH3t7eqFu3LjfKVKCff/4Zfn5+KCgogLm5uVq7RhbSqUJ16NBBdASd9eDBAzg6Oqqty+VyFBcXC0hEf8UP3ZrVoEEDPHz4EA0bNoSjoyOOHj0KT09PXLp0iUdtteDPfYg/+ugjzJkzBxMmTFCuTZw4EV9//TWOHz+O4OBgERF1QlFRESIjI3Hs2DF4e3urzWTgwEvtCQkJQa9evdCoUSO4uLioFXTZO1c7LCws8Pvvv6Nz584q6wqFAjKZjL2itcjb2xsvX76Eg4MDTE1N1d7zPH2kPc7Ozrh9+zbs7OzQvHlzREREwM7ODuvWreM8DJKU5s2bQyaTQSaTqV3nAcDExARr1qwRkEx3JCUlISIiAvr6+tDX18erV6/g4OCAJUuWYNiwYejXr5/oiJK0bt06fPfddxg6dKjoKDpnypQpGDlyJBYsWABTU1PRcSoEC+mVXEZGBlauXImUlBTIZDI0adIEQUFBaNSokehokta0aVOcPXtWbcfQ7t274eHhISgVkfb07dsXJ06cQKtWrRAUFIRBgwYhKioK2dnZLORq2ZEjR7B48WK19W7dumHGjBkCEumOGzduwNPTEwCQmpqq8hh3smhXYGAgTp48iU6dOqFmzZp8vSuIn58fDA0NsW3btnIHXpL2DBo0CA8ePMCCBQv42lewSZMm4eHDhwBeD3Xt1q0bvv/+exgaGuK7774TG45IgzIzM6FQKODg4ICLFy/C2tpa+ZihoSFq1aoFfX19gQmlz8DAQHl9r127NrKzs9GkSRNUr14d2dnZgtNJV1FREdq2bSs6hk568OABJk6cqDNFdICF9ErtyJEj8PX1RfPmzdGuXTsoFAqcO3cOTZs2xc8//4wuXbqIjihZM2fOxNChQ/HgwQPI5XLs3bsXt2/fRnR0NA4cOCA6HpHG/bm1xccff4wGDRrg3LlzcHR0hK+vr8Bk0lezZk3s27cPU6dOVVnfv38/atasKSiVbvhrC7W/c//+fdSrVw96enpaTqQ7oqOj8cMPP7A3cQW7ceMGEhMT4ezsLDqKzjl37hzi4+M56FUAPz8/5c8eHh7IysrCrVu30LBhQ1hZWQlMRqRZZZvA/tqjmCqOh4cHEhIS0LhxY3Tq1AlhYWHIycnBli1blG00SfNGjRqFbdu2sS2mAN26dUNCQoJOtdxlIb0SmzFjBoKDg9V6t86YMQPTp09nIV2LPvzwQ+zcuRMLFiyATCZDWFgYPD09eQODdEbr1q3RunVr0TF0wuzZsxEQEIBTp04pe6SfP38ehw8fRmRkpOB0BAAuLi6cyaBhNWrU4Ok6Aby9vXHv3j0W0gXgoNfKw9TUVHkaicTj6QztSE1NxalTp8od/hcWFiYolfQtWLAAf/zxBwBg7ty5GDZsGMaOHQtHR0ds2rRJcDrpevnyJdavX4/jx4/D3d1drX0a2zVqT69evTB16lQkJyfDzc1N7bWX4qY8mYKNhistY2NjXL9+HU5OTirrqampcHd3x8uXLwUlIxKPw0b/u59++ulfP1eKfwArkwsXLmD16tVISUmBQqGAi4sLJk6ciFatWomORgDMzc1x9epVXm80aNOmTTh8+DA2bdqkU0dBRdu9ezdmzZqFqVOnlvtlx93dXVAy6Tt69Chmz56N+fPnl/vac9CrZk2ePPlfP5cFFrH4N1bzNmzYgLFjx8LKygp16tRRG/7HIbvaoVAokJ2djVq1asHExER0HJ3SqVOnv31MJpMhJiamAtPoljed2JXq/B0W0isxGxsbrFixAp988onK+q5duxASEsIeW6TT+KH7v/u3bSqk+geQ6N/i9UbzPDw8kJGRAYVCATs7O7WiIr/ka0d5132ZTMZhoxWg7LX/6+5bvvba8aaiyp+xwEJSZGtri3HjxmH69Omio+gUuVwOY2Nj3Lx5U20zJBFJB1u7VGKffvopRo8ejTt37qBt27aQyWSIjY3F4sWLMWXKFNHxJKdGjRpITU2FlZUVLC0t33jM8NmzZxWYjMpz6NAh1K9fX3SMtxr7J1YeGRkZ2LRpE+7cuYOVK1eiVq1aOHz4MGxsbNC0aVPR8Yg0rk+fPqIj6KTMzEzREXTWv53JQJrB11u83NxchIWF4eTJk+W2F+H3Ke357bff1Dbjkfbp6enByckJubm5LKQTSRh3pFdiCoUCK1euxPLly/Hrr78CAOrVq4epU6di4sSJ7CenYZs3b8bAgQNhZGSEzZs3v/G5w4YNq6BUuufjjz+Gt7c3ZsyYobK+dOlSXLx4Ebt37xaUjEg7Tp8+jR49eqBdu3Y4c+YMUlJS4ODggCVLluDixYvYs2eP6Ig6jzvSxdm+fTt8fX1RtWpV0VGIKsS4ceMwZ84cDsGkt16PHj2QkZGBgIAA1K5dW+27K79PaU9AQABatGiBMWPGiI6ic3755RcsWrQIa9euhaurq+g4OuXSpUvYvXs3srOzUVRUpPLY3r17BaXSDQUFBTh9+nS5r/3EiRMFpdIeFtLfEmUDK8zNzQUnkb6SkhJ8//336NatG+rUqSM6js6xtrZGTEyM2lTz69ev4/3338fjx48FJZO2OXPmvPFxDiXSnjZt2uCTTz7B5MmTVQq2ly5dQp8+ffDgwQPREXUeZzKIw9de87Zs2YJ169YhMzMT8fHxsLW1xcqVK2Fvb4/evXuLjqfz+J7XvE6dOr1xAxJbu2iHubk5YmNj0axZM9FRdM7ChQuxYsUK9OrVq9yZDFIsbFUWlpaWKCwsRElJCQwNDdV6pfMkhnbs2LED/v7+6Nq1K44dO4auXbsiLS0Njx49Qt++fTnoVYsSExPRs2dPFBYWoqCgADVq1EBOTg5MTU1Rq1Yt3LlzR3REjWNrl0osMzMTJSUlcHJyUimgp6WlwcDAAHZ2duLCSViVKlUwduxYpKSkiI6ik54/fw5DQ0O1dQMDA+Tn5wtIpBv27dun8ntxcTEyMzNRpUoVNGrUiIV0Lbp+/Tq2bdumtm5tbY3c3FwBieivuOdAHL72mrV27VqEhYVh0qRJmD9/vrIvt4WFBVauXMlCeiXA97zmNW/eXOX34uJiJCUl4caNG9wVrUXvvPMOXrx4ITqGTlq/fj3MzMxw+vRpnD59WuUxmUzGQroWrVy5UnQEnbRgwQKEh4dj/PjxMDc3x6pVq2Bvb4/PPvsMdevWFR1P0oKDg/Hhhx9i7dq1sLCwwPnz52FgYIAhQ4YgKChIdDytYCG9Ehs+fDhGjhyp1l/rwoULiIyMxKlTp8QE0wGtWrVCYmIibG1tRUfROa6urti5c6da4XbHjh1wcXERlEr6EhMT1dby8/MxfPhw9O3bV0Ai3WFhYYGHDx/C3t5eZT0xMZFzACqJ5ORk1KtXT3QMov9szZo12LBhA/r06YNFixYp1729vRESEiIwGZH2hIeHl7s+a9YsPH/+vILT6I5vv/0WM2bMQFhYGFxdXdV2RVerVk1QMunjPAxxeHNOjIyMDPTq1QsAYGRkhIKCAshkMgQHB6Nz586YPXu24ITSlZSUhIiICOjr60NfXx+vXr1StikdNmwY+vXrJzqixrGQXoklJiaiXbt2auutW7fGhAkTBCTSHePGjcOUKVNw//59eHl5qfVmdXd3F5RM+kJDQ/HRRx8hIyMDnTt3BgCcOHEC27dvZ3/0ClatWjXMmTMHH3zwAYYOHSo6jmQNHjwY06dPx+7duyGTySCXyxEXF4eQkBD4+/uLjic5/8uHubJ+ijY2NtqKQ1ShMjMz4eHhobZe9qWTSJcMGTIELVu2xLJly0RHkSQLCwv8/vvvys/zZRQKBWQymfJEDGlX2SkXzlerOKWlpdi3bx9SUlIgk8nQpEkT9O7dG1WqsPymLTVq1FC2Q65fvz5u3LgBNzc35OXlobCwUHA6aTMwMFBeX2rXro3s7Gw0adIE1atXR3Z2tuB02sH/kisxmUymvBj82e+//84PHlo2YMAAAKr942QyGT/4VQBfX1/s378fCxYswJ49e2BiYgJ3d3ccP34cHTp0EB1P5+Tl5eH3338XHUPS5s+fj+HDh6N+/fpQKBRwcXFBaWkpBg8ejK+++kp0PMmpXr268meFQoF9+/ahevXq8Pb2BgBcvnwZeXl5ktw9QWRvb4+kpCS1E3eHDh3iqS/SOfHx8TA2NhYdQ7L8/PxgaGiIbdu2lTtslLQrOjoaS5cuRVpaGgCgcePGmDp1KjfHaNmNGzfQu3dvPHr0CM7OzgCA1NRUWFtb46efflKbA0aa0b59exw7dgxubm7o378/goKCEBMTg2PHjuG9994THU/SPDw8kJCQgMaNG6NTp04ICwtDTk4OtmzZItn3O4eNVmIffPABTE1NsX37dujr6wN4fXdzwIABKCgowKFDhwQnlK67d+++8XG2fCGpWb16tcrvCoUCDx8+xJYtW+Dj44Pt27cLSqY7MjIykJiYCLlcDg8PD7W2XqR506dPx7Nnz7Bu3TqVv7Pjxo1DtWrVsHTpUsEJ6c8DeOm/27RpE0JDQ7F8+XIEBAQgMjISGRkZWLhwISIjIzFw4EDREXUe3/Oa99cbo2WfcRISEhAaGoqZM2cKSiZtpqamSExMVBYTqeKsWLECoaGhmDBhAtq1aweFQoG4uDh88803mDdvHoKDg0VHlKzWrVujVq1a2Lx5MywtLQEAv/32G4YPH44nT54gPj5ecEJpevbsGV6+fIl69epBLpdj2bJliI2NhaOjI0JDQ5X/LkjzEhIS8Mcff6BTp054+vQphg0bpnztN23aJMmB0yykV2LJycnw8fGBhYUF2rdvDwA4e/Ys8vPzERMTA1dXV8EJiTTv0qVLkMvlaNWqlcr6hQsXoK+vr9w1Spr11/7cenp6sLa2RufOnfH555+rDDwmzUpLS2PRXBBra2vExsaqfcm/ffs22rZty2GvlYCrqysOHTrE9joatGHDBsybNw/37t0D8PoI9KxZsxAQECA4GQHA2LFjMXfuXFhZWYmOIhkjRoxQ+f3Pn3G6du0qKJX0+fj4ICwsDO+//77oKDrH3t4es2fPVmsRuHnzZsyaNYs91LXIxMQECQkJaNq0qcr6jRs30KJFCw7gJZIAFtIruV9//RVff/01rl69qmxxMWHCBNSoUUN0NMnbsmUL1q1bh8zMTMTHx8PW1hYrV66Evb09evfuLTqeZLVs2RLTpk3Dxx9/rLK+d+9eLF68GBcuXBCUjEg79PT0ULduXXTo0AEdOnRAx44duXurglhaWmLTpk3o06ePyvr+/fsxYsQI/Pbbb2KC6Yi8vDzs2bMHGRkZmDp1KmrUqIErV66gdu3aHLRbAXJyciCXy1GrVi3RUXTG2bNnERERgYyMDOzZswf169fHli1bYG9vj3fffVd0PCKN2r17N2bNmoWpU6fCzc1NbdgoZ05pj7GxMW7cuAFHR0eV9bS0NLi5ueHly5eCkklf8+bNsWLFCrXZADExMQgKCsL169cFJZM+uVyO9PR0PHnyBHK5XOUxHx8fQalIitgjvZKrV68eFixY8MbnjBs3DnPmzOHOFQ1au3YtwsLCMGnSJMyfP1/ZE93CwgIrV65kIV2LkpOT4enpqbbu4eGB5ORkAYl0z7179yCTydCgQQPRUXTCw4cPERMTg9OnTyM8PBxjx45F7dq1lUX1MWPGiI4oWSNGjMDIkSORnp6O1q1bAwDOnz+PRYsWqe1gJM26du0a3n//fVSvXh1ZWVn49NNPUaNGDezbtw93795FdHS06IiSx8+NFeuHH37A0KFD4efnh8TERLx69QoA8Mcff2DBggU4ePCg4ITSl5CQoDL8z8vLS3QkSSubOTVy5EjlGmdOVQxHR0fs2rULX3zxhcr6zp07eQpSC/Lz85U/L1iwABMnTsSsWbNUPlvOmTMHixcvFhVR8s6fP4/Bgwfj7t27+OteYV5vtOvx48cICQnBiRMn8OTJE7XXX4qvPXekS0C1atWQlJTEXooa5OLiggULFqBPnz4qvSpv3LiBjh07IicnR3REyapZsyYOHDiANm3aqKyfO3cOvXr14g5RLSkpKcHs2bOxevVqPH/+HABgZmaGwMBAzJw5U20XEWlPeno65s2bh++//x5yuVySHz4qi7IeiqtWrcLDhw8BAHXr1kVQUBCmTJmi7JtOmvf+++/D09MTS5YsUfk7e+7cOQwePBhZWVmiI0pSbm4uwsLCcPLkyXJ3bD179kxQMunz8PBAcHAw/P39Vd7zSUlJ6N69Ox49eiQ6omTdv38fgwYNQlxcHCwsLAC8PhHTtm1bbN++na2jtIQzp8T54YcfMGDAALz//vto164dZDIZYmNjceLECezatQt9+/YVHVFS9PT0VIbplpXYytb+/Ds/12tH8+bN0bhxY8yePRt169ZVG25cvXp1Qcmkr0ePHsjOzsaECRPKfe2luAmVO9IlgPdCNC8zMxMeHh5q60ZGRigoKBCQSHd06dIFn3/+OX788UflH7y8vDx88cUX6NKli+B00jVhwgTs27cPS5YsUd7EiI+Px6xZs5CTk4N169YJTihdz58/R2xsLE6dOoXTp08jKSkJTZo0QWBgIDp06CA6nqTp6elh2rRpmDZtmnI3UbVq1QSn0g2XLl1CRESE2nr9+vVZUNSiIUOGICMjAwEBAahdu7balx3Sntu3b5d7tLxatWrIy8ur+EA6ZOTIkSguLkZKSoqyddrt27cxcuRIBAQE4OjRo4ITShML5eJ89NFHuHDhAsLDw7F//34oFAq4uLjg4sWL5X7Hpf/m5MmToiPovLS0NOzZs0etnRFpX2xsLM6ePYvmzZuLjlJhWEgnKoe9vT2SkpLUPgAeOnQILi4uglLphuXLl8PHxwe2trbKD3pJSUmoXbs2tmzZIjiddG3fvh07duxAjx49lGvu7u5o2LAhBg4cyEK6FllaWqJGjRoYOnQovvrqK7z77rvcNVGBSkpKcOrUKWRkZGDw4MEAXs8nqVatGszMzASnky5jY2OVo9Blbt++DWtrawGJdENsbCxiY2PRrFkz0VF0Tt26dZGeng47OzuV9djYWJ4q1bKzZ8/i3LlzKvNHnJ2dsWbNGrRr105gMt2QnJyM7OxsFBUVqaz7+voKSqQbvLy8sHXrVtExdML/ZeML2/NqVqtWrZCens5CugA2NjY6t7mXhXSickydOhXjx4/Hy5cvoVAocPHiRWzfvh0LFy5EZGSk6HiSVr9+fVy7dg3ff/+9csjuiBEjMGjQILYX0SJjY2O1L/cAYGdnB0NDw4oPpEN69eqF2NhYbNmyBffu3UN2djY6duyIJk2aiI4meXfv3kX37t2RnZ2NV69eoUuXLjA3N8eSJUvw8uVL3kDSot69e2POnDnYtWsXgNfHnbOzszFjxgx89NFHgtNJ1zvvvIMXL16IjqGTPvvsMwQFBWHjxo2QyWT49ddfER8fj5CQEISFhYmOJ2kNGzZEcXGx2npJSQkHG2vRnTt30LdvX1y/fl3ZGx34f+0u2OJCew4ePAh9fX1069ZNZf3IkSOQy+UqG2dIjK1btyIkJISF9P/g2rVryp8DAwMxZcoUPHr0iMONK9jKlSsxY8YMRERElFtPkCL2SJeAP/dZJM3ZsGED5s2bh3v37gF4XeCdNWsWAgICBCcj0rw5c+bg1q1b2LRpE4yMjAAAr169QkBAAJycnDBz5kzBCaXv2rVrOH36NE6fPo2zZ89CJpOhY8eO2LFjh+hoklU2ByMqKgo1a9ZU/i09ffo0Ro0ahbS0NNERJSs/Px89e/bEzZs38ccff6BevXp49OgR2rRpg4MHD6Jq1aqiI0rSpUuXMGPGDISFhcHV1VXtiyZbG2nXl19+ifDwcLx8+RLA65aBISEhmDt3ruBk0vbjjz9iwYIF+Oabb+Dl5QWZTIaEhAQEBgZi+vTp6NOnj+iIkvThhx9CX18fGzZsgIODAy5evIjc3FxMmTIFy5YtQ/v27UVHlCx3d3csWrQIPXv2VFk/fPgwpk+fjqtXrwpKRmVYw/nvynrT/11Jk8ONtcfS0lKlPWBBQQFKSkpgamqq9tlSivN3WEiXAF6EtSsnJwdyuRy1atUSHUUnREdHv/Fxf3//CkqiW/r27YsTJ07AyMhIeeT/6tWrKCoqwnvvvafy3L1794qIqBMSExNx8uRJnDx5EocPH4ZMJlM7Ck2aY2Vlhbi4ODg7O6v8Lc3KyoKLiwsKCwtFR5S8mJgYXLlyBXK5HJ6ennj//fdFR5K0tLQ0DBo0CImJiSrr/KKpXaWlpYiNjYWbmxuMjY2RnJwMuVwOFxcXtpCqAJaWligsLERJSQmqVHl9ILvs57/etJPiF35RrKysEBMTA3d3d1SvXh0XL16Es7MzYmJiMGXKFLXrEGmOiYkJUlJS1HaHZmVloWnTppz5VQmwhvPf/dNA4z/jzAbN2rx5879+7rBhw7SYRAy2dqnEsrOzYWNjozYISqFQ4N69e2jYsCGA14OjuINIO548eYLbt29DJpNBJpOxb2sFCAoKUvm9uLgYhYWFMDQ0hKmpKQvpWmJhYaHWTsHGxkZQGt0SHh6OU6dO4ezZs/jjjz/QvHlzdOjQAZ999lm5g+lIc+RyebmFw/v378Pc3FxAIt1QUlICY2NjJCUloXPnzujcubPoSDrDz88PhoaG2LZtG4eNVqCyFgspKSmoUaMGvL29RUfSKStXrhQdQSeVlpYqbxRZWVnh119/hbOzM2xtbXH79m3B6aStevXquHPnjlohPT09nSe+SDJYHBdHisXx/wUL6ZWYvb09Hj58qLYT+tmzZ7C3t1d++V+7dq2IeJKWn5+P8ePHY/v27ZDL5QBefwkaMGAAvvnmGw4C1KLffvtNbS0tLQ1jx47F1KlTBSTSDZs2bRIdQWd9//336NixIz799FP4+PjwxmgF6tKlC1auXIn169cDeH0E9Pnz55g5c6bacWjSnCpVqsDW1pa7nwW4ceMGEhMTVYYuUsVwc3PDnTt3YG9vLzqKztH1L/yiuLq64tq1a3BwcECrVq2wZMkSGBoaYv369dyFq2W+vr6YNGkS9u3bh0aNGgF4XUSfMmUKh7ySJC1cuBC1a9fGyJEjVdY3btyIp0+fYvr06YKSSd/fzWQ4evQoSktLJTmTga1dKjE9PT08fvxYbRf03bt34eLiwiNZWtS/f38kJSVhzZo1aNOmDWQyGc6dO4egoCC4u7srh6NRxUlISMCQIUNw69Yt0VEk7enTp8pTGI0bN+YpDJK0X3/9FZ06dYK+vj7S0tLg7e2NtLQ0WFlZ4cyZM2zppUWbNm3C7t27sXXrVtSoUUN0HJ3h4+ODsLAwttAR4OjRo5g+fTrmzp0LLy8vtV2hvImqXaWlpdi/fz9SUlIgk8ng4uICX19f6Ovri44mWUeOHEFBQQH69euHO3fu4IMPPsCtW7dQs2ZN7Ny5k6eRtOj3339H9+7dkZCQgAYNGgB4fdquffv22Lt3LywsLMQGJLZ20TA7Ozts27YNbdu2VVm/cOECBg4ciMzMTEHJpE8XZzKwkF4JTZ48GQCwatUqfPrppzA1NVU+VlpaigsXLkBfXx9xcXGiIkpe1apVceTIEbz77rsq62fPnkX37t15E0OAxMREdOjQAfn5+aKjSFJBQQECAwMRHR2tcgrD398fa9asUbkOkebl5eUhKipK+QW/SZMmCAgI4OmXCvDixQts375dpU+3n58fTExMREeTNA8PD6Snp6O4uBi2trZqRcUrV64ISiZtu3fvxqxZszB16lS4ubmpDYRyd3cXlEz69PT0lD//uaUO+9NrX3p6Onr27IkHDx7A2dkZCoUCqampsLGxwS+//KLcsUva9+zZM7UhdaQdCoUCx44dw9WrV2FiYgJ3d3e2DKxExo4di7lz58LKykp0FEkwNjZGSkqK2qmvO3fuwMXFRTnkmzRPF2cysLVLJVQ2eEWhUOD69eswNDRUPmZoaIhmzZohJCREVDydULNmzXILWNWrV4elpaWARLrjp59+UvldoVDg4cOH+Prrr9GuXTtBqaRv8uTJOH36NH7++Wfl6xwbG4uJEydiypQpbCGlRQkJCejWrRtMTEzQsmVLKBQKhIeHY8GCBTh69Cg8PT1FR5Q0ExMTjBw5Uu0oKGlXnz59REfQSQMGDAAAlfe7TCZjMbcCnDx5UnQEnTVx4kQ0atQI58+fV56Ayc3NxZAhQzBx4kT88ssvghNKW3p6OjIyMuDj44MaNWqA+/gqhkwmQ9euXdG1a9e/fY6bmxsOHjzIuUhaUFhYiOzsbBQVFamsl92w5ncrzbKxsUFcXJxaIT0uLg716tUTlEo36OJMBu5Ir8RGjBiBVatW8ainAOvXr8fu3bsRHR2NunXrAgAePXqEYcOGoV+/fvjss88EJ5SuP+/YAqAc8tq5c2csX75c+e+DNMvKygp79uxBx44dVdZPnjyJ/v374+nTp2KC6YD27dvD0dERGzZsQJUqr+9vl5SUYNSoUbhz5w7OnDkjOKG0paam4tSpU3jy5InyNEaZsLAwQamItOPu3btvfJyDu0iKqlativPnz8PNzU1l/erVq2jXrh2eP38uKJm05ebmon///jh58iRkMhnS0tLg4OCAgIAAWFhYYPny5aIj6jy2F9G8p0+fYsSIETh06FC5j/OGtXYsXrwYS5cuxdKlS5Vto06cOIFp06ZhypQp+PzzzwUnlK7Ro0fj/PnzajMZPvroI7Ro0QKRkZGCE2oed6RXYhz+J87atWuRnp4OW1tbNGzYEACQnZ0NIyMjPH36FBEREcrn8vi5Zv21kEUVo7CwELVr11Zbr1WrFgoLCwUk0h0JCQkqRXTg9TDGadOmwdvbW2Ay6duwYQPGjh0LKysr1KlTR+WouUwmYyGdJOffFsp79eqFyMhI3rzWoH+6KcqWC9pjZGSEP/74Q239+fPnKid/SbOCg4NhYGCA7OxsNGnSRLk+YMAABAcHs5BOkjRp0iT89ttvOH/+PDp16oR9+/bh8ePHmDdvHt/zWjRt2jQ8e/YM48aNU54CMDY2xvTp01lE17KlS5eie/fueOedd9RmMixbtkxwOu1gIb2S6devH7777jtUq1YN/fr1e+Nz9+7dW0GpdA+PnFcepaWluH79OmxtbdlWR4vatGmDmTNnIjo6GsbGxgBe946ePXs22rRpIzidtFWrVg3Z2dl45513VNbv3bsHc3NzQal0w7x58zB//nxMnz5ddBSdo6en98YeudyxJdaZM2fw4sUL0TEk5a8nvgDVXul8z2vPBx98gNGjRyMqKgotW7YE8HoA3ZgxY+Dr6ys4nXQdPXoUR44cURZWyjg5Of3j6Riit1VMTAx+/PFHtGjRAnp6erC1tUWXLl1QrVo1LFy4EL169RIdUZJkMhkWL16M0NBQpKSkwMTEBE5OTjAyMlJ53v3791GvXj21U/D0f1e9enWcO3dOp2YysJBeyVSvXl35oZpD5sSZOXOm6Ag6a9KkSXBzc0NAQABKS0vh4+OD+Ph4mJqa4sCBA+V+EaX/btWqVejevTsaNGiAZs2aQSaTISkpCcbGxjhy5IjoeJI2YMAABAQEYNmyZWjbti1kMhliY2MxdepUDBo0SHQ8Sfvtt9/wySefiI6hk/bt26fye3FxMRITE7F582bMnj1bUCoi7fntt99Ufi97z4eGhmL+/PmCUumG1atXY9iwYWjTpo1ywG5JSQl8fX2xatUqwemkq6CgoNxh9Tk5OWrFLSKpKCgoQK1atQAANWrUwNOnT9G4cWO4ubnxJHsFMDMzQ4sWLf72cRcXFyQlJbGdkYbp2kwGFtIrmT+3c2FrF3GOHz+O999/v9zHIiIi2CNdi/bs2YMhQ4YAAH7++WdkZWXh1q1biI6Oxpdffom4uDjBCaXJ1dUVaWlp2Lp1K27dugWFQoGBAwfCz88PJiYmouNJ2rJlyyCTyeDv74+SkhIAgIGBAcaOHYtFixYJTidtn3zyCY4ePYoxY8aIjqJzevfurbb28ccfo2nTpti5cycCAgIEpCLSnvI2yHTp0gVGRkYIDg7G5cuXBaTSDRYWFvjxxx+RlpaGlJQUAK+LKY6OjoKTSZuPjw+io6Mxd+5cAK8LLXK5HEuXLkWnTp0EpyPSDmdnZ9y+fRt2dnZo3rw5IiIiYGdnh3Xr1rFdWiXAEZHiZGVlobi4WHQMjeCwUaJyGBkZYcKECVi4cKGyd+LTp08xcuRIxMXF4dmzZ4ITSpexsTHS09PRoEEDjB49Gqampli5ciUyMzPRrFkz5Ofni45IpBWFhYXIyMiAQqGAo6Njubu46L9bvXq18ueCggKsWLECvXr1gpubm3KnYpmJEydWdDydl5GRAXd3dxQUFIiOotM4gK7ipKSkoEWLFhx4WUHKvvq+qbUUaUZycjI6duwILy8vxMTEwNfXFzdv3sSzZ88QFxenHEpH4vBar3nff/89iouLMXz4cCQmJqJbt27Izc2FoaEhvvvuOwwYMEB0RJ3G97w4UnrtuSO9EsvNzUVYWBhOnjyJJ0+eqA1hZDFXe86cOYOhQ4fi+PHj2LZtG7KysjBy5Ei4uLjg6tWrouNJWu3atZGcnIy6devi8OHD+PbbbwG8LjLq6+sLTidtt2/fxpo1a5CSkgKZTIZ33nkHEyZMUOvdTdphamoKNzc30TEkLzw8XOV3MzMznD59GqdPn1ZZl8lkLKRXsBcvXmDNmjVq/XSJpODatWsqvysUCjx8+BCLFi1Cs2bNBKXSHVFRUQgPD0daWhqA1326J02ahFGjRglOJl0uLi64du0a1q5dC319fRQUFKBfv34YP348d+ZWEhEREahdu7boGJLi5+en/NnDw0N5urphw4awsrISmIyINIWF9EpsyJAhyMjIQEBAAGrXrs2dExWoVatWSExMxJgxY+Dl5QW5XI558+Zh6tSp/PegZSNGjED//v1Rt25dyGQydOnSBcDroVAs6GrPnj17MGjQIHh7eyuHi54/fx5ubm7Ytm0b+0hr2D8Nk/4zDpbWrMzMTNERCIClpaXK31OFQoE//vgDpqam2Lp1q8BkRNrRvHlzyGQytWPlrVu3xsaNGwWl0g2hoaEIDw9HYGCg8jNOfHw8goODkZWVhXnz5glOKE3Z2dmwsbEpd+5FdnY2GjZsKCCVdP35xN0/KdsoMHjwYG3F0UnFxcVwdnbGgQMH4OLiAuD1RhlPT0/ByYhIk1hIr8RiY2MRGxvLXSqC3L59G5cuXUKDBg3w66+/4tatWygsLETVqlVFR5O0WbNmwdXVFffu3cMnn3yiHEakr6+PGTNmCE4nXdOmTcPnn3+OOXPmqKzPnDkT06dPZyFdwzhMmnTdypUrVX7X09ODtbU1WrVqBUtLSzGhSOmLL75AjRo1RMeQlL/exCt7zxsbGwtKpDvWrl2LDRs2qAzw9vX1hbu7OwIDA1lI1xJ7e3s8fPhQOXixTG5uLuzt7VFaWioomTT99cTd3+GJO+0xMDDAq1evuPGuEuO/G9IE9kivxFq0aIE1a9agdevWoqPonEWLFmHmzJkYPXo0li5dioyMDAwZMgT5+fnYunWrcjcLiSOlqc+VgampKa5du6Y2eCstLQ3NmjVDYWGhoGRE2vPxxx/D29tb7Sbd0qVLcfHiRezevVtQMiLtefDgAeLi4sptG8jiCkmRpaUlLl68CCcnJ5X11NRUtGzZEnl5eWKCSZyenh4eP34Ma2trlfW7d+/CxcWFszBIkhYtWoRbt24hMjISVapw32plI6U+3W8bKb32/C+7Evv2228xY8YMhIWFwdXVVW0IWrVq1QQlk75Vq1Zh//796NGjBwCgadOmuHjxIr744gt07NgRr169EpyQpDT1uTLo2LEjzp49q1ZIj42NRfv27QWlItKu06dPY+bMmWrr3bt3x7JlywQk0i15eXm4ePFiuQVdf39/QamkbdOmTRgzZgwMDQ1Rs2ZNlZ1Z3KWofSdOnMCJEyfKfc+zvYv2DBkyBGvXrsWKFStU1tevX6/Sz5g0Y/LkyQBeX1NCQ0NVhqeXlpbiwoULaN68uaB0RNp14cIFnDhxAkePHoWbm5vaaXa2bKwY+fn5iImJgbOzM5o0aaJcT05ORr169QQm0w15eXmwsLBQWZPSTAYW0isxCwsL/P777+jcubPKukKhgEwm43E4Lbp+/braMBADAwMsXboUH3zwgaBURNrj6+uL6dOn4/Lly8pTMOfPn8fu3bsxe/Zs/PTTTyrPpf/Gw8PjXx8tvHLlipbT6K7nz5/D0NBQbd3AwAD5+fkCEumOn3/+GX5+figoKIC5ublaQZeFdO0ICwtDWFgYPv/8c+jp6YmOo1Nmz56NOXPmwNvbWzkHhipOVFQUjh49qvIZ5969e/D391cWfgGoFdvpf5eYmAjg9XfW69evq/ydNTQ0RLNmzRASEiIqns64f/8+fvrpJ2RnZ6OoqEjlMb7PtcfCwgIfffSR6Bg6p3///vDx8cGECRPw4sULeHt7IysrCwqFAjt27FD+O+Fpds1bvHgx7OzsMGDAAACv/1388MMPqFOnDg4ePKhsVS2lmQxs7VKJtWzZElWqVEFQUFC5w0Y7dOggKJluyMvLw549e5CRkYGpU6eiRo0auHLlCmrXro369euLjqfzpHQ0qDL4twUV3sTTjPIGb/2d8nZMk2a0aNECH374IcLCwlTWZ82ahZ9//hmXL18WlEz6GjdujJ49e2LBggUquxVJu2rWrImLFy+iUaNGoqPonLp162LJkiUYOnSo6Cg6p1OnTv/qeTKZDDExMVpOoztGjBiBVatW/eMp6vv376NevXq8uadBJ06cgK+vL+zt7XH79m24uroqi4qenp58n5Pk1KlTB0eOHEGzZs2wbds2zJw5E1evXsXmzZuxfv165Q0+0jwHBwds3boVbdu2xbFjx9C/f3/s3LkTu3btQnZ2No4ePSo6osaxkF6JmZqaIjExEc7OzqKj6Jxr167h/fffR/Xq1ZGVlYXbt2/DwcEBoaGhuHv3LqKjo0VH1HkspBPRf/XTTz/ho48+wuDBg5Wnv06cOIHt27dj9+7d6NOnj9iAEla1alVcv36d1/AKNm3aNNSoUYPDuwXgTYzKjwVdMapVq4akpCT+PdCgli1bonv37pgzZ47yO1OtWrXg5+eH7t27Y+zYsaIjSlbnzp2xd+9etbYW+fn56NOnD29iaImJiQlSU1NhY2MDf39/1KtXD4sWLUJ2djZcXFzw/Plz0REl68+vfVBQEF6+fImIiAikpqaiVatW+O2330RH1Dh+SqjEvL29ce/ePdExdNLkyZMxfPhwpKWlwdjYWLneo0cPnDlzRmAyIrHc3Nx4XdKSy5cvY+vWrfj++++5a6KC+Pr6Yv/+/UhPT8e4ceMwZcoU3L9/H8ePH2cRXcu6deuGhIQE0TF0zsKFC3H69Gl07NgRgYGBmDx5sso/pD2jRo3Ctm3bRMegN3BxcUFWVpboGDqH+/o0LyUlBcOGDQMAVKlSBS9evICZmRnmzJmDxYsXC04nbadOnVJrpQMAL1++xNmzZwUk0g02NjaIj49HQUEBDh8+jK5duwIAfvvtN5V6DmmepaWlsj5w+PBhvP/++wBeX9ulepKdPdIrscDAQAQFBWHq1Klwc3NTGzbq7u4uKJn0Xbp0CREREWrr9evXx6NHjwQkIqocOORV8548eYKBAwfi1KlTsLCwgEKhwO+//45OnTphx44dsLa2Fh1R0nr16oVevXqJjqFzevXqhalTpyI5ObnczzicxaAdCxYswJEjR5SnHf/am5605+XLl1i/fj2OHz8Od3d3tfc8exaLx4IuSUXVqlXx6tUrAEC9evWQkZGBpk2bAgBycnJERpOsa9euKX9OTk5WqRmUlpbi8OHDbA+rRZMmTYKfnx/MzMzQsGFDdOzYEQBw5swZuLm5iQ0ncf369cPgwYPh5OSE3Nxc9OjRAwCQlJQER0dHwem0g4X0SqysWf/IkSOVazKZjMNGK4CxsXG5g+Zu377NopYAUp/6TLotMDAQ+fn5uHnzpnKqfHJyMoYNG4aJEydi+/btghNKl4ODAy5duoSaNWuqrOfl5cHT0xN37twRlEz6Pv30UwDAnDlz1B7jZxztWbFiBTZu3Ijhw4eLjqJzrl27hubNmwMAbty4ofIYb2IQkSa1bt0acXFxcHFxQa9evTBlyhRcv34de/fuVQ7cJc1q3rw5ZDIZZDKZsl3gn5mYmGDNmjUCkumGcePGoWXLlrh37x66dOmibNHl4OCAefPmCU4nbeHh4bCzs8O9e/ewZMkSmJmZAQAePnyIcePGCU6nHeyRXondvXv3jY/b2tpWUBLdM3r0aDx9+hS7du1CjRo1cO3aNejr66NPnz7w8fHBypUrRUeUrH879ZnEYG96zatevTqOHz+OFi1aqKxfvHgRXbt2RV5enphgOkBPTw+PHj1CrVq1VNYfP36Mhg0bKndzEUlFnTp1cPbsWTg5OYmOQlTp8DOOGHzdNe/OnTt4/vw53N3dUVhYiJCQEMTGxsLR0RHh4eGsI2jB3bt3oVAo4ODggIsXL6psvjM0NEStWrWgr68vMKFuKCoqQmZmJho1aoQqVbhvmLSD76xKjH/gxFm2bBl69uyJWrVq4cWLF+jQoQMePXqENm3aYP78+aLjSVpERAS2bt0KADh27BiOHTuGQ4cOYdeuXZg6daokpz6TbpPL5WpH/AHAwMAAcrlcQCLp++mnn5Q/HzlyBNWrV1f+XlpaihMnTsDOzk5AMt308uVL9q+sIEFBQVizZg1Wr14tOorOSk9PR0ZGBnx8fGBiYqI8aUqkq/j+17w/35QwNTXFt99+KzCNbiir3fCzuxiFhYUIDAzE5s2bAQCpqalwcHDAxIkTUa9ePQ5Z17ItW7YgIiICd+7cQXx8PGxtbbFy5UrY29ujd+/eouNpHAvpldyDBw8QFxeHJ0+eqF2UJ06cKCiV9FWrVg2xsbGIiYnBlStXIJfL4enpqRycQNrz8OFD2NjYAAAOHDiA/v37o2vXrrCzs0OrVq0EpyPSvM6dOyMoKAjbt29HvXr1ALy+9gcHB+O9994TnE6aygaJymQy5TCuMgYGBrCzs8Py5csFJNMdpaWlWLBgAdatW4fHjx8rv/CEhobCzs4OAQEBoiNK0sWLFxETE4MDBw6gadOmajfx9u7dKyiZ9OXm5qJ///44efIkZDIZ0tLS4ODggFGjRsHCwoLXnEqABV0xeEBee4qKisqtIzRs2FBQIt2QmpqKU6dOlfvah4WFCUolbZ9//jmuXr2KU6dOoXv37sr1999/HzNnzmQhXYvWrl2LsLAwTJo0CfPnz1e2Z7SwsMDKlStZSKeKtWnTJowZMwaGhoaoWbOm2kAoFtK1r3PnzuX2OCvj5uaGgwcPKgu/9N+VTX22sbHB4cOHlT3NpDz1mXTb119/jd69e8POzg42NjaQyWTIzs6Gm5ub8nQGaVbZlxp7e3tcunQJVlZWghPpnvnz52Pz5s1YsmSJsl868Prvanh4OAvpWmJhYYF+/fqJjqGTgoODYWBggOzsbOU8DOD1TKTg4GAW0isBFnQ1p6SkBMbGxkhKSoKrq+sbn5ucnKzcSECakZqaioCAAJw7d05lnbPWtG/Dhg0YO3YsrKysUKdOHbUaDgvp2rF//37s3LkTrVu3VnnNXVxckJGRITCZ9K1ZswYbNmxAnz59sGjRIuW6t7c3QkJCBCbTHhbSK7GwsDCEhYXh888/Vw5LoMolKysLxcXFomNIii5Ofa6sOOS1YtjY2ODKlSs4duwYbt26BYVCARcXF56AqQCZmZmiI+is6OhorF+/Hu+99x7GjBmjXHd3d8etW7cEJpO2TZs2iY6gs44ePYojR46gQYMGKutOTk7/OBeJ/u9Y0BWjSpUqsLW1/VcFW25I0rwRI0agSpUqOHDgAOrWrcvTFhVo3rx5mD9/PqZPny46ik55+vSp2swjACgoKOD7X8syMzPh4eGhtm5kZISCggIBibSPhfRKrLCwEAMHDmQRnXRKeHg47O3tkZ2drTNTnyuDfzvkdfDgwSJjSkaNGjWQmpoKKysrjBw5EqtWrUKXLl3QpUsX0dF0TkFBAU6fPo3s7GwUFRWpPMaTX9rz4MGDcm+OyuVy3qAmSSooKICpqanaek5ODoyMjAQk0g0s6Irz1Vdf4fPPP8fWrVtRo0YN0XF0SlJSEi5fvox33nlHdBSd89tvv+GTTz4RHUPntGjRAr/88gsCAwMB/L9WXRs2bECbNm1ERpM8e3t7JCUlqc14PHToEFxcXASl0i4W0iuxgIAA7N69m/2cSGcUFxdj9OjRCA0NVRmSAwCTJk0SE0pHcMhrxSoqKkJ+fj6srKywefNmLF68GObm5qJj6ZzExET07NkThYWFKCgoQI0aNZCTkwNTU1PUqlWLhXQtatq0Kc6ePav2oXv37t3l7mohzdmzZw927dpV7s2jK1euCEolfT4+PoiOjsbcuXMBvP6SL5fLsXTpUnTq1ElwOmljQVeM1atXIz09HfXq1YOtrS2qVq2q8jivN9rj4uKCnJwc0TF00ieffIKjR4+qnLYj7Vu4cCG6d++O5ORklJSUYNWqVbh58ybi4+Nx+vRp0fEkberUqRg/fjxevnwJhUKBixcvYvv27Vi4cCEiIyNFx9MKFtIrsYULF+KDDz7A4cOH4ebmpjYQasWKFYKSEWmHgYEB9u3bh9DQUNFRdA6HvFasNm3aoE+fPvDy8oJCocDEiRNhYmJS7nM3btxYwel0R3BwMD788EOsXbsWFhYWOH/+PAwMDDBkyBAEBQWJjidpM2fOxNChQ/HgwQPI5XLs3bsXt2/fRnR0NA4cOCA6nmStXr0aX375JYYNG4Yff/wRI0aMQEZGBi5duoTx48eLjidpS5cuRceOHZGQkICioiJMmzYNN2/exLNnzxAXFyc6nqSxoCtG2WBvqniLFy/GtGnTsGDBgnLrCNWqVROUTPocHR0RGhqK8+fPl/vac5OGdrRt2xZxcXFYtmwZGjVqhKNHj8LT0xPx8fFwc3MTHU/SRowYgZKSEkybNg2FhYUYPHgw6tevj1WrVmHgwIGi42mFTMGpKpXW3LlzMXPmTDg7O6N27dpqgypiYmIEpiMAMDc3x9WrV9V2T9P/3YgRI+Dm5obJkyeLjqJT6tWrhz179qBt27ZwdnbGvHnz8Mknn+D27dto0aIF8vPzRUeUlMePHyM8PBwZGRnYu3cvunXr9rdH+/ft21fB6XSHhYUFLly4AGdnZ1hYWCA+Ph5NmjTBhQsXMGzYMPbq1rIjR45gwYIFuHz5MuRyOTw9PREWFoauXbuKjiZZ77zzDmbOnIlBgwapfIYJCwvDs2fP8PXXX4uOKGmPHj3C2rVrVd7z48ePR926dUVHk7TZs2e/8fGZM2dWUBKiilHWGvavvaE5bFT77O3t//YxmUyGO3fuVGAaooqVk5MDuVxebr96KWEhvRKztLREeHg4hg8fLjoK/Q0W0jVv/vz5WLZsGd577z14eXmp7RriXXztmDBhAg4cOAAnJyckJiYiKysLZmZm2LlzJxYvXszdWlpkb2+PhIQE1KxZU3QUnWNtbY24uDg0btwYzs7OWL16Nbp164Zbt27B09MThYWFoiMSaZSpqSlSUlJga2uLWrVq4dixY2jWrBnS0tLQunVr5Obmio4oWdnZ2bCxsSl36Fl2djYaNmwoIBWR9iUkJCAlJQUymQxNmjSBl5eX6EiS90+tLDp06FBBSYi053/Z6MVTGKRJbO1SiRkZGaFdu3aiY9D/Ly8vDxYWFiprERERqF27tphAEhUZGQkLCwtcvnwZly9fVnlMJpOxkK4lHPIqTmZm5r96npubGw4ePMhhaBrk4eGBhIQENG7cGJ06dUJYWBhycnKwZcsWHgPVMgcHB1y6dEntBlJeXh48PT25Y0tL6tSpg9zcXNja2sLW1hbnz59Hs2bNkJmZCe6t0S57e3s8fPhQbZdWbm4u7O3tuUO0ArCgW7Hu37+PQYMGIS4uTvkdKi8vD23btsX27dv5eUZLiouLMWvWLERERKBx48ai4+iEyZMnY+7cuahateobT1XLZDIsX768ApNJm4WFRbk3p/+MpzC07/HjxwgJCcGJEyfw5MkTtc+TUnztWUivxIKCgrBmzRqsXr1adBSds3jxYtjZ2WHAgAEAgP79++OHH35AnTp1cPDgQTRr1gwAMHjwYJExJenPRcWyi/A//YGk/4ZDXt8OWVlZKC4uFh1DUhYsWIA//vgDwOt2asOGDcPYsWPh6OiITZs2CU4nbVlZWeV+sH716hUePHggIJFu6Ny5M37++Wd4enoiICAAwcHB2LNnDxISEtCvXz/R8SSt7Mv8Xz1//hzGxsYCEukOFnTFGDlyJIqLi5GSkgJnZ2cAwO3btzFy5EgEBARwkL2WGBgY4MaNG/z+VIESExOVn9ETExP/9nn8d6JZJ0+eFB2BAAwfPhzZ2dkIDQ1F3bp1deJ9ztYulVjfvn0RExODmjVromnTpmqDKvbu3SsomfQ5ODhg69ataNu2LY4dO4b+/ftj586d2LVrF7Kzs/nBT8uioqIQHh6OtLQ0AICTkxMmTZqEUaNGCU4mXRYWFrhy5QrbFFVibCVFUvDTTz8BeD2EbvPmzahevbrysdLSUpw4cQLHjh3D7du3RUWUNLlcDrlcjipVXu+l2bVrF2JjY+Ho6IgxY8bA0NBQcELpKduduGrVKnz66acwNTVVPlZaWooLFy5AX1+fA0e1qGvXrsjPz8fmzZvVCrpVq1bl53otMTExwblz5+Dh4aGyfuXKFbRr1w4vXrwQlEz6pkyZAgMDAyxatEh0FCKSOHNzc5w9exbNmzcXHaXCcEd6JWZhYcHdQYI8fPhQuTvlwIED6N+/P7p27Qo7Ozu0atVKcDppCw0NRXh4OAIDA9GmTRsAQHx8PIKDg5GVlYV58+YJTihNffv2xf79+znklXTKhg0b0LFjRzg5OYmOojP69OkD4PWurGHDhqk8ZmBgADs7Ox571iI9PT3lEDrg9Ym7/v37C0wkfWW7ExUKBa5fv65ys8LQ0BDNmjVDSEiIqHg64ezZszh37pyyiA4Azs7OWLNmDdtoalHDhg3LPUlXUlKC+vXrC0ikO4qKihAZGYljx47B29tbbebUihUrBCUj0pxr167B1dUVenp6uHbt2huf6+7uXkGpdI+NjY3OtQdkIb0S47FycSwtLXHv3j3Y2Njg8OHDyuKtQqGQZI+nymTt2rXYsGEDBg0apFzz9fWFu7s7AgMDWUjXEkdHR8ydOxfnzp3jkFfSGcuXL8eYMWNQu3ZtdOjQAR07dkSHDh3wzjvviI4mWXK5HMDrftGXLl2ClZWV4ES65+zZs4iIiEBGRgb27NmD+vXrY8uWLbC3t8e7774rOp7klB09HzFiBFatWvWPA8/u37+PevXqqdzwoP+GBV0xlixZgsDAQHzzzTfw8vKCTCZDQkICgoKCsGzZMtHxJO3GjRvw9PQEAKSmpqo8pgttF0g3NG/eHI8ePUKtWrXQvHlzyGSycgu67JGuXStXrsSMGTMQEREBOzs70XEqBFu7vAWePn2K27dvQyaToXHjxrC2thYdSfImTJiAAwcOwMnJCYmJicjKyoKZmRl27tyJxYsX48qVK6IjSpalpSUuXryotkM0NTUVLVu2RF5enphgEmdvb/+3j8lkMg7+qwTY2kU7Hj16hJMnT+L06dM4deoU0tLSYG1tjY4dO2LHjh2i4+k8DtnVrB9++AFDhw6Fn58ftmzZguTkZDg4OODbb7/FgQMHcPDgQdERdV61atWQlJTEa70G/fjjj1iwYIFaQTcwMBDTp09XnpQhzbK0tERhYSFKSkqU7aTKfv7rho1nz56JiEhEb7G7d++iYcOGkMlkuHv37hufa2trW0GpdM+fr/WmpqZqLamleH1nIb0SKygoQGBgIKKjo5U7uPT19eHv7481a9ao9FgkzSouLsbq1auRnZ2N4cOHK3v7rVy5EmZmZuzVrUWBgYEwMDBQO3IYEhKCFy9e4JtvvhGUTHdwyGvlxEK6dhUUFCA2NhY7duzA1q1boVAoUFJSIjqWzuP7XrM8PDwQHBwMf39/ldc2KSkJ3bt3x6NHj0RH1Hl8z2seC7pibN68+V8/96+tvkgz0tPTkZGRAR8fH5iYmPzt0GOit5GnpydOnDgBS0tLzJkzByEhIayRCfBP13opXt9ZSK/EPvvsMxw/fhxff/21sn9fbGwsJk6ciC5dumDt2rWCE0pTcXExRo8ejdDQUH6JEaDs5pGNjQ1at24NADh//jzu3bsHf39/lTuc7O+nWRzyWnnk5eXBwsJCZW3btm3o3bu32pd++r87dOiQcif61atX0bRpU/j4+KBjx45o3749LC0tRUfUeSwqapapqSmSk5NhZ2en8treuXMHLi4uePnypeiIOo/vec1jQbdyW7RoEcaMGaP2uYf+73Jzc9G/f3+cPHkSMpkMaWlpcHBwQEBAACwsLDiLhCTBxMQEaWlpaNCgAfT19fHw4UPUqlVLdCzSAeyRXon98MMP2LNnDzp27Khc69mzJ0xMTNC/f38W0rXEwMAA+/btQ2hoqOgoOunPPf0yMjIAANbW1rC2tsaNGzeUz+NuCs3ikFdxFi9eDDs7OwwYMADA6+F/P/zwA+rUqYODBw+iWbNmAIDBgweLjClJvXr1grW1NaZMmYIjR46gevXqoiMRaVXdunWRnp6u1sMyNjaWhVuSrH9bHF+0aFG5N7JJuxYsWID+/fvzddeg4OBgGBgYIDs7G02aNFGuDxgwAMHBwSykkyQ0b94cI0aMwLvvvguFQoFly5bBzMys3OeGhYVVcDppy8/PV858yc/Pf+Nz/2k2zNuIO9IrMVNTU1y+fFnljx8A3Lx5Ey1btkRBQYGgZNI3YsQIuLm5YfLkyaKjEFUIKysrrFmzRmXIKwBs374dgYGByMnJEZRM+hwcHLB161a0bdsWx44dQ//+/bFz507s2rUL2dnZOHr0qOiIkrVy5UqcOXMGZ8+ehb6+vnLgaMeOHdX+9pIY3J2rWUuWLMHmzZuxceNGdOnSBQcPHsTdu3cRHByMsLAwTJgwQXREncf3vDjsTy8G3/OaV6dOHRw5cgTNmjVTeX0zMzPh5uaG58+fi45I9J/dvn0bM2fOREZGBq5cuQIXFxdl+64/k8lknHGnYX8+AaCnp1fuJseyVlJSHPTKHemVWJs2bTBz5kxER0fD2NgYAPDixQvMnj1buWOUtMPR0RFz587FuXPn4OXlpdZKYeLEiYKSEWlHaWkpvL291da9vLzYJ1rLHj58qBykeODAAfTv3x9du3aFnZ0dWrVqJTidtE2aNAmTJk0CAFy/fh2nT5/G8ePHERQUhJo1a+Lhw4diAxJp2LRp0/D777+jU6dOePnyJXx8fGBkZISQkBAW0SsJnrgTh/vLSCoKCgrK7RWdk5MDIyMjAYmINM/Z2Rk7duwAAOjp6eHEiRNs7VJBYmJiUKNGDQDAyZMnBaepeCykV2IrV65Ejx490KBBAzRr1gwymQxJSUkwMjLiDkUti4yMhIWFBS5fvozLly+rPCaTyVhIJ8kZMmQI1q5dq9Z3fv369fDz8xOUSjdYWlri3r17sLGxweHDh5VtdBQKhSTv4FdGiYmJOHXqFE6ePImzZ89CLpejQYMGomMRacX8+fPx5ZdfIjk5GXK5HC4uLn97FJoqHou5RPRf+fj4IDo6GnPnzgXw+vurXC7H0qVL0alTJ8HpiDRPLpf/q+f16tULkZGRqFu3rpYTSVuHDh3K/VlXsJBeibm5uSEtLQ1bt27FrVu3oFAoMHDgQPj5+cHExER0PEnLzMxU/lz2hYY7hEjqoqKicPTo0XKHvP65zRGHvGpWv379MHjwYDg5OSE3Nxc9evQAACQlJcHR0VFwOmnz9fVFbGws8vPz0bx5c3Ts2BGjR4+Gj4+PJPv5VXbl9SaOiIhA7dq1xQSSoJEjR2LVqlUwNzdXOYVUUFCAwMBAbNy4UWA66SopKYGxsTGSkpLg6ur6xucmJyejXr16FZSMiKRo6dKl6NixIxISElBUVIRp06bh5s2bePbsGeLi4kTHIxLmzJkzePHihegYb71r16796+e6u7trMYkY7JFeiS1cuBC1a9fGyJEjVdY3btyIp0+fYvr06YKS6YaoqCiEh4cjLS0NAODk5IRJkyZh1KhRgpMRad6/3Z0ik8kQExOj5TS6pbi4GKtXr0Z2djaGDx8ODw8PAK9PJZmZmfGao0UhISHo2LEjC+cC/Nshu6RZf+5p+Wc5OTmoU6cOW3lpUaNGjbB3716+tysx9uoWg6+7djx69Ahr167F5cuXIZfL4enpifHjx3MnLuk0Xm80o6wv+j+Vk6XaI52F9ErMzs4O27ZtQ9u2bVXWL1y4gIEDB6rsmibNCg0NRXh4OAIDA5X96OPj4/H1118jKChI2XqBiOi/KC4uxujRoxEaGsoPdJWYm5sbDh48qOxlT/8dh+xWrPz8fCgUClhaWiItLQ3W1tbKx0pLS/Hzzz9jxowZ+PXXXwWmlLZNmzZh9+7d2Lp1q7KvKFUuLLCI0bNnT0RFRbHAq0HZ2dmwsbEp90R1dnY2GjZsKCAVkXi8zmvG3bt3//VzbW1ttZhEDBbSKzFjY2OkpKTA3t5eZf3OnTtwcXHBy5cvBSWTPisrK6xZswaDBg1SWd++fTsCAwORk5MjKBkRSY2FhQWuXLnCD3SVGD90a56JiQlSU1NhY2ODoKAgvHz5EhEREUhNTUWrVq3w22+/iY4oKWU7h/6OTCbD7Nmz8eWXX1ZgKt3i4eGB9PR0FBcXw9bWVm2Q/ZUrVwQlozIs6GpeaWkp9u/fj5SUFMhkMjRp0gS9e/eGvr6+6GiS9nenj3Jzc1GrVi1J7hAl+jf4mV4cKfWnZ4/0SszGxgZxcXFqhfS4uDj2TtSy0tJSld6hZby8vHjsmYg0qm/fvti/f79KH3oiqeOQ3Yp18uRJKBQKdO7cGT/88IPKjmhDQ0PY2trys6WW9enTR3QEnfZvCroHDx4UmFB60tPT0atXL9y/fx/Ozs5QKBTKG6i//PILGjVqJDqiZCkUinJvnj5//hzGxsYCEhGRrpNSf3oW0iuxUaNGYdKkSSguLkbnzp0BACdOnMC0adMwZcoUwemkbciQIVi7dq3aUMX169fDz89PUCoikiJHR0fMnTsX586dg5eXl9ouxYkTJwpKRqQ9HLJbsTp06ADg9TD1hg0b/uMA9XHjxmHOnDmwsrKqiHg6YebMmaIj6CwWdMWYOHEiHBwcEB8fr7x5l5ubiyFDhmDixIn45ZdfBCeUnrJNGTKZDKGhoTA1NVU+VlpaigsXLqB58+aC0hERSQNbu1RiCoUCM2bMwOrVq1FUVATgdbuX6dOnIywsTHA6aQsMDER0dDRsbGzQunVrAMD58+dx7949+Pv7w8DAQPncvxbbiYj+F389dfRnMpkMd+7cqcA0VB4eA9U8Dtmt3KpVq4akpCS+57UgISFBZVe0l5eX6EiS17NnTygUCnz//fdqBV09PT0WdLWkatWqOH/+PNzc3FTWr169inbt2uH58+eCkklXp06dAACnT59GmzZtYGhoqHzM0NAQdnZ2CAkJgZOTk6iIRBr3v8ycWrhwIcaOHQsLC4uKCUdKUvo+xUL6W+D58+dISUmBiYkJnJycYGRkJDqS5JV9CPknMpkMMTExWk5DRLqi7E/yP+0WpYolpQ9+lQGH7FZ+fM9r3v379zFo0CDExcUpv8Dn5eWhbdu22L59O4cZaxELumLUqFEDBw4cQNu2bVXW4+Li8OGHH+LZs2eCkknfiBEjsGrVKlSrVk10FKIKwZlTlZ+UPlvqiQ5A/8zMzAwtWrSAq6sri+gV5OTJk//qHxbRiUgToqKi4OrqCmNjYxgbG8PV1RWRkZGiYxFphYGBAfbt2yc6BlGFGjlyJIqLi5GSkoJnz57h2bNnSElJgUKhQEBAgOh4kmZkZIQ//vhDbf358+cqO3ZJsz744AOMHj0aFy5cgEKhgEKhwPnz5zFmzBj4+vqKjidpixYt+tsi+rVr1yo4DZH2lc2cIqoI7JFOREQkUGhoKMLDwxEYGIg2bdoAAOLj4xEcHIysrCzlEEaqGHl5eWrHPSMiIlC7dm0xgSSKQ3ZJ15w9exbnzp2Ds7Ozcs3Z2Rlr1qxBu3btBCaTvrKCblRUFFq2bAkAuHDhAgu6WrZ69WoMGzYMbdq0UbbFLCkpga+vL1atWiU4nbS5ubkhMjJS7f29bNkyhIaGSmbgH1EZzpyiisTWLkRERAJZWVlhzZo1GDRokMr69u3bERgYiJycHEHJpG/x4sWws7PDgAEDAAD9+/fHDz/8gDp16uDgwYNo1qyZ4ITSNX/+fCxbtgzvvfcev/BUQlI6fltZODs7Y8uWLcpCbpmLFy9i8ODBSE9PF5RM+vLy8jBs2DD8/PPPagXd7777DtWrVxecUNrS0tKQkpICAHBxceFA6QqwfPlyfPXVVxg2bBjCw8Px7NkzDB06FDdv3sSGDRt4A4kkhzOnxNDV/vQspBMREQlkaWmJixcvqg1+Sk1NRcuWLZGXlycmmA5wcHDA1q1b0bZtWxw7dgz9+/fHzp07sWvXLmRnZ+Po0aOiI0oWv/BUbiyka96PP/6IBQsW4JtvvoGXlxdkMhkSEhIQGBiI6dOno0+fPqIjSh4LuuJwBkzFu3r1KoYMGYKXL1/i2bNnaN26NTZu3MgTdiR5vN5ULF3sT89COhERkUCBgYEwMDDAihUrVNZDQkLw4sULfPPNN4KSSZ+JiQlSU1NhY2ODoKAgvHz5EhEREUhNTUWrVq3w22+/iY6oE/iFp/IZO3Ys5s6dCysrK9FRJMPS0hKFhYUoKSlBlSqvu2uW/fzXExkcwqg9vN5UrKioKISHhyMtLQ0A4OTkhEmTJmHUqFGCk0nfH3/8gU8//RQ//PADACAyMhLDhg0TnIpIe3i9EWPEiBFwc3PTqXaN7JFOREQkWFRUFI4ePYrWrVsDAM6fP4979+7B399f5UPJX4vt9N9YWlri3r17sLGxweHDh5X96BUKBUpLSwWnkz5+4REjLy8PFy9exJMnTyCXy1Ue8/f3BwCsXbtWRDRJW7lypegIOo3Xm4rHGTDixMXFYciQIahZsyauXbuGuLg4BAYG4pdffkFERAQsLS1FRyTSKF5vxNHF/vTckU5ERCRQp06d/tXzZDIZYmJitJxGt0yYMAEHDhyAk5MTEhMTkZWVBTMzM+zcuROLFy/GlStXREeUrL/7wvP1118jKCiIX3i05Oeff4afnx8KCgpgbm6usitXJpNxJ3QlsGjRIowZM0YSPUQrC15vxOAMGHGMjIwQHByMuXPnKucCZGRkYOjQocjOzsb9+/cFJyTSLF5vxNHFdo0spBMREZFOKi4uxurVq5GdnY3hw4fDw8MDwOudo2ZmZtypqEX8wiNG48aN0bNnTyxYsACmpqai41A5qlWrhqSkJJ3qNaptvN6IwRkw4pw+fRodOnRQW5fL5Zg/fz5CQ0MFpCLSHl5vKgddaZ+mJzoAERERUUUrmzLft29frFq1SllEB8Dj/hWgtLQU3t7eauteXl4oKSkRkEg3PHjwABMnTmQRvRLjHifN4/VGjCFDhpTbJmr9+vXw8/MTkEh3lBXR09PTceTIEbx48QLA6+IWi+gkRbzeiBUVFQVXV1cYGxvD2NgYrq6uiIyMFB1La7gjnYiIiHSSLk6Zryw4ZFeMfv36YeDAgejfv7/oKPQ3zM3NcfXqVV6XNIjXGzECAwMRHR0NGxubcmfAlLUcATgDRtNyc3PRv39/nDx5EjKZDGlpaXBwcEBAQAAsLS2xbNky0RGJNIrXG3F0sX0aC+lERESkk3RxynxlwS88YkRFRWHOnDnK9/6fX2cA8PX1FZSMyrCQrnm83ojBGTDi+Pv748mTJ4iMjESTJk2U15SjR48iODgYN2/eFB2RSKN4vRFHF9unsZBOREREOmn+/PlYtmwZ3nvvPZ2ZMl9Z8AuPGHp6f9/VUSaTobS0tALTUHlYSNc8Xm9I19SpUwdHjhxBs2bNVK4pmZmZcHNzw/Pnz0VHJCKJ0MX+9CykExERkU7SxSnzRFS5sZBOUpOeno6MjAz4+PjAxMQECoVC8oPoRDM3N8eVK1fg5OSkck25dOkSunfvjtzcXNERiUgidLF9WhXRAYiIiIhEyMzMVP6sK1Pmiahya9++PUxMTETHkCQWdCvW3/XpHjVqFCwsLLB8+XLRESXLx8cH0dHRmDt3LoDXn23kcjmWLl36r09oEBH9W1FRUTh69Gi57dP+3EJTKu3TuCOdiIiIdFZUVBTCw8ORlpYGAHBycsKkSZMwatQowcmINGP16tUYPXo0jI2NsXr16jc+l+2MtKu0tBT79+9HSkoKZDIZmjRpgt69e0NfX190NEl70+BFFnS1h326xUlOTkbHjh3h5eWFmJgY+Pr64ubNm3j27Bni4uLQqFEj0RGJSCJ0sX0aC+lERESkk3RxyjzpHnt7eyQkJKBmzZpsZyRQeno6evXqhfv378PZ2RkKhQKpqamwsbHBL7/8wsKWFrGgKwb7dIv16NEjrF27FpcvX4ZcLoenpyfGjx+PunXrio5GRPRWYyGdiIiIdJIuTpknIjF69uwJhUKB77//HjVq1ADweqf0kCFDoKenh19++UVwQuliQVcM9umu/MaNG4c5c+bAyspKdBQioreGnugARERERCKUlpbC29tbbd3LywslJSUCEhGRVJ0+fRpLlixRFtEBoGbNmli0aBFOnz4tMJn0FRQUwNTUVG09JycHRkZGAhLphrI+3WXYp7vy2bp1K/Lz80XHICJ6q3DYKBEREemkIUOGYO3atWqDb9avXw8/Pz9BqYi06/79+/jpp5+QnZ2NoqIilcekMgSqMjIyMsIff/yhtv78+XMYGhoKSKQ7OHhRjGXLlqFDhw5ISEhAUVERpk2bptKnm8RjcwIiov8dC+lERESks3RtyjzpthMnTsDX1xf29va4ffs2XF1dkZWVBYVCAU9PT9HxJO2DDz7A6NGjERUVhZYtWwIALly4gDFjxsDX11dwOmljQbfiFRcXY9y4cfjpp59w6NAh6Ovro6CgAP369WOfbiIiequxRzoRERHpJF2cMk+6rWXLlujevTvmzJmj7Flcq1Yt+Pn5oXv37hg7dqzoiJKVl5eHYcOG4eeff4aBgQEAoKSkBL6+vvjuu+9QvXp1wQmlqbi4GF27dsXChQtx6NAhDl6sQNbW1jh37hycnJxER6G/8efe9URE9O+wkE5EREREpAPMzc2RlJSERo0awdLSErGxsWjatCmuXr2K3r17IysrS3REyUtLS0NKSgoAwMXFBY6OjoITSR8LumJMmTIFBgYGWLRokego9DdYSCci+t+xtQsRERERkQ6oWrUqXr16BQCoV68eMjIy0LRpUwCvBy+S9jk5OSmL5zKZTHAa3eDv74+oqCgWdCtYUVERIiMjcezYMXh7e6Nq1aoqj7NlGhERvY1YSCciIiIi0gGtW7dGXFwcXFxc0KtXL0yZMgXXr1/H3r17lXMCSHuioqIQHh6OtLQ0AK+L6pMmTcKoUaMEJ5M2FnTFuHHjhnL2QmpqqspjvIlUOQwZMgTVqlUTHYOI6K3C1i5ERERERDrgzp07eP78Odzd3VFYWIiQkBDExsbC0dER4eHhsLW1FR1RskJDQxEeHo7AwEC0adMGABAfH4+vv/4aQUFBmDdvnuCE0vWmeRicgUFStGnTJpiZmeGTTz5RWd+9ezcKCwsxbNgwQcmIiN5+LKQTERERERFpkZWVFdasWYNBgwaprG/fvh2BgYFsrUNEGuPs7Ix169ap3UQ6ffo0Ro8ejdu3bwtKRkT09mNrFyIiIiIiHfP8+XPI5XKVNR7x157S0lJ4e3urrXt5eaGkpERAIiKSqrt378Le3l5t3dbWFtnZ2QISERFJh57oAEREREREpH2ZmZno1asXqlatiurVq8PS0hKWlpawsLCApaWl6HiSNmTIEKxdu1Ztff369fDz8xOQiIikqlatWrh27Zra+tWrV1GzZk0BiYiIpIM70omIiIiIdEBZwXbjxo2oXbs2B/5VsKioKBw9elQ52PX8+fO4d+8e/P39MXnyZOXzOPySiP6LgQMHYuLEiTA3N4ePjw+A121dgoKCMHDgQMHpiIjebuyRTkRERESkA8zMzHD58mU4OzuLjqJz3jTw8s84/JKI/quioiIMHToUu3fvRpUqr/dOyuVy+Pv7Y926dTA0NBSckIjo7cVCOhERERGRDujUqRO+/PJLvP/++6KjEBGRFigUCmRnZ8Pa2hoPHjxAUlISTExM4ObmBltbW9HxiIjeeiykExERERHpgIyMDIwZMwZDhgyBq6srDAwMVB53d3cXlEx3pKenIyMjAz4+PjAxMYFCoWCLHSLSGLlcDmNjY9y8eRNOTk6i4xARSQ57pBMRERER6YCnT58iIyMDI0aMUK7JZDJlMbe0tFRgOmnLzc1F//79cfLkSchkMqSlpcHBwQGjRo2ChYUFli9fLjoiEUmAnp4enJyckJuby0I6EZEW6IkOQERERERE2jdy5Eh4eHggPj4ed+7cQWZmpsr/S9oTHBwMAwMDZGdnw9TUVLk+YMAAHD58WGAyIpKaJUuWYOrUqbhx44boKEREksPWLkREREREOqBq1aq4evUqHB0dRUfROXXq1MGRI0fQrFkzmJub4+rVq3BwcEBmZibc3Nzw/Plz0RGJSCIsLS1RWFiIkpISGBoawsTEROXxZ8+eCUpGRPT2Y2sXIiIiIiId0LlzZxbSBSkoKFDZiV4mJycHRkZGAhIRkVStXLlSdAQiIsliIZ2IiIiISAd8+OGHCA4OxvXr1+Hm5qY2bNTX11dQMunz8fFBdHQ05s6dC+B1b3q5XI6lS5eiU6dOgtMRkZQMGzZMdAQiIsliaxciIiIiIh2gp/f345E4bFS7UlJS0KFDB3h5eSEmJga+vr64efMmnj17hri4ODRq1Eh0RCKSkIyMDGzatAkZGRlYtWoVatWqhcOHD8PGxgZNmzYVHY+I6K3FYaNERERERDpALpf/7T8somtPcXExxo0bh59++gktW7ZEly5dUFBQgH79+iExMZFFdCLSqNOnT8PNzQ0XLlzA3r17lTMYrl27hpkzZwpOR0T0duOOdCIiIiIiUnJzc8PBgwdhY2MjOopkWFtb49y5c3BychIdhYgkrk2bNvjkk08wefJkleHGly5dQp8+ffDgwQPREYmI3lrckU5EREREREpZWVkoLi4WHUNS/P39ERUVJToGEemA69evo2/fvmrr1tbWyM3NFZCIiEg6OGyUiIiIiIhIi4qKihAZGYljx47B29sbVatWVXl8xYoVgpIRkdRYWFjg4cOHsLe3V1lPTExE/fr1BaUiIpIGFtKJiIiIiIi06MaNG/D09AQApKamqjwmk8lERCIiiRo8eDCmT5+O3bt3QyaTQS6XIy4uDiEhIfD39xcdj4jorcYe6UREREREpPTnnrpERPR2KS4uxvDhw7Fjxw4oFApUqVIFJSUl8PPzw3fffQd9fX3REYmI3lospBMRERERkRIL6UREb787d+4gISEBMpkMHh4ecHR0FB2JiOitx9YuREREREREREQSERUVhfDwcKSlpQEAnJycMGnSJIwaNUpwMiKitxsL6UREREREOiovLw8WFhYqaxEREahdu7aYQERE9J+EhoYiPDwcgYGBaNOmDQAgPj4ewcHByMrKwrx58wQnJCJ6e7G1CxERERGRDli8eDHs7OwwYMAAAED//v3xww8/oE6dOjh48CCaNWsmOCEREf1XVlZWWLNmDQYNGqSyvn37dgQGBiInJ0dQMiKit5+e6ABERERERKR9ERERsLGxAQAcO3YMx44dw6FDh9CjRw9MnTpVcDoiItKE0tJSeHt7q617eXmhpKREQCIiIulgIZ2IiIiISAc8fPhQWUg/cOAA+vfvj65du2LatGm4dOmS4HRERKQJQ4YMwdq1a9XW169fDz8/PwGJiIikgz3SiYiIiIh0gKWlJe7duwcbGxscPnxY2SdXoVCgtLRUcDoiItKUqKgoHD16FK1btwYAnD9/Hvfu3YO/vz8mT56sfN6KFStERSQieiuxkE5EREREpAP69euHwYMHw8nJCbm5uejRowcAICkpCY6OjoLTERGRJty4cQOenp4AgIyMDACAtbU1rK2tcePGDeXzZDKZkHxERG8zFtKJiIiIiHRAeHg47O3tkZ2djSVLlsDMzAzA65Yv48aNE5yOiIg04eTJk6IjEBFJlkyhUChEhyAiIiIiIu0pLi7G6NGjERoaCgcHB9FxiIiIiIjeOhw2SkREREQkcQYGBti3b5/oGEREREREby0W0omIiIiIdEDfvn2xf/9+0TGIiIiIiN5K7JFORERERKQDHB0dMXfuXJw7dw5eXl6oWrWqyuMTJ04UlIyIiIiIqPJjj3QiIiIiIh1gb2//t4/JZDLcuXOnAtMQEREREb1dWEgnIiIiItIxZV8BZDKZ4CRERERERG8H9kgnIiIiItIRUVFRcHV1hbGxMYyNjeHq6orIyEjRsYiIiIiIKj32SCciIiIi0gGhoaEIDw9HYGAg2rRpAwCIj49HcHAwsrKyMG/ePMEJiYiIiIgqL7Z2ISIiIiLSAVZWVlizZg0GDRqksr59+3YEBgYiJydHUDIiIiIiosqPrV2IiIiIiHRAaWkpvL291da9vLxQUlIiIBERERER0duDhXQiIiIiIh0wZMgQrF27Vm19/fr18PPzE5CIiIiIiOjtwdYuREREREQ6IDAwENHR0bCxsUHr1q0BAOfPn8e9e/fg7+8PAwMD5XNXrFghKiYRERERUaXEQjoRERERkQ7o1KnTv3qeTCZDTEyMltMQEREREb1dWEgnIiIiIiIiIiIiInoD9kgnIiIiIiIiIiIiInoDFtKJiIiIiIiIiIiIiN6AhXQiIiIiIiIiIiIiojdgIZ2IiIiIiIiIiIiI6A1YSCciIiIiqiQUCgVGjx6NGjVqQCaTISkpSXQkIiIiIiICIFMoFArRIYiIiIiICDh06BB69+6NU6dOwcHBAVZWVqhSpcp/+t8cPnw48vLysH//fs2EJCIiIiLSQf/tUzkREREREWlMRkYG6tati7Zt24qOoqa0tBQymQx6ejzUSkRERES6h5+CiYiIiIgqgeHDhyMwMBDZ2dmQyWSws7ODQqHAkiVL4ODgABMTEzRr1gx79uxR/t+UlpYiICAA9vb2MDExgbOzM1atWqV8fNasWdi8eTN+/PFHyGQyyGQynDp1CqdOnYJMJkNeXp7yuUlJSZDJZMjKygIAfPfdd7CwsMCBAwfg4uICIyMj3L17F0VFRZg2bRrq16+PqlWrolWrVjh16pTyf+fu3bv48MMPYWlpiapVq6Jp06Y4ePCgtl8+IiIiIiKt4o50IiIiIqJKYNWqVWjUqBHWr1+PS5cuQV9fH1999RX27t2LtWvXwsnJCWfOnMGQIUNgbW2NDh06QC6Xo0GDBti1axesrKxw7tw5jB49GnXr1kX//v0REhKClJQU5OfnY9OmTQCAGjVq4Ny5c/8qU2FhIRYuXIjIyEjUrFkTtWrVwogRI5CVlYUdO3agXr162LdvH7p3747r16/DyckJ48ePR1FREc6cOYOqVasiOTkZZmZm2nzpiIiIiIi0joV0IiIiIqJKoHr16jA3N4e+vj7q1KmDgoICrFixAjExMWjTpg0AwMHBAbGxsYiIiECHDh1gYGCA2bNnK/837O3tce7cOezatQv9+/eHmZkZTExM8OrVK9SpU+d/zlRcXIxvv/0WzZo1A/C69cz27dtx//591KtXDwAQEhKCw4cPY9OmTViwYAGys7Px0Ucfwc3NTZmZiIiIiOhtx0I6EREREVEllJycjJcvX6JLly4q60VFRfDw8FD+vm7dOkRGRuLu3bt48eIFioqK0Lx5c41kMDQ0hLu7u/L3K1euQKFQoHHjxirPe/XqFWrWrAkAmDhxIsaOHYujR4/i/fffx0cffaTyv0FERERE9DZiIZ2IiIiIqBKSy+UAgF9++QX169dXeczIyAgAsGvXLgQHB2P58uVo06YNzM3NsXTpUly4cOGN/9tlA0MVCoVyrbi4WO15JiYmkMlkKpn09fVx+fJl6Ovrqzy3rH3LqFGj0K1bN/zyyy84evQoFi5ciOXLlyMwMPDf/n+diIiIiKjSYSGdiIiIiKgSKhvwmZ2djQ4dOpT7nLNnz6Jt27YYN26cci0jI0PlOYaGhigtLVVZs7a2BgA8fPgQlpaWAF4PG/0nHh4eKC0txZMnT9C+ffu/fZ6NjQ3GjBmDMWPG4PPPP8eGDRtYSCciIiKitxoL6URERERElZC5uTlCQkIQHBwMuVyOd999F/n5+Th37hzMzMwwbNgwODo6Ijo6GkeOHIG9vT22bNmCS5cuwd7eXvm/Y2dnhyNHjuD27duoWbMmqlevDkdHR9jY2GDWrFmYN28e0tLSsHz58n/M1LhxY/j5+cHf3x/Lly+Hh4cHcnJyEBMTAzc3N/Ts2ROTJk1Cjx490LhxY/z222+IiYlBkyZNtPlSERERERFpnZ7oAEREREREVL65c+ciLCwMCxcuRJMmTdCtWzf8/PPPykL5mDFj0K9fPwwYMACtWrVCbm6uyu50APj000/h7OwMb29vWFtbIy4uDgYGBti+fTtu3bqFZs2aYfHixZg3b96/yrRp0yb4+/tjypQpcHZ2hq+vLy5cuAAbGxsAQGlpKcaPH48mTZqge/fucHZ2xrfffqvZF4aIiIiIqILJFH9ujEhERERERERERERERCq4I52IiIiIiIiIiIiI6A1YSCciIiIiIiIiIiIiegMW0omIiIiIiIiIiIiI3oCFdCIiIiIiIiIiIiKiN2AhnYiIiIiIiIiIiIjoDVhIJyIiIiIiIiIiIiJ6AxbSiYiIiIiIiIiIiIjegIV0IiIiIiIiIiIiIqI3YCGdiIiIiIiIiIiIiOgNWEgnIiIiIiIiIiIiInoDFtKJiIiIiIiIiIiIiN7g/wPwsB3I/runAQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'status' is the column with binary status\n",
    "# and df contains all the necessary columns already\n",
    "\n",
    "# List of features to plot (excluding non-numeric and target columns)\n",
    "features_to_plot = ['commit_counts', 'prs_experience', 'prs_succ_rate', \n",
    "                    'prs_popularity', 'prs_followed_pri', 'prs_watched_repo', \n",
    "                    'prs_tenure_mnth', 'prs_main_team_member', \n",
    "                    'repo_pr_tenure_mnth', 'repo_pr_popularity', 'repo_pr_team_size', \n",
    "                    'perc_external_contribs', 'intra_branch', \n",
    "                    'pr_files_changed', 'pr_lines_changed']\n",
    "\n",
    "# Melt the DataFrame to long-form for seaborn's boxplot\n",
    "df_melted = df[features_to_plot + ['status']].melt(id_vars='status', var_name='features', value_name='value')\n",
    "\n",
    "# Initialize the figure size\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create the boxplot\n",
    "sns.boxplot(x='features', y='value', hue='status', data=df_melted, showfliers=False)\n",
    "\n",
    "# Improve aesthetics of the plot\n",
    "plt.xticks(rotation=90)  # Rotate the x labels to prevent overlap\n",
    "plt.title('Boxplots of Features by Status')\n",
    "plt.legend(title='Status')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust the plot to ensure everything fits without overlap\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['status', 'manual_analysis','pr_id','repo_id'], axis=1)\n",
    "Y = df['status']\n",
    "\n",
    "consistently_correct = pd.Series(True, index=df.index)\n",
    "\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "all_accuracies = []\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    x_train, x_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "    model_stage1 = xgb.XGBClassifier()\n",
    "\n",
    "    model_stage1.fit(x_train, y_train)\n",
    "    y_pred = model_stage1.predict(x_test)\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    all_accuracies.append(report)\n",
    "    consistently_correct[test_index] &= (y_pred == y_test)\n",
    "\n",
    "#this is for the next stage\n",
    "consistently_correct_df = df[consistently_correct]\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(all_accuracies)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'precision': 0.9990669465826919, 'recall': 1.0, 'f1-score': 0.9995332555425905, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9959798994974874, 'f1-score': 0.9979859013091642, 'support': 995}</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>{'precision': 0.9995334732913459, 'recall': 0.9979899497487437, 'f1-score': 0.9987595784258774, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9992428442996721, 'recall': 0.9992421371731717, 'f1-score': 0.9992415508320451, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'precision': 0.9983682983682983, 'recall': 1.0, 'f1-score': 0.9991834830281116, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.992964824120603, 'f1-score': 0.9964699949571356, 'support': 995}</td>\n",
       "      <td>0.998674</td>\n",
       "      <td>{'precision': 0.9991841491841491, 'recall': 0.9964824120603015, 'f1-score': 0.9978267389926236, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9986759041135699, 'recall': 0.9986737400530504, 'f1-score': 0.9986719406577778, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'precision': 0.9988336832283649, 'recall': 0.999766518795237, 'f1-score': 0.9992998833138856, 'support': 4283}</td>\n",
       "      <td>{'precision': 0.9989909182643795, 'recall': 0.9949748743718593, 'f1-score': 0.9969788519637464, 'support': 995}</td>\n",
       "      <td>0.998863</td>\n",
       "      <td>{'precision': 0.9989123007463722, 'recall': 0.9973706965835482, 'f1-score': 0.9981393676388159, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9988633249223463, 'recall': 0.9988632057597575, 'f1-score': 0.9988623262480674, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'precision': 0.9993000466635558, 'recall': 1.0, 'f1-score': 0.9996499008052282, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9969849246231156, 'f1-score': 0.9984901862103673, 'support': 995}</td>\n",
       "      <td>0.999432</td>\n",
       "      <td>{'precision': 0.9996500233317779, 'recall': 0.9984924623115579, 'f1-score': 0.9990700435077977, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9994320007313394, 'recall': 0.9994316028798788, 'f1-score': 0.999431273290661, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'precision': 0.9995332555425904, 'recall': 1.0, 'f1-score': 0.9997665732959851, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9979899497487437, 'f1-score': 0.9989939637826961, 'support': 995}</td>\n",
       "      <td>0.999621</td>\n",
       "      <td>{'precision': 0.9997666277712952, 'recall': 0.9989949748743718, 'f1-score': 0.9993802685393406, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9996212454507227, 'recall': 0.9996210685865858, 'f1-score': 0.9996209222035783, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'precision': 0.9995332555425904, 'recall': 1.0, 'f1-score': 0.9997665732959851, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9979899497487437, 'f1-score': 0.9989939637826961, 'support': 995}</td>\n",
       "      <td>0.999621</td>\n",
       "      <td>{'precision': 0.9997666277712952, 'recall': 0.9989949748743718, 'f1-score': 0.9993802685393406, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9996212454507227, 'recall': 0.9996210685865858, 'f1-score': 0.9996209222035783, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'precision': 0.9986010725110749, 'recall': 1.0, 'f1-score': 0.9993000466635559, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9939698492462311, 'f1-score': 0.996975806451613, 'support': 995}</td>\n",
       "      <td>0.998863</td>\n",
       "      <td>{'precision': 0.9993005362555374, 'recall': 0.9969849246231155, 'f1-score': 0.9981379265575845, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9988647960524695, 'recall': 0.9988632057597575, 'f1-score': 0.9988618846683146, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'precision': 0.9986010725110749, 'recall': 1.0, 'f1-score': 0.9993000466635559, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9939698492462311, 'f1-score': 0.996975806451613, 'support': 995}</td>\n",
       "      <td>0.998863</td>\n",
       "      <td>{'precision': 0.9993005362555374, 'recall': 0.9969849246231155, 'f1-score': 0.9981379265575845, 'support': 5278}</td>\n",
       "      <td>{'precision': 0.9988647960524695, 'recall': 0.9988632057597575, 'f1-score': 0.9988618846683146, 'support': 5278}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'precision': 0.999066728884741, 'recall': 1.0, 'f1-score': 0.9995331465919701, 'support': 4282}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9959798994974874, 'f1-score': 0.9979859013091642, 'support': 995}</td>\n",
       "      <td>0.999242</td>\n",
       "      <td>{'precision': 0.9995333644423705, 'recall': 0.9979899497487437, 'f1-score': 0.9987595239505671, 'support': 5277}</td>\n",
       "      <td>{'precision': 0.9992427009824637, 'recall': 0.9992419935569452, 'f1-score': 0.9992414071459985, 'support': 5277}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'precision': 0.9965100046533272, 'recall': 1.0, 'f1-score': 0.9982519519869478, 'support': 4283}</td>\n",
       "      <td>{'precision': 1.0, 'recall': 0.9849094567404426, 'f1-score': 0.9923973644196654, 'support': 994}</td>\n",
       "      <td>0.997157</td>\n",
       "      <td>{'precision': 0.9982550023266636, 'recall': 0.9924547283702213, 'f1-score': 0.9953246582033066, 'support': 5277}</td>\n",
       "      <td>{'precision': 0.9971673962346409, 'recall': 0.9971574758385446, 'f1-score': 0.9971491549352368, 'support': 5277}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 0  \\\n",
       "0  {'precision': 0.9990669465826919, 'recall': 1.0, 'f1-score': 0.9995332555425905, 'support': 4283}                 \n",
       "1  {'precision': 0.9983682983682983, 'recall': 1.0, 'f1-score': 0.9991834830281116, 'support': 4283}                 \n",
       "2  {'precision': 0.9988336832283649, 'recall': 0.999766518795237, 'f1-score': 0.9992998833138856, 'support': 4283}   \n",
       "3  {'precision': 0.9993000466635558, 'recall': 1.0, 'f1-score': 0.9996499008052282, 'support': 4283}                 \n",
       "4  {'precision': 0.9995332555425904, 'recall': 1.0, 'f1-score': 0.9997665732959851, 'support': 4283}                 \n",
       "5  {'precision': 0.9995332555425904, 'recall': 1.0, 'f1-score': 0.9997665732959851, 'support': 4283}                 \n",
       "6  {'precision': 0.9986010725110749, 'recall': 1.0, 'f1-score': 0.9993000466635559, 'support': 4283}                 \n",
       "7  {'precision': 0.9986010725110749, 'recall': 1.0, 'f1-score': 0.9993000466635559, 'support': 4283}                 \n",
       "8  {'precision': 0.999066728884741, 'recall': 1.0, 'f1-score': 0.9995331465919701, 'support': 4282}                  \n",
       "9  {'precision': 0.9965100046533272, 'recall': 1.0, 'f1-score': 0.9982519519869478, 'support': 4283}                 \n",
       "\n",
       "                                                                                                                 1  \\\n",
       "0  {'precision': 1.0, 'recall': 0.9959798994974874, 'f1-score': 0.9979859013091642, 'support': 995}                  \n",
       "1  {'precision': 1.0, 'recall': 0.992964824120603, 'f1-score': 0.9964699949571356, 'support': 995}                   \n",
       "2  {'precision': 0.9989909182643795, 'recall': 0.9949748743718593, 'f1-score': 0.9969788519637464, 'support': 995}   \n",
       "3  {'precision': 1.0, 'recall': 0.9969849246231156, 'f1-score': 0.9984901862103673, 'support': 995}                  \n",
       "4  {'precision': 1.0, 'recall': 0.9979899497487437, 'f1-score': 0.9989939637826961, 'support': 995}                  \n",
       "5  {'precision': 1.0, 'recall': 0.9979899497487437, 'f1-score': 0.9989939637826961, 'support': 995}                  \n",
       "6  {'precision': 1.0, 'recall': 0.9939698492462311, 'f1-score': 0.996975806451613, 'support': 995}                   \n",
       "7  {'precision': 1.0, 'recall': 0.9939698492462311, 'f1-score': 0.996975806451613, 'support': 995}                   \n",
       "8  {'precision': 1.0, 'recall': 0.9959798994974874, 'f1-score': 0.9979859013091642, 'support': 995}                  \n",
       "9  {'precision': 1.0, 'recall': 0.9849094567404426, 'f1-score': 0.9923973644196654, 'support': 994}                  \n",
       "\n",
       "   accuracy  \\\n",
       "0  0.999242   \n",
       "1  0.998674   \n",
       "2  0.998863   \n",
       "3  0.999432   \n",
       "4  0.999621   \n",
       "5  0.999621   \n",
       "6  0.998863   \n",
       "7  0.998863   \n",
       "8  0.999242   \n",
       "9  0.997157   \n",
       "\n",
       "                                                                                                          macro avg  \\\n",
       "0  {'precision': 0.9995334732913459, 'recall': 0.9979899497487437, 'f1-score': 0.9987595784258774, 'support': 5278}   \n",
       "1  {'precision': 0.9991841491841491, 'recall': 0.9964824120603015, 'f1-score': 0.9978267389926236, 'support': 5278}   \n",
       "2  {'precision': 0.9989123007463722, 'recall': 0.9973706965835482, 'f1-score': 0.9981393676388159, 'support': 5278}   \n",
       "3  {'precision': 0.9996500233317779, 'recall': 0.9984924623115579, 'f1-score': 0.9990700435077977, 'support': 5278}   \n",
       "4  {'precision': 0.9997666277712952, 'recall': 0.9989949748743718, 'f1-score': 0.9993802685393406, 'support': 5278}   \n",
       "5  {'precision': 0.9997666277712952, 'recall': 0.9989949748743718, 'f1-score': 0.9993802685393406, 'support': 5278}   \n",
       "6  {'precision': 0.9993005362555374, 'recall': 0.9969849246231155, 'f1-score': 0.9981379265575845, 'support': 5278}   \n",
       "7  {'precision': 0.9993005362555374, 'recall': 0.9969849246231155, 'f1-score': 0.9981379265575845, 'support': 5278}   \n",
       "8  {'precision': 0.9995333644423705, 'recall': 0.9979899497487437, 'f1-score': 0.9987595239505671, 'support': 5277}   \n",
       "9  {'precision': 0.9982550023266636, 'recall': 0.9924547283702213, 'f1-score': 0.9953246582033066, 'support': 5277}   \n",
       "\n",
       "                                                                                                       weighted avg  \n",
       "0  {'precision': 0.9992428442996721, 'recall': 0.9992421371731717, 'f1-score': 0.9992415508320451, 'support': 5278}  \n",
       "1  {'precision': 0.9986759041135699, 'recall': 0.9986737400530504, 'f1-score': 0.9986719406577778, 'support': 5278}  \n",
       "2  {'precision': 0.9988633249223463, 'recall': 0.9988632057597575, 'f1-score': 0.9988623262480674, 'support': 5278}  \n",
       "3  {'precision': 0.9994320007313394, 'recall': 0.9994316028798788, 'f1-score': 0.999431273290661, 'support': 5278}   \n",
       "4  {'precision': 0.9996212454507227, 'recall': 0.9996210685865858, 'f1-score': 0.9996209222035783, 'support': 5278}  \n",
       "5  {'precision': 0.9996212454507227, 'recall': 0.9996210685865858, 'f1-score': 0.9996209222035783, 'support': 5278}  \n",
       "6  {'precision': 0.9988647960524695, 'recall': 0.9988632057597575, 'f1-score': 0.9988618846683146, 'support': 5278}  \n",
       "7  {'precision': 0.9988647960524695, 'recall': 0.9988632057597575, 'f1-score': 0.9988618846683146, 'support': 5278}  \n",
       "8  {'precision': 0.9992427009824637, 'recall': 0.9992419935569452, 'f1-score': 0.9992414071459985, 'support': 5277}  \n",
       "9  {'precision': 0.9971673962346409, 'recall': 0.9971574758385446, 'f1-score': 0.9971491549352368, 'support': 5277}  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_support</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4282.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>994.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>5277.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>5277.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class  avg_support  avg_precision  avg_recall  avg_f1_score\n",
       "0  0             4282.9       1.0            1.00        1.0         \n",
       "1  1             994.9        1.0            0.99        1.0         \n",
       "2  macro avg     5277.8       1.0            1.00        1.0         \n",
       "3  weighted avg  5277.8       1.0            1.00        1.0         "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df_wa = metrics_df.drop(columns='accuracy')\n",
    "\n",
    "\n",
    "averages_stage1 = {}\n",
    "\n",
    "\n",
    "for class_label, dicts in metrics_df_wa.items():\n",
    "    metric_sums = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0}\n",
    "    \n",
    "    for metric_dict in dicts:\n",
    "        metric_sums['precision'] += metric_dict['precision']\n",
    "        metric_sums['recall'] += metric_dict['recall']\n",
    "        metric_sums['f1-score'] += metric_dict['f1-score']\n",
    "        metric_sums['support'] += metric_dict['support']\n",
    "\n",
    "    \n",
    "    averages_stage1[class_label] = {\n",
    "        'avg_support': metric_sums['support'] / len(dicts),\n",
    "        'avg_precision': metric_sums['precision'] / len(dicts),\n",
    "        'avg_recall': metric_sums['recall'] / len(dicts),\n",
    "        'avg_f1_score': metric_sums['f1-score'] / len(dicts)\n",
    "    }\n",
    "averages__stage1_df = pd.DataFrame(averages_stage1).T\n",
    "\n",
    "averages__stage1_df['avg_precision'] = averages__stage1_df['avg_precision'].round(2)\n",
    "averages__stage1_df['avg_recall'] = averages__stage1_df['avg_recall'].round(2)\n",
    "averages__stage1_df['avg_f1_score'] = averages__stage1_df['avg_f1_score'].round(2)\n",
    "averages__stage1_df['avg_support'] = averages__stage1_df['avg_support'].round(2)\n",
    "\n",
    "\n",
    "averages__stage1_df.reset_index(inplace=True)\n",
    "averages__stage1_df.rename(columns={'index': 'class'}, inplace=True)\n",
    "\n",
    "averages__stage1_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_for_next_stage = consistently_correct_df['status']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of duplicated rows in the consistently_correct_df\n",
    "consistently_correct_df.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52723"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_for_next_stage.count()\n",
    "#52723 compared to 52778. looks correct based on our accuracy 55 are gone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not looked at for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_stage1 = xgb.XGBClassifier()\n",
    "model_stage1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8565\n",
      "           1       1.00      0.99      1.00      2000\n",
      "\n",
      "    accuracy                           1.00     10565\n",
      "   macro avg       1.00      1.00      1.00     10565\n",
      "weighted avg       1.00      1.00      1.00     10565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_stage1 = model_stage1.predict(x_test)\n",
    "print(\"Stage 1 - Classification Report:\\n\", classification_report(y_test, predictions_stage1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_predictions_stage1 = model_stage1.predict(df.drop(['status', 'manual_analysis', 'pr_id','repo_id'], axis=1))\n",
    "# Adding predictions back to the dataset\n",
    "df['predicted_status'] = full_predictions_stage1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pr_id</th>\n",
       "      <th>commit_counts</th>\n",
       "      <th>prs_experience</th>\n",
       "      <th>prs_succ_rate</th>\n",
       "      <th>prs_popularity</th>\n",
       "      <th>prs_followed_pri</th>\n",
       "      <th>prs_watched_repo</th>\n",
       "      <th>prs_tenure_mnth</th>\n",
       "      <th>prs_main_team_member</th>\n",
       "      <th>repo_pr_tenure_mnth</th>\n",
       "      <th>repo_pr_popularity</th>\n",
       "      <th>repo_pr_team_size</th>\n",
       "      <th>perc_external_contribs</th>\n",
       "      <th>intra_branch</th>\n",
       "      <th>pr_files_changed</th>\n",
       "      <th>pr_lines_changed</th>\n",
       "      <th>repo_id</th>\n",
       "      <th>status</th>\n",
       "      <th>manual_analysis</th>\n",
       "      <th>predicted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>10710116</td>\n",
       "      <td>2.052480</td>\n",
       "      <td>0.551998</td>\n",
       "      <td>0.377336</td>\n",
       "      <td>-1.415663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.253013</td>\n",
       "      <td>0</td>\n",
       "      <td>0.545840</td>\n",
       "      <td>0.136861</td>\n",
       "      <td>-0.148184</td>\n",
       "      <td>0.035603</td>\n",
       "      <td>1</td>\n",
       "      <td>1.705726</td>\n",
       "      <td>2.109971</td>\n",
       "      <td>9204</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>4109359</td>\n",
       "      <td>1.926326</td>\n",
       "      <td>0.551998</td>\n",
       "      <td>0.730687</td>\n",
       "      <td>0.449347</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077583</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.544086</td>\n",
       "      <td>-1.556927</td>\n",
       "      <td>-1.032777</td>\n",
       "      <td>-0.935148</td>\n",
       "      <td>0</td>\n",
       "      <td>3.212820</td>\n",
       "      <td>2.061389</td>\n",
       "      <td>9281863</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>41500541</td>\n",
       "      <td>2.363751</td>\n",
       "      <td>-0.473401</td>\n",
       "      <td>0.780038</td>\n",
       "      <td>0.968358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.587516</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647841</td>\n",
       "      <td>0.815280</td>\n",
       "      <td>0.585820</td>\n",
       "      <td>0.214885</td>\n",
       "      <td>0</td>\n",
       "      <td>6.285401</td>\n",
       "      <td>2.338621</td>\n",
       "      <td>6401040</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>6390465</td>\n",
       "      <td>2.317450</td>\n",
       "      <td>0.257108</td>\n",
       "      <td>0.305998</td>\n",
       "      <td>1.228275</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354925</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.864063</td>\n",
       "      <td>-1.345569</td>\n",
       "      <td>-0.758361</td>\n",
       "      <td>0.179764</td>\n",
       "      <td>0</td>\n",
       "      <td>0.881939</td>\n",
       "      <td>1.108024</td>\n",
       "      <td>7176443</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>9041941</td>\n",
       "      <td>2.052480</td>\n",
       "      <td>0.400404</td>\n",
       "      <td>0.522617</td>\n",
       "      <td>-0.089947</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.742459</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.589978</td>\n",
       "      <td>-1.596947</td>\n",
       "      <td>-0.990372</td>\n",
       "      <td>-0.522283</td>\n",
       "      <td>0</td>\n",
       "      <td>2.438667</td>\n",
       "      <td>1.808288</td>\n",
       "      <td>15285703</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>3817724</td>\n",
       "      <td>2.269178</td>\n",
       "      <td>-0.108146</td>\n",
       "      <td>0.917782</td>\n",
       "      <td>-0.444593</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.305644</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.127077</td>\n",
       "      <td>-1.151079</td>\n",
       "      <td>-1.243193</td>\n",
       "      <td>-0.192570</td>\n",
       "      <td>0</td>\n",
       "      <td>2.576372</td>\n",
       "      <td>1.891247</td>\n",
       "      <td>8660746</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3850</th>\n",
       "      <td>14382193</td>\n",
       "      <td>1.706111</td>\n",
       "      <td>1.118215</td>\n",
       "      <td>0.126238</td>\n",
       "      <td>-0.026376</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354925</td>\n",
       "      <td>0</td>\n",
       "      <td>0.686111</td>\n",
       "      <td>-0.433588</td>\n",
       "      <td>-0.499731</td>\n",
       "      <td>-0.076603</td>\n",
       "      <td>0</td>\n",
       "      <td>2.048901</td>\n",
       "      <td>1.119534</td>\n",
       "      <td>62688</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>19578733</td>\n",
       "      <td>1.531270</td>\n",
       "      <td>1.137150</td>\n",
       "      <td>0.905500</td>\n",
       "      <td>0.083629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967082</td>\n",
       "      <td>0</td>\n",
       "      <td>0.951808</td>\n",
       "      <td>-0.260626</td>\n",
       "      <td>-0.217931</td>\n",
       "      <td>-1.460301</td>\n",
       "      <td>0</td>\n",
       "      <td>1.537983</td>\n",
       "      <td>1.113819</td>\n",
       "      <td>170988</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>6474200</td>\n",
       "      <td>1.432580</td>\n",
       "      <td>-0.046081</td>\n",
       "      <td>0.636718</td>\n",
       "      <td>0.476167</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.181025</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.788819</td>\n",
       "      <td>-1.486026</td>\n",
       "      <td>-1.871830</td>\n",
       "      <td>-4.687270</td>\n",
       "      <td>1</td>\n",
       "      <td>1.537983</td>\n",
       "      <td>1.201711</td>\n",
       "      <td>10982460</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6576</th>\n",
       "      <td>16663966</td>\n",
       "      <td>2.408236</td>\n",
       "      <td>1.888922</td>\n",
       "      <td>0.853337</td>\n",
       "      <td>1.220685</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.928868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.334092</td>\n",
       "      <td>-0.190708</td>\n",
       "      <td>-0.517338</td>\n",
       "      <td>-3.382070</td>\n",
       "      <td>0</td>\n",
       "      <td>2.123141</td>\n",
       "      <td>2.102638</td>\n",
       "      <td>3218707</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6943</th>\n",
       "      <td>6112888</td>\n",
       "      <td>4.380772</td>\n",
       "      <td>1.243456</td>\n",
       "      <td>0.780038</td>\n",
       "      <td>2.251341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.050614</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.108111</td>\n",
       "      <td>-0.417218</td>\n",
       "      <td>-0.129724</td>\n",
       "      <td>-0.886764</td>\n",
       "      <td>0</td>\n",
       "      <td>2.123141</td>\n",
       "      <td>1.761961</td>\n",
       "      <td>7450539</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7134</th>\n",
       "      <td>6878278</td>\n",
       "      <td>3.194416</td>\n",
       "      <td>1.546962</td>\n",
       "      <td>-0.146670</td>\n",
       "      <td>1.380745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.726456</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.231023</td>\n",
       "      <td>-1.743417</td>\n",
       "      <td>-0.197121</td>\n",
       "      <td>0.214885</td>\n",
       "      <td>0</td>\n",
       "      <td>1.134520</td>\n",
       "      <td>1.791619</td>\n",
       "      <td>10603682</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9125</th>\n",
       "      <td>836551</td>\n",
       "      <td>1.531270</td>\n",
       "      <td>0.319174</td>\n",
       "      <td>0.615764</td>\n",
       "      <td>0.594854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.567993</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.620015</td>\n",
       "      <td>0.761520</td>\n",
       "      <td>-1.032777</td>\n",
       "      <td>-0.984218</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.438619</td>\n",
       "      <td>0.677844</td>\n",
       "      <td>1361330</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9468</th>\n",
       "      <td>4768751</td>\n",
       "      <td>2.165996</td>\n",
       "      <td>1.318864</td>\n",
       "      <td>0.810574</td>\n",
       "      <td>1.228275</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.198541</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.188934</td>\n",
       "      <td>0.577009</td>\n",
       "      <td>-0.309680</td>\n",
       "      <td>-0.232106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.909245</td>\n",
       "      <td>1.344424</td>\n",
       "      <td>9982829</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9829</th>\n",
       "      <td>22563573</td>\n",
       "      <td>8.882065</td>\n",
       "      <td>-0.108146</td>\n",
       "      <td>0.713169</td>\n",
       "      <td>0.675422</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.941780</td>\n",
       "      <td>0</td>\n",
       "      <td>1.076983</td>\n",
       "      <td>1.082677</td>\n",
       "      <td>1.365251</td>\n",
       "      <td>-0.038795</td>\n",
       "      <td>0</td>\n",
       "      <td>5.096596</td>\n",
       "      <td>3.884249</td>\n",
       "      <td>9793</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9928</th>\n",
       "      <td>2532175</td>\n",
       "      <td>2.269178</td>\n",
       "      <td>0.347665</td>\n",
       "      <td>0.780038</td>\n",
       "      <td>1.044558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.509461</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.475071</td>\n",
       "      <td>-1.396726</td>\n",
       "      <td>-0.573667</td>\n",
       "      <td>-0.436863</td>\n",
       "      <td>0</td>\n",
       "      <td>1.440328</td>\n",
       "      <td>1.340264</td>\n",
       "      <td>287583</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pr_id  commit_counts  prs_experience  prs_succ_rate  prs_popularity  \\\n",
       "385   10710116       2.052480        0.551998       0.377336       -1.415663   \n",
       "902    4109359       1.926326        0.551998       0.730687        0.449347   \n",
       "1034  41500541       2.363751       -0.473401       0.780038        0.968358   \n",
       "1100   6390465       2.317450        0.257108       0.305998        1.228275   \n",
       "1490   9041941       2.052480        0.400404       0.522617       -0.089947   \n",
       "3265   3817724       2.269178       -0.108146       0.917782       -0.444593   \n",
       "3850  14382193       1.706111        1.118215       0.126238       -0.026376   \n",
       "4252  19578733       1.531270        1.137150       0.905500        0.083629   \n",
       "5794   6474200       1.432580       -0.046081       0.636718        0.476167   \n",
       "6576  16663966       2.408236        1.888922       0.853337        1.220685   \n",
       "6943   6112888       4.380772        1.243456       0.780038        2.251341   \n",
       "7134   6878278       3.194416        1.546962      -0.146670        1.380745   \n",
       "9125    836551       1.531270        0.319174       0.615764        0.594854   \n",
       "9468   4768751       2.165996        1.318864       0.810574        1.228275   \n",
       "9829  22563573       8.882065       -0.108146       0.713169        0.675422   \n",
       "9928   2532175       2.269178        0.347665       0.780038        1.044558   \n",
       "\n",
       "      prs_followed_pri  prs_watched_repo  prs_tenure_mnth  \\\n",
       "385                  0                 0        -1.253013   \n",
       "902                  0                 1         0.077583   \n",
       "1034                 0                 0         0.587516   \n",
       "1100                 0                 1         0.354925   \n",
       "1490                 0                 0         0.742459   \n",
       "3265                 0                 0         0.305644   \n",
       "3850                 1                 1         0.354925   \n",
       "4252                 0                 0         0.967082   \n",
       "5794                 1                 0        -0.181025   \n",
       "6576                 1                 1         0.928868   \n",
       "6943                 0                 0         1.050614   \n",
       "7134                 0                 0         0.726456   \n",
       "9125                 1                 0        -1.567993   \n",
       "9468                 1                 1         0.198541   \n",
       "9829                 0                 0         0.941780   \n",
       "9928                 0                 0         0.509461   \n",
       "\n",
       "      prs_main_team_member  repo_pr_tenure_mnth  repo_pr_popularity  \\\n",
       "385                      0             0.545840            0.136861   \n",
       "902                      1            -2.544086           -1.556927   \n",
       "1034                     0             0.647841            0.815280   \n",
       "1100                     0            -0.864063           -1.345569   \n",
       "1490                     0            -0.589978           -1.596947   \n",
       "3265                     0            -1.127077           -1.151079   \n",
       "3850                     0             0.686111           -0.433588   \n",
       "4252                     0             0.951808           -0.260626   \n",
       "5794                     0            -0.788819           -1.486026   \n",
       "6576                     0             0.334092           -0.190708   \n",
       "6943                     0            -0.108111           -0.417218   \n",
       "7134                     0            -1.231023           -1.743417   \n",
       "9125                     1            -1.620015            0.761520   \n",
       "9468                     0            -0.188934            0.577009   \n",
       "9829                     0             1.076983            1.082677   \n",
       "9928                     0            -0.475071           -1.396726   \n",
       "\n",
       "      repo_pr_team_size  perc_external_contribs  intra_branch  \\\n",
       "385           -0.148184                0.035603             1   \n",
       "902           -1.032777               -0.935148             0   \n",
       "1034           0.585820                0.214885             0   \n",
       "1100          -0.758361                0.179764             0   \n",
       "1490          -0.990372               -0.522283             0   \n",
       "3265          -1.243193               -0.192570             0   \n",
       "3850          -0.499731               -0.076603             0   \n",
       "4252          -0.217931               -1.460301             0   \n",
       "5794          -1.871830               -4.687270             1   \n",
       "6576          -0.517338               -3.382070             0   \n",
       "6943          -0.129724               -0.886764             0   \n",
       "7134          -0.197121                0.214885             0   \n",
       "9125          -1.032777               -0.984218             1   \n",
       "9468          -0.309680               -0.232106             0   \n",
       "9829           1.365251               -0.038795             0   \n",
       "9928          -0.573667               -0.436863             0   \n",
       "\n",
       "      pr_files_changed  pr_lines_changed   repo_id  status  manual_analysis  \\\n",
       "385           1.705726          2.109971      9204       1                3   \n",
       "902           3.212820          2.061389   9281863       1               11   \n",
       "1034          6.285401          2.338621   6401040       1                0   \n",
       "1100          0.881939          1.108024   7176443       1               10   \n",
       "1490          2.438667          1.808288  15285703       1                7   \n",
       "3265          2.576372          1.891247   8660746       1                8   \n",
       "3850          2.048901          1.119534     62688       1                7   \n",
       "4252          1.537983          1.113819    170988       1               10   \n",
       "5794          1.537983          1.201711  10982460       1               11   \n",
       "6576          2.123141          2.102638   3218707       1                8   \n",
       "6943          2.123141          1.761961   7450539       1                9   \n",
       "7134          1.134520          1.791619  10603682       1               11   \n",
       "9125         -0.438619          0.677844   1361330       1               10   \n",
       "9468          1.909245          1.344424   9982829       1               11   \n",
       "9829          5.096596          3.884249      9793       1                6   \n",
       "9928          1.440328          1.340264    287583       1                7   \n",
       "\n",
       "      predicted_status  \n",
       "385                  0  \n",
       "902                  0  \n",
       "1034                 0  \n",
       "1100                 0  \n",
       "1490                 0  \n",
       "3265                 0  \n",
       "3850                 0  \n",
       "4252                 0  \n",
       "5794                 0  \n",
       "6576                 0  \n",
       "6943                 0  \n",
       "7134                 0  \n",
       "9125                 0  \n",
       "9468                 0  \n",
       "9829                 0  \n",
       "9928                 0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10003)\n",
    "#show how many instances are predicted_status and status are different\n",
    "df[df['predicted_status'] != df['status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_merged_data = consistently_correct_df[consistently_correct_df['status'] == 1]\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_non_merged = non_merged_data.drop(['status', 'manual_analysis', 'pr_id','repo_id', 'Consistently_Correct'], axis=1)\n",
    "X_non_merged_imputed = imputer.fit_transform(X_non_merged)\n",
    "y_non_merged = non_merged_data['manual_analysis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pr_id                     9895\n",
       "commit_counts             9895\n",
       "prs_experience            9895\n",
       "prs_succ_rate             9895\n",
       "prs_popularity            9895\n",
       "prs_followed_pri          9895\n",
       "prs_watched_repo          9895\n",
       "prs_tenure_mnth           9895\n",
       "prs_main_team_member      9895\n",
       "repo_pr_tenure_mnth       9895\n",
       "repo_pr_popularity        9895\n",
       "repo_pr_team_size         9895\n",
       "perc_external_contribs    9665\n",
       "intra_branch              9895\n",
       "pr_files_changed          9895\n",
       "pr_lines_changed          9895\n",
       "repo_id                   9895\n",
       "status                    9895\n",
       "manual_analysis           9895\n",
       "Consistently_Correct      9895\n",
       "dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_merged_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "classification_reports = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_non_merged_imputed, y_non_merged):\n",
    "    x_train_fold, x_test_fold = X_non_merged_imputed[train_index], X_non_merged_imputed[test_index]\n",
    "    y_train_fold, y_test_fold = y_non_merged.iloc[train_index], y_non_merged.iloc[test_index]\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_fold_smote, y_train_fold_smote = smote.fit_resample(x_train_fold, y_train_fold)\n",
    "\n",
    "    model_non_merged = xgb.XGBClassifier()\n",
    "    model_non_merged.fit(x_train_fold_smote, y_train_fold_smote)\n",
    "\n",
    "    y_pred_fold = model_non_merged.predict(x_test_fold)\n",
    "\n",
    "    report = classification_report(y_test_fold, y_pred_fold, output_dict=True)\n",
    "    classification_reports.append(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'precision': 0.14285714285714285, 'recall': 0.25, 'f1-score': 0.18181818181818182, 'support': 4}</td>\n",
       "      <td>{'precision': 0.03571428571428571, 'recall': 0.024390243902439025, 'f1-score': 0.028985507246376812, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.26666666666666666, 'recall': 0.21505376344086022, 'f1-score': 0.2380952380952381, 'support': 93}</td>\n",
       "      <td>{'precision': 0.03225806451612903, 'recall': 0.0196078431372549, 'f1-score': 0.024390243902439025, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}</td>\n",
       "      <td>{'precision': 0.1206896551724138, 'recall': 0.10144927536231885, 'f1-score': 0.11023622047244096, 'support': 69}</td>\n",
       "      <td>{'precision': 0.1625, 'recall': 0.13829787234042554, 'f1-score': 0.14942528735632185, 'support': 94}</td>\n",
       "      <td>{'precision': 0.1917808219178082, 'recall': 0.11965811965811966, 'f1-score': 0.14736842105263157, 'support': 117}</td>\n",
       "      <td>{'precision': 0.10526315789473684, 'recall': 0.06666666666666667, 'f1-score': 0.0816326530612245, 'support': 30}</td>\n",
       "      <td>{'precision': 0.39313984168865435, 'recall': 0.5477941176470589, 'f1-score': 0.4577572964669739, 'support': 272}</td>\n",
       "      <td>{'precision': 0.2445414847161572, 'recall': 0.27450980392156865, 'f1-score': 0.2586605080831409, 'support': 204}</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>{'precision': 0.14128426009533288, 'recall': 0.14645230883972604, 'f1-score': 0.13986412979624743, 'support': 990}</td>\n",
       "      <td>{'precision': 0.23686890152077691, 'recall': 0.26666666666666666, 'f1-score': 0.2463863913871926, 'support': 990}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.13043478260869565, 'recall': 0.07317073170731707, 'f1-score': 0.09375, 'support': 41}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.16666666666666666, 'f1-score': 0.2, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2698412698412698, 'recall': 0.1827956989247312, 'f1-score': 0.21794871794871795, 'support': 93}</td>\n",
       "      <td>{'precision': 0.10714285714285714, 'recall': 0.058823529411764705, 'f1-score': 0.07594936708860758, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.175, 'recall': 0.1, 'f1-score': 0.12727272727272726, 'support': 70}</td>\n",
       "      <td>{'precision': 0.18840579710144928, 'recall': 0.13829787234042554, 'f1-score': 0.15950920245398775, 'support': 94}</td>\n",
       "      <td>{'precision': 0.16923076923076924, 'recall': 0.09322033898305085, 'f1-score': 0.12021857923497266, 'support': 118}</td>\n",
       "      <td>{'precision': 0.21052631578947367, 'recall': 0.13333333333333333, 'f1-score': 0.163265306122449, 'support': 30}</td>\n",
       "      <td>{'precision': 0.3793859649122807, 'recall': 0.6360294117647058, 'f1-score': 0.4752747252747253, 'support': 272}</td>\n",
       "      <td>{'precision': 0.27906976744186046, 'recall': 0.2955665024630542, 'f1-score': 0.28708133971291866, 'support': 203}</td>\n",
       "      <td>0.295960</td>\n",
       "      <td>{'precision': 0.179919793672388, 'recall': 0.1564920071329208, 'f1-score': 0.16002249709242553, 'support': 990}</td>\n",
       "      <td>{'precision': 0.2575723841553228, 'recall': 0.295959595959596, 'f1-score': 0.2635609527276399, 'support': 990}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.24561403508771928, 'recall': 0.15217391304347827, 'f1-score': 0.1879194630872483, 'support': 92}</td>\n",
       "      <td>{'precision': 0.1891891891891892, 'recall': 0.1346153846153846, 'f1-score': 0.15730337078651685, 'support': 52}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.06666666666666667, 'recall': 0.04285714285714286, 'f1-score': 0.05217391304347826, 'support': 70}</td>\n",
       "      <td>{'precision': 0.18571428571428572, 'recall': 0.13978494623655913, 'f1-score': 0.15950920245398773, 'support': 93}</td>\n",
       "      <td>{'precision': 0.14942528735632185, 'recall': 0.11016949152542373, 'f1-score': 0.12682926829268293, 'support': 118}</td>\n",
       "      <td>{'precision': 0.13333333333333333, 'recall': 0.12903225806451613, 'f1-score': 0.13114754098360656, 'support': 31}</td>\n",
       "      <td>{'precision': 0.32754342431761785, 'recall': 0.4852941176470588, 'f1-score': 0.3911111111111111, 'support': 272}</td>\n",
       "      <td>{'precision': 0.26222222222222225, 'recall': 0.29064039408866993, 'f1-score': 0.2757009345794393, 'support': 203}</td>\n",
       "      <td>0.247475</td>\n",
       "      <td>{'precision': 0.1299757036572797, 'recall': 0.12371397067318612, 'f1-score': 0.12347456702817257, 'support': 990}</td>\n",
       "      <td>{'precision': 0.22066753946554116, 'recall': 0.2474747474747475, 'f1-score': 0.22761195454249175, 'support': 990}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.07142857142857142, 'recall': 0.04878048780487805, 'f1-score': 0.057971014492753624, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.3090909090909091, 'recall': 0.18478260869565216, 'f1-score': 0.23129251700680273, 'support': 92}</td>\n",
       "      <td>{'precision': 0.08, 'recall': 0.0392156862745098, 'f1-score': 0.05263157894736842, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.09302325581395349, 'recall': 0.05714285714285714, 'f1-score': 0.07079646017699115, 'support': 70}</td>\n",
       "      <td>{'precision': 0.14444444444444443, 'recall': 0.13978494623655913, 'f1-score': 0.14207650273224043, 'support': 93}</td>\n",
       "      <td>{'precision': 0.1518987341772152, 'recall': 0.1016949152542373, 'f1-score': 0.12182741116751271, 'support': 118}</td>\n",
       "      <td>{'precision': 0.14285714285714285, 'recall': 0.12903225806451613, 'f1-score': 0.13559322033898305, 'support': 31}</td>\n",
       "      <td>{'precision': 0.4005102040816326, 'recall': 0.575091575091575, 'f1-score': 0.4721804511278195, 'support': 273}</td>\n",
       "      <td>{'precision': 0.2742616033755274, 'recall': 0.32019704433497537, 'f1-score': 0.29545454545454547, 'support': 203}</td>\n",
       "      <td>0.278788</td>\n",
       "      <td>{'precision': 0.13895957210578305, 'recall': 0.13297686490831334, 'f1-score': 0.13165197512041807, 'support': 990}</td>\n",
       "      <td>{'precision': 0.24520899956186437, 'recall': 0.2787878787878788, 'f1-score': 0.25451551604553, 'support': 990}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.2608695652173913, 'f1-score': 0.2727272727272727, 'support': 92}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.05128205128205128, 'recall': 0.02857142857142857, 'f1-score': 0.03669724770642202, 'support': 70}</td>\n",
       "      <td>{'precision': 0.1951219512195122, 'recall': 0.17204301075268819, 'f1-score': 0.18285714285714288, 'support': 93}</td>\n",
       "      <td>{'precision': 0.13541666666666666, 'recall': 0.11016949152542373, 'f1-score': 0.12149532710280372, 'support': 118}</td>\n",
       "      <td>{'precision': 0.15384615384615385, 'recall': 0.12903225806451613, 'f1-score': 0.14035087719298245, 'support': 31}</td>\n",
       "      <td>{'precision': 0.3896457765667575, 'recall': 0.5238095238095238, 'f1-score': 0.44687499999999997, 'support': 273}</td>\n",
       "      <td>{'precision': 0.2818181818181818, 'recall': 0.3054187192118227, 'f1-score': 0.2931442080378251, 'support': 203}</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>{'precision': 0.12440375559280074, 'recall': 0.1274928330960662, 'f1-score': 0.1245122563020374, 'support': 990}</td>\n",
       "      <td>{'precision': 0.23469958049150066, 'recall': 0.26666666666666666, 'f1-score': 0.24733121791804513, 'support': 990}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.07692307692307693, 'recall': 0.04878048780487805, 'f1-score': 0.059701492537313446, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2711864406779661, 'recall': 0.17391304347826086, 'f1-score': 0.2119205298013245, 'support': 92}</td>\n",
       "      <td>{'precision': 0.03225806451612903, 'recall': 0.0196078431372549, 'f1-score': 0.024390243902439025, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.10909090909090909, 'recall': 0.08571428571428572, 'f1-score': 0.096, 'support': 70}</td>\n",
       "      <td>{'precision': 0.15053763440860216, 'recall': 0.15053763440860216, 'f1-score': 0.15053763440860216, 'support': 93}</td>\n",
       "      <td>{'precision': 0.1686746987951807, 'recall': 0.11965811965811966, 'f1-score': 0.14, 'support': 117}</td>\n",
       "      <td>{'precision': 0.045454545454545456, 'recall': 0.03225806451612903, 'f1-score': 0.03773584905660377, 'support': 31}</td>\n",
       "      <td>{'precision': 0.41578947368421054, 'recall': 0.5787545787545788, 'f1-score': 0.4839203675344564, 'support': 273}</td>\n",
       "      <td>{'precision': 0.22026431718061673, 'recall': 0.24630541871921183, 'f1-score': 0.23255813953488372, 'support': 203}</td>\n",
       "      <td>0.264914</td>\n",
       "      <td>{'precision': 0.12418159672760305, 'recall': 0.1212941230159434, 'f1-score': 0.11973035473130193, 'support': 989}</td>\n",
       "      <td>{'precision': 0.2333192487305227, 'recall': 0.2649140546006067, 'f1-score': 0.2434557394924356, 'support': 989}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.15625, 'recall': 0.11904761904761904, 'f1-score': 0.13513513513513511, 'support': 42}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11}</td>\n",
       "      <td>{'precision': 0.21052631578947367, 'recall': 0.17391304347826086, 'f1-score': 0.1904761904761905, 'support': 92}</td>\n",
       "      <td>{'precision': 0.14705882352941177, 'recall': 0.09803921568627451, 'f1-score': 0.11764705882352941, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.15384615384615385, 'recall': 0.08571428571428572, 'f1-score': 0.11009174311926605, 'support': 70}</td>\n",
       "      <td>{'precision': 0.16393442622950818, 'recall': 0.10752688172043011, 'f1-score': 0.12987012987012989, 'support': 93}</td>\n",
       "      <td>{'precision': 0.10526315789473684, 'recall': 0.08547008547008547, 'f1-score': 0.09433962264150944, 'support': 117}</td>\n",
       "      <td>{'precision': 0.125, 'recall': 0.0967741935483871, 'f1-score': 0.10909090909090909, 'support': 31}</td>\n",
       "      <td>{'precision': 0.39540816326530615, 'recall': 0.5677655677655677, 'f1-score': 0.4661654135338346, 'support': 273}</td>\n",
       "      <td>{'precision': 0.2672811059907834, 'recall': 0.2857142857142857, 'f1-score': 0.27619047619047615, 'support': 203}</td>\n",
       "      <td>0.270981</td>\n",
       "      <td>{'precision': 0.1437140122121145, 'recall': 0.13499709817876637, 'f1-score': 0.13575055657341503, 'support': 989}</td>\n",
       "      <td>{'precision': 0.24048668960813793, 'recall': 0.27098078867542974, 'f1-score': 0.2494774599474562, 'support': 989}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 4}</td>\n",
       "      <td>{'precision': 0.075, 'recall': 0.07142857142857142, 'f1-score': 0.07317073170731707, 'support': 42}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2839506172839506, 'recall': 0.25, 'f1-score': 0.26589595375722547, 'support': 92}</td>\n",
       "      <td>{'precision': 0.08571428571428572, 'recall': 0.058823529411764705, 'f1-score': 0.06976744186046513, 'support': 51}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1-score': 0.28571428571428575, 'support': 3}</td>\n",
       "      <td>{'precision': 0.10256410256410256, 'recall': 0.057971014492753624, 'f1-score': 0.07407407407407407, 'support': 69}</td>\n",
       "      <td>{'precision': 0.14925373134328357, 'recall': 0.10752688172043011, 'f1-score': 0.125, 'support': 93}</td>\n",
       "      <td>{'precision': 0.15789473684210525, 'recall': 0.1282051282051282, 'f1-score': 0.14150943396226415, 'support': 117}</td>\n",
       "      <td>{'precision': 0.1724137931034483, 'recall': 0.16666666666666666, 'f1-score': 0.16949152542372883, 'support': 30}</td>\n",
       "      <td>{'precision': 0.41388888888888886, 'recall': 0.5457875457875457, 'f1-score': 0.47077409162717215, 'support': 273}</td>\n",
       "      <td>{'precision': 0.28695652173913044, 'recall': 0.3251231527093596, 'f1-score': 0.3048498845265589, 'support': 203}</td>\n",
       "      <td>0.283114</td>\n",
       "      <td>{'precision': 0.24813638978993294, 'recall': 0.1912388186462961, 'f1-score': 0.19835395188775765, 'support': 989}</td>\n",
       "      <td>{'precision': 0.25707011530509644, 'recall': 0.28311425682507585, 'f1-score': 0.26525196672387863, 'support': 989}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}</td>\n",
       "      <td>{'precision': 0.038461538461538464, 'recall': 0.023809523809523808, 'f1-score': 0.029411764705882353, 'support': 42}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.15217391304347827, 'f1-score': 0.17283950617283952, 'support': 92}</td>\n",
       "      <td>{'precision': 0.12903225806451613, 'recall': 0.0784313725490196, 'f1-score': 0.0975609756097561, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}</td>\n",
       "      <td>{'precision': 0.13333333333333333, 'recall': 0.11594202898550725, 'f1-score': 0.12403100775193798, 'support': 69}</td>\n",
       "      <td>{'precision': 0.12903225806451613, 'recall': 0.08602150537634409, 'f1-score': 0.1032258064516129, 'support': 93}</td>\n",
       "      <td>{'precision': 0.14457831325301204, 'recall': 0.10256410256410256, 'f1-score': 0.12, 'support': 117}</td>\n",
       "      <td>{'precision': 0.07692307692307693, 'recall': 0.06666666666666667, 'f1-score': 0.07142857142857144, 'support': 30}</td>\n",
       "      <td>{'precision': 0.37735849056603776, 'recall': 0.5147058823529411, 'f1-score': 0.4354587869362364, 'support': 272}</td>\n",
       "      <td>{'precision': 0.2459016393442623, 'recall': 0.2955665024630542, 'f1-score': 0.2684563758389262, 'support': 203}</td>\n",
       "      <td>0.251769</td>\n",
       "      <td>{'precision': 0.12288507566752442, 'recall': 0.1196567914842198, 'f1-score': 0.11853439957464691, 'support': 989}</td>\n",
       "      <td>{'precision': 0.22202115971265637, 'recall': 0.2517694641051567, 'f1-score': 0.23194597518841764, 'support': 989}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.11538461538461539, 'recall': 0.07317073170731707, 'f1-score': 0.08955223880597016, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.25882352941176473, 'recall': 0.2391304347826087, 'f1-score': 0.24858757062146894, 'support': 92}</td>\n",
       "      <td>{'precision': 0.15625, 'recall': 0.09803921568627451, 'f1-score': 0.12048192771084337, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.11594202898550725, 'f1-score': 0.14678899082568805, 'support': 69}</td>\n",
       "      <td>{'precision': 0.21333333333333335, 'recall': 0.1702127659574468, 'f1-score': 0.1893491124260355, 'support': 94}</td>\n",
       "      <td>{'precision': 0.1951219512195122, 'recall': 0.13675213675213677, 'f1-score': 0.16080402010050251, 'support': 117}</td>\n",
       "      <td>{'precision': 0.07142857142857142, 'recall': 0.06666666666666667, 'f1-score': 0.0689655172413793, 'support': 30}</td>\n",
       "      <td>{'precision': 0.4014778325123153, 'recall': 0.5992647058823529, 'f1-score': 0.48082595870206485, 'support': 272}</td>\n",
       "      <td>{'precision': 0.3106796116504854, 'recall': 0.3137254901960784, 'f1-score': 0.3121951219512195, 'support': 204}</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>{'precision': 0.1602082870783831, 'recall': 0.15107534805136574, 'f1-score': 0.15146253819876435, 'support': 989}</td>\n",
       "      <td>{'precision': 0.2708972233827844, 'recall': 0.3023255813953488, 'f1-score': 0.27903845808948774, 'support': 989}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   0  \\\n",
       "0  {'precision': 0.14285714285714285, 'recall': 0.25, 'f1-score': 0.18181818181818182, 'support': 4}   \n",
       "1  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                                    \n",
       "2  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                                    \n",
       "3  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                                    \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                                    \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                                    \n",
       "6  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                                    \n",
       "7  {'precision': 1.0, 'recall': 0.25, 'f1-score': 0.4, 'support': 4}                                   \n",
       "8  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}                                    \n",
       "9  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                                    \n",
       "\n",
       "                                                                                                                      1  \\\n",
       "0  {'precision': 0.03571428571428571, 'recall': 0.024390243902439025, 'f1-score': 0.028985507246376812, 'support': 41}    \n",
       "1  {'precision': 0.13043478260869565, 'recall': 0.07317073170731707, 'f1-score': 0.09375, 'support': 41}                  \n",
       "2  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}                                                      \n",
       "3  {'precision': 0.07142857142857142, 'recall': 0.04878048780487805, 'f1-score': 0.057971014492753624, 'support': 41}     \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}                                                      \n",
       "5  {'precision': 0.07692307692307693, 'recall': 0.04878048780487805, 'f1-score': 0.059701492537313446, 'support': 41}     \n",
       "6  {'precision': 0.15625, 'recall': 0.11904761904761904, 'f1-score': 0.13513513513513511, 'support': 42}                  \n",
       "7  {'precision': 0.075, 'recall': 0.07142857142857142, 'f1-score': 0.07317073170731707, 'support': 42}                    \n",
       "8  {'precision': 0.038461538461538464, 'recall': 0.023809523809523808, 'f1-score': 0.029411764705882353, 'support': 42}   \n",
       "9  {'precision': 0.11538461538461539, 'recall': 0.07317073170731707, 'f1-score': 0.08955223880597016, 'support': 41}      \n",
       "\n",
       "                                                                                    2  \\\n",
       "0  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "1  {'precision': 0.25, 'recall': 0.16666666666666666, 'f1-score': 0.2, 'support': 12}   \n",
       "2  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "3  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "6  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 11}                    \n",
       "7  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "8  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "9  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                    \n",
       "\n",
       "                                                                                                                  3  \\\n",
       "0  {'precision': 0.26666666666666666, 'recall': 0.21505376344086022, 'f1-score': 0.2380952380952381, 'support': 93}   \n",
       "1  {'precision': 0.2698412698412698, 'recall': 0.1827956989247312, 'f1-score': 0.21794871794871795, 'support': 93}    \n",
       "2  {'precision': 0.24561403508771928, 'recall': 0.15217391304347827, 'f1-score': 0.1879194630872483, 'support': 92}   \n",
       "3  {'precision': 0.3090909090909091, 'recall': 0.18478260869565216, 'f1-score': 0.23129251700680273, 'support': 92}   \n",
       "4  {'precision': 0.2857142857142857, 'recall': 0.2608695652173913, 'f1-score': 0.2727272727272727, 'support': 92}     \n",
       "5  {'precision': 0.2711864406779661, 'recall': 0.17391304347826086, 'f1-score': 0.2119205298013245, 'support': 92}    \n",
       "6  {'precision': 0.21052631578947367, 'recall': 0.17391304347826086, 'f1-score': 0.1904761904761905, 'support': 92}   \n",
       "7  {'precision': 0.2839506172839506, 'recall': 0.25, 'f1-score': 0.26589595375722547, 'support': 92}                  \n",
       "8  {'precision': 0.2, 'recall': 0.15217391304347827, 'f1-score': 0.17283950617283952, 'support': 92}                  \n",
       "9  {'precision': 0.25882352941176473, 'recall': 0.2391304347826087, 'f1-score': 0.24858757062146894, 'support': 92}   \n",
       "\n",
       "                                                                                                                    4  \\\n",
       "0  {'precision': 0.03225806451612903, 'recall': 0.0196078431372549, 'f1-score': 0.024390243902439025, 'support': 51}    \n",
       "1  {'precision': 0.10714285714285714, 'recall': 0.058823529411764705, 'f1-score': 0.07594936708860758, 'support': 51}   \n",
       "2  {'precision': 0.1891891891891892, 'recall': 0.1346153846153846, 'f1-score': 0.15730337078651685, 'support': 52}      \n",
       "3  {'precision': 0.08, 'recall': 0.0392156862745098, 'f1-score': 0.05263157894736842, 'support': 51}                    \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 51}                                                    \n",
       "5  {'precision': 0.03225806451612903, 'recall': 0.0196078431372549, 'f1-score': 0.024390243902439025, 'support': 51}    \n",
       "6  {'precision': 0.14705882352941177, 'recall': 0.09803921568627451, 'f1-score': 0.11764705882352941, 'support': 51}    \n",
       "7  {'precision': 0.08571428571428572, 'recall': 0.058823529411764705, 'f1-score': 0.06976744186046513, 'support': 51}   \n",
       "8  {'precision': 0.12903225806451613, 'recall': 0.0784313725490196, 'f1-score': 0.0975609756097561, 'support': 51}      \n",
       "9  {'precision': 0.15625, 'recall': 0.09803921568627451, 'f1-score': 0.12048192771084337, 'support': 51}                \n",
       "\n",
       "                                                                                                  5  \\\n",
       "0  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}                                   \n",
       "1  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "2  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "3  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "6  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "7  {'precision': 0.25, 'recall': 0.3333333333333333, 'f1-score': 0.28571428571428575, 'support': 3}   \n",
       "8  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}                                   \n",
       "9  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}                                   \n",
       "\n",
       "                                                                                                                    6  \\\n",
       "0  {'precision': 0.1206896551724138, 'recall': 0.10144927536231885, 'f1-score': 0.11023622047244096, 'support': 69}     \n",
       "1  {'precision': 0.175, 'recall': 0.1, 'f1-score': 0.12727272727272726, 'support': 70}                                  \n",
       "2  {'precision': 0.06666666666666667, 'recall': 0.04285714285714286, 'f1-score': 0.05217391304347826, 'support': 70}    \n",
       "3  {'precision': 0.09302325581395349, 'recall': 0.05714285714285714, 'f1-score': 0.07079646017699115, 'support': 70}    \n",
       "4  {'precision': 0.05128205128205128, 'recall': 0.02857142857142857, 'f1-score': 0.03669724770642202, 'support': 70}    \n",
       "5  {'precision': 0.10909090909090909, 'recall': 0.08571428571428572, 'f1-score': 0.096, 'support': 70}                  \n",
       "6  {'precision': 0.15384615384615385, 'recall': 0.08571428571428572, 'f1-score': 0.11009174311926605, 'support': 70}    \n",
       "7  {'precision': 0.10256410256410256, 'recall': 0.057971014492753624, 'f1-score': 0.07407407407407407, 'support': 69}   \n",
       "8  {'precision': 0.13333333333333333, 'recall': 0.11594202898550725, 'f1-score': 0.12403100775193798, 'support': 69}    \n",
       "9  {'precision': 0.2, 'recall': 0.11594202898550725, 'f1-score': 0.14678899082568805, 'support': 69}                    \n",
       "\n",
       "                                                                                                                   7  \\\n",
       "0  {'precision': 0.1625, 'recall': 0.13829787234042554, 'f1-score': 0.14942528735632185, 'support': 94}                \n",
       "1  {'precision': 0.18840579710144928, 'recall': 0.13829787234042554, 'f1-score': 0.15950920245398775, 'support': 94}   \n",
       "2  {'precision': 0.18571428571428572, 'recall': 0.13978494623655913, 'f1-score': 0.15950920245398773, 'support': 93}   \n",
       "3  {'precision': 0.14444444444444443, 'recall': 0.13978494623655913, 'f1-score': 0.14207650273224043, 'support': 93}   \n",
       "4  {'precision': 0.1951219512195122, 'recall': 0.17204301075268819, 'f1-score': 0.18285714285714288, 'support': 93}    \n",
       "5  {'precision': 0.15053763440860216, 'recall': 0.15053763440860216, 'f1-score': 0.15053763440860216, 'support': 93}   \n",
       "6  {'precision': 0.16393442622950818, 'recall': 0.10752688172043011, 'f1-score': 0.12987012987012989, 'support': 93}   \n",
       "7  {'precision': 0.14925373134328357, 'recall': 0.10752688172043011, 'f1-score': 0.125, 'support': 93}                 \n",
       "8  {'precision': 0.12903225806451613, 'recall': 0.08602150537634409, 'f1-score': 0.1032258064516129, 'support': 93}    \n",
       "9  {'precision': 0.21333333333333335, 'recall': 0.1702127659574468, 'f1-score': 0.1893491124260355, 'support': 94}     \n",
       "\n",
       "                                                                                                                    8  \\\n",
       "0  {'precision': 0.1917808219178082, 'recall': 0.11965811965811966, 'f1-score': 0.14736842105263157, 'support': 117}    \n",
       "1  {'precision': 0.16923076923076924, 'recall': 0.09322033898305085, 'f1-score': 0.12021857923497266, 'support': 118}   \n",
       "2  {'precision': 0.14942528735632185, 'recall': 0.11016949152542373, 'f1-score': 0.12682926829268293, 'support': 118}   \n",
       "3  {'precision': 0.1518987341772152, 'recall': 0.1016949152542373, 'f1-score': 0.12182741116751271, 'support': 118}     \n",
       "4  {'precision': 0.13541666666666666, 'recall': 0.11016949152542373, 'f1-score': 0.12149532710280372, 'support': 118}   \n",
       "5  {'precision': 0.1686746987951807, 'recall': 0.11965811965811966, 'f1-score': 0.14, 'support': 117}                   \n",
       "6  {'precision': 0.10526315789473684, 'recall': 0.08547008547008547, 'f1-score': 0.09433962264150944, 'support': 117}   \n",
       "7  {'precision': 0.15789473684210525, 'recall': 0.1282051282051282, 'f1-score': 0.14150943396226415, 'support': 117}    \n",
       "8  {'precision': 0.14457831325301204, 'recall': 0.10256410256410256, 'f1-score': 0.12, 'support': 117}                  \n",
       "9  {'precision': 0.1951219512195122, 'recall': 0.13675213675213677, 'f1-score': 0.16080402010050251, 'support': 117}    \n",
       "\n",
       "                                                                                                                    9  \\\n",
       "0  {'precision': 0.10526315789473684, 'recall': 0.06666666666666667, 'f1-score': 0.0816326530612245, 'support': 30}     \n",
       "1  {'precision': 0.21052631578947367, 'recall': 0.13333333333333333, 'f1-score': 0.163265306122449, 'support': 30}      \n",
       "2  {'precision': 0.13333333333333333, 'recall': 0.12903225806451613, 'f1-score': 0.13114754098360656, 'support': 31}    \n",
       "3  {'precision': 0.14285714285714285, 'recall': 0.12903225806451613, 'f1-score': 0.13559322033898305, 'support': 31}    \n",
       "4  {'precision': 0.15384615384615385, 'recall': 0.12903225806451613, 'f1-score': 0.14035087719298245, 'support': 31}    \n",
       "5  {'precision': 0.045454545454545456, 'recall': 0.03225806451612903, 'f1-score': 0.03773584905660377, 'support': 31}   \n",
       "6  {'precision': 0.125, 'recall': 0.0967741935483871, 'f1-score': 0.10909090909090909, 'support': 31}                   \n",
       "7  {'precision': 0.1724137931034483, 'recall': 0.16666666666666666, 'f1-score': 0.16949152542372883, 'support': 30}     \n",
       "8  {'precision': 0.07692307692307693, 'recall': 0.06666666666666667, 'f1-score': 0.07142857142857144, 'support': 30}    \n",
       "9  {'precision': 0.07142857142857142, 'recall': 0.06666666666666667, 'f1-score': 0.0689655172413793, 'support': 30}     \n",
       "\n",
       "                                                                                                                  10  \\\n",
       "0  {'precision': 0.39313984168865435, 'recall': 0.5477941176470589, 'f1-score': 0.4577572964669739, 'support': 272}    \n",
       "1  {'precision': 0.3793859649122807, 'recall': 0.6360294117647058, 'f1-score': 0.4752747252747253, 'support': 272}     \n",
       "2  {'precision': 0.32754342431761785, 'recall': 0.4852941176470588, 'f1-score': 0.3911111111111111, 'support': 272}    \n",
       "3  {'precision': 0.4005102040816326, 'recall': 0.575091575091575, 'f1-score': 0.4721804511278195, 'support': 273}      \n",
       "4  {'precision': 0.3896457765667575, 'recall': 0.5238095238095238, 'f1-score': 0.44687499999999997, 'support': 273}    \n",
       "5  {'precision': 0.41578947368421054, 'recall': 0.5787545787545788, 'f1-score': 0.4839203675344564, 'support': 273}    \n",
       "6  {'precision': 0.39540816326530615, 'recall': 0.5677655677655677, 'f1-score': 0.4661654135338346, 'support': 273}    \n",
       "7  {'precision': 0.41388888888888886, 'recall': 0.5457875457875457, 'f1-score': 0.47077409162717215, 'support': 273}   \n",
       "8  {'precision': 0.37735849056603776, 'recall': 0.5147058823529411, 'f1-score': 0.4354587869362364, 'support': 272}    \n",
       "9  {'precision': 0.4014778325123153, 'recall': 0.5992647058823529, 'f1-score': 0.48082595870206485, 'support': 272}    \n",
       "\n",
       "                                                                                                                   11  \\\n",
       "0  {'precision': 0.2445414847161572, 'recall': 0.27450980392156865, 'f1-score': 0.2586605080831409, 'support': 204}     \n",
       "1  {'precision': 0.27906976744186046, 'recall': 0.2955665024630542, 'f1-score': 0.28708133971291866, 'support': 203}    \n",
       "2  {'precision': 0.26222222222222225, 'recall': 0.29064039408866993, 'f1-score': 0.2757009345794393, 'support': 203}    \n",
       "3  {'precision': 0.2742616033755274, 'recall': 0.32019704433497537, 'f1-score': 0.29545454545454547, 'support': 203}    \n",
       "4  {'precision': 0.2818181818181818, 'recall': 0.3054187192118227, 'f1-score': 0.2931442080378251, 'support': 203}      \n",
       "5  {'precision': 0.22026431718061673, 'recall': 0.24630541871921183, 'f1-score': 0.23255813953488372, 'support': 203}   \n",
       "6  {'precision': 0.2672811059907834, 'recall': 0.2857142857142857, 'f1-score': 0.27619047619047615, 'support': 203}     \n",
       "7  {'precision': 0.28695652173913044, 'recall': 0.3251231527093596, 'f1-score': 0.3048498845265589, 'support': 203}     \n",
       "8  {'precision': 0.2459016393442623, 'recall': 0.2955665024630542, 'f1-score': 0.2684563758389262, 'support': 203}      \n",
       "9  {'precision': 0.3106796116504854, 'recall': 0.3137254901960784, 'f1-score': 0.3121951219512195, 'support': 204}      \n",
       "\n",
       "   accuracy  \\\n",
       "0  0.266667   \n",
       "1  0.295960   \n",
       "2  0.247475   \n",
       "3  0.278788   \n",
       "4  0.266667   \n",
       "5  0.264914   \n",
       "6  0.270981   \n",
       "7  0.283114   \n",
       "8  0.251769   \n",
       "9  0.302326   \n",
       "\n",
       "                                                                                                            macro avg  \\\n",
       "0  {'precision': 0.14128426009533288, 'recall': 0.14645230883972604, 'f1-score': 0.13986412979624743, 'support': 990}   \n",
       "1  {'precision': 0.179919793672388, 'recall': 0.1564920071329208, 'f1-score': 0.16002249709242553, 'support': 990}      \n",
       "2  {'precision': 0.1299757036572797, 'recall': 0.12371397067318612, 'f1-score': 0.12347456702817257, 'support': 990}    \n",
       "3  {'precision': 0.13895957210578305, 'recall': 0.13297686490831334, 'f1-score': 0.13165197512041807, 'support': 990}   \n",
       "4  {'precision': 0.12440375559280074, 'recall': 0.1274928330960662, 'f1-score': 0.1245122563020374, 'support': 990}     \n",
       "5  {'precision': 0.12418159672760305, 'recall': 0.1212941230159434, 'f1-score': 0.11973035473130193, 'support': 989}    \n",
       "6  {'precision': 0.1437140122121145, 'recall': 0.13499709817876637, 'f1-score': 0.13575055657341503, 'support': 989}    \n",
       "7  {'precision': 0.24813638978993294, 'recall': 0.1912388186462961, 'f1-score': 0.19835395188775765, 'support': 989}    \n",
       "8  {'precision': 0.12288507566752442, 'recall': 0.1196567914842198, 'f1-score': 0.11853439957464691, 'support': 989}    \n",
       "9  {'precision': 0.1602082870783831, 'recall': 0.15107534805136574, 'f1-score': 0.15146253819876435, 'support': 989}    \n",
       "\n",
       "                                                                                                         weighted avg  \n",
       "0  {'precision': 0.23686890152077691, 'recall': 0.26666666666666666, 'f1-score': 0.2463863913871926, 'support': 990}   \n",
       "1  {'precision': 0.2575723841553228, 'recall': 0.295959595959596, 'f1-score': 0.2635609527276399, 'support': 990}      \n",
       "2  {'precision': 0.22066753946554116, 'recall': 0.2474747474747475, 'f1-score': 0.22761195454249175, 'support': 990}   \n",
       "3  {'precision': 0.24520899956186437, 'recall': 0.2787878787878788, 'f1-score': 0.25451551604553, 'support': 990}      \n",
       "4  {'precision': 0.23469958049150066, 'recall': 0.26666666666666666, 'f1-score': 0.24733121791804513, 'support': 990}  \n",
       "5  {'precision': 0.2333192487305227, 'recall': 0.2649140546006067, 'f1-score': 0.2434557394924356, 'support': 989}     \n",
       "6  {'precision': 0.24048668960813793, 'recall': 0.27098078867542974, 'f1-score': 0.2494774599474562, 'support': 989}   \n",
       "7  {'precision': 0.25707011530509644, 'recall': 0.28311425682507585, 'f1-score': 0.26525196672387863, 'support': 989}  \n",
       "8  {'precision': 0.22202115971265637, 'recall': 0.2517694641051567, 'f1-score': 0.23194597518841764, 'support': 989}   \n",
       "9  {'precision': 0.2708972233827844, 'recall': 0.3023255813953488, 'f1-score': 0.27903845808948774, 'support': 989}    "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_reports_df = pd.DataFrame(classification_reports)\n",
    "classification_reports_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.295960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.264914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.270981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.283114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.251769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.302326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy\n",
       "0  0.266667\n",
       "1  0.295960\n",
       "2  0.247475\n",
       "3  0.278788\n",
       "4  0.266667\n",
       "5  0.264914\n",
       "6  0.270981\n",
       "7  0.283114\n",
       "8  0.251769\n",
       "9  0.302326"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_report = classification_reports_df.groupby(classification_reports_df.index).mean()\n",
    "mean_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_support</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.3</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92.2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.1</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>69.6</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>93.3</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>117.4</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>272.5</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>203.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>989.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class  avg_support  avg_precision  avg_recall  avg_f1_score\n",
       "0   0             4.1          0.11           0.05        0.06        \n",
       "1   1             41.3         0.07           0.05        0.06        \n",
       "2   2             11.9         0.02           0.02        0.02        \n",
       "3   3             92.2         0.26           0.20        0.22        \n",
       "4   4             51.1         0.10           0.06        0.07        \n",
       "5   5             2.4          0.02           0.03        0.03        \n",
       "6   6             69.6         0.12           0.08        0.09        \n",
       "7   7             93.3         0.17           0.14        0.15        \n",
       "8   8             117.4        0.16           0.11        0.13        \n",
       "9   9             30.5         0.12           0.10        0.11        \n",
       "10  10            272.5        0.39           0.56        0.46        \n",
       "11  11            203.2        0.27           0.30        0.28        \n",
       "12  macro avg     989.5        0.15           0.14        0.14        \n",
       "13  weighted avg  989.5        0.24           0.27        0.25        "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_reports_df_wa = classification_reports_df.drop(columns='accuracy')\n",
    "\n",
    "\n",
    "averages_stage2 = {}\n",
    "\n",
    "\n",
    "for class_label, dicts in classification_reports_df_wa.items():\n",
    "    metric_sums = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0}\n",
    "    \n",
    "    for metric_dict in dicts:\n",
    "        metric_sums['precision'] += metric_dict['precision']\n",
    "        metric_sums['recall'] += metric_dict['recall']\n",
    "        metric_sums['f1-score'] += metric_dict['f1-score']\n",
    "        metric_sums['support'] += metric_dict['support']\n",
    "    \n",
    "    averages_stage2[class_label] = {\n",
    "        'avg_support': metric_sums['support'] / len(dicts),\n",
    "        'avg_precision': metric_sums['precision'] / len(dicts),\n",
    "        'avg_recall': metric_sums['recall'] / len(dicts),\n",
    "        'avg_f1_score': metric_sums['f1-score'] / len(dicts)\n",
    "    }\n",
    "averages__stage2_df = pd.DataFrame(averages_stage2).T\n",
    "\n",
    "averages__stage2_df['avg_precision'] = averages__stage2_df['avg_precision'].round(2)\n",
    "averages__stage2_df['avg_recall'] = averages__stage2_df['avg_recall'].round(2)\n",
    "averages__stage2_df['avg_f1_score'] = averages__stage2_df['avg_f1_score'].round(2)\n",
    "averages__stage2_df['avg_support'] = averages__stage2_df['avg_support'].round(2)\n",
    "\n",
    "\n",
    "averages__stage2_df.reset_index(inplace=True)\n",
    "averages__stage2_df.rename(columns={'index': 'class'}, inplace=True)\n",
    "\n",
    "averages__stage2_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing it only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputing for smote, the nan values are only in perc_external_contribs\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_non_merged_imputed = imputer.fit_transform(X_non_merged)\n",
    "\n",
    "X_train_non_merged, X_test_non_merged, y_train_non_merged, y_test_non_merged = train_test_split(X_non_merged_imputed, y_non_merged, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_non_merged_smote, y_train_non_merged_smote = smote.fit_resample(X_train_non_merged, y_train_non_merged)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_non_merged = xgb.XGBClassifier()\n",
    "model_non_merged.fit(X_train_non_merged_smote, y_train_non_merged_smote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 2 - Classification Report for Non-merged Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         9\n",
      "           1       0.06      0.05      0.05        87\n",
      "           2       0.06      0.04      0.05        25\n",
      "           3       0.21      0.20      0.21       166\n",
      "           4       0.06      0.04      0.05       103\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.15      0.06      0.09       155\n",
      "           7       0.14      0.11      0.12       207\n",
      "           8       0.17      0.12      0.14       229\n",
      "           9       0.11      0.10      0.10        62\n",
      "          10       0.37      0.55      0.44       530\n",
      "          11       0.24      0.26      0.25       398\n",
      "\n",
      "    accuracy                           0.25      1979\n",
      "   macro avg       0.13      0.13      0.12      1979\n",
      "weighted avg       0.22      0.25      0.23      1979\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_non_merged = model_non_merged.predict(X_test_non_merged)\n",
    "print(\"Stage 2 - Classification Report for Non-merged Data:\\n\", classification_report(y_test_non_merged, predictions_non_merged))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stage 2 without Smote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_non_merged, X_test_non_merged, y_train_non_merged, y_test_non_merged = train_test_split(X_non_merged, y_non_merged, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Stage 2 - Non-merged Data:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.00      0.00      0.00        87\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.33      0.18      0.23       181\n",
      "           4       0.16      0.03      0.05       101\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.08      0.02      0.03       146\n",
      "           7       0.19      0.12      0.15       194\n",
      "           8       0.19      0.12      0.15       247\n",
      "           9       0.19      0.05      0.07        65\n",
      "          10       0.37      0.62      0.46       539\n",
      "          11       0.25      0.37      0.30       409\n",
      "\n",
      "    accuracy                           0.29      1997\n",
      "   macro avg       0.15      0.13      0.12      1997\n",
      "weighted avg       0.24      0.29      0.25      1997\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_non_merged = xgb.XGBClassifier()\n",
    "model_non_merged.fit(X_train_non_merged, y_train_non_merged)\n",
    "\n",
    "# Predictions and evaluation\n",
    "predictions_non_merged = model_non_merged.predict(X_test_non_merged)\n",
    "print(\"Classification Report for Stage 2 - Non-merged Data:\\n\", classification_report(y_test_non_merged, predictions_non_merged))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaotic: 0\n",
    "Duplicate: 1\n",
    "Merge Conflict: 2\n",
    "No Comment: 3\n",
    "No Reason: 4\n",
    "Not PR: 5\n",
    "Quality: 6\n",
    "Replaced: 7\n",
    "Resolved: 8\n",
    "Stale: 9\n",
    "Successful: 10\n",
    "Unnecessary: 11\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_merged_data = consistently_correct_df[consistently_correct_df['status'] == 1]\n",
    "X_non_merged = non_merged_data.drop(['status', 'manual_analysis', 'pr_id','repo_id', 'Consistently_Correct'], axis=1)\n",
    "y_non_merged = non_merged_data['manual_analysis']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only doing one stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_merged_data = df[df['status'] == 1]\n",
    "imputer = SimpleImputer(strategy='mean')  \n",
    "X_non_merged = non_merged_data.drop(['status', 'manual_analysis', 'pr_id','repo_id'], axis=1)\n",
    "X_non_merged_imputed = imputer.fit_transform(X_non_merged)\n",
    "y_non_merged = non_merged_data['manual_analysis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pr_id                     9949\n",
       "commit_counts             9949\n",
       "prs_experience            9949\n",
       "prs_succ_rate             9949\n",
       "prs_popularity            9949\n",
       "prs_followed_pri          9949\n",
       "prs_watched_repo          9949\n",
       "prs_tenure_mnth           9949\n",
       "prs_main_team_member      9949\n",
       "repo_pr_tenure_mnth       9949\n",
       "repo_pr_popularity        9949\n",
       "repo_pr_team_size         9949\n",
       "perc_external_contribs    9719\n",
       "intra_branch              9949\n",
       "pr_files_changed          9949\n",
       "pr_lines_changed          9949\n",
       "repo_id                   9949\n",
       "status                    9949\n",
       "manual_analysis           9949\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_merged_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/amirrshams/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "classification_reports = []\n",
    "\n",
    "for train_index, test_index in skf.split(X_non_merged_imputed, y_non_merged):\n",
    "    x_train_fold, x_test_fold = X_non_merged_imputed[train_index], X_non_merged_imputed[test_index]\n",
    "    y_train_fold, y_test_fold = y_non_merged.iloc[train_index], y_non_merged.iloc[test_index]\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    x_train_fold_smote, y_train_fold_smote = smote.fit_resample(x_train_fold, y_train_fold)\n",
    "\n",
    "    model_non_merged = xgb.XGBClassifier()\n",
    "    model_non_merged.fit(x_train_fold_smote, y_train_fold_smote)\n",
    "\n",
    "    y_pred_fold = model_non_merged.predict(x_test_fold)\n",
    "\n",
    "    report = classification_report(y_test_fold, y_pred_fold, output_dict=True)\n",
    "    classification_reports.append(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'precision': 0.5, 'recall': 0.25, 'f1-score': 0.3333333333333333, 'support': 4}</td>\n",
       "      <td>{'precision': 0.045454545454545456, 'recall': 0.023809523809523808, 'f1-score': 0.03125, 'support': 42}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.23684210526315788, 'recall': 0.1935483870967742, 'f1-score': 0.21301775147928992, 'support': 93}</td>\n",
       "      <td>{'precision': 0.02857142857142857, 'recall': 0.0196078431372549, 'f1-score': 0.023255813953488372, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.1891891891891892, 'recall': 0.10144927536231885, 'f1-score': 0.1320754716981132, 'support': 69}</td>\n",
       "      <td>{'precision': 0.18840579710144928, 'recall': 0.1368421052631579, 'f1-score': 0.15853658536585363, 'support': 95}</td>\n",
       "      <td>{'precision': 0.17894736842105263, 'recall': 0.1440677966101695, 'f1-score': 0.1596244131455399, 'support': 118}</td>\n",
       "      <td>{'precision': 0.058823529411764705, 'recall': 0.06451612903225806, 'f1-score': 0.061538461538461535, 'support': 31}</td>\n",
       "      <td>{'precision': 0.382051282051282, 'recall': 0.5457875457875457, 'f1-score': 0.44947209653092, 'support': 273}</td>\n",
       "      <td>{'precision': 0.24444444444444444, 'recall': 0.2682926829268293, 'f1-score': 0.2558139534883721, 'support': 205}</td>\n",
       "      <td>0.265327</td>\n",
       "      <td>{'precision': 0.1710608074923595, 'recall': 0.14566010741881935, 'f1-score': 0.15149315671111432, 'support': 995}</td>\n",
       "      <td>{'precision': 0.23687998425222032, 'recall': 0.26532663316582916, 'f1-score': 0.2449324922275222, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.09090909090909091, 'recall': 0.07142857142857142, 'f1-score': 0.08, 'support': 42}</td>\n",
       "      <td>{'precision': 0.09090909090909091, 'recall': 0.08333333333333333, 'f1-score': 0.08695652173913043, 'support': 12}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.1827956989247312, 'f1-score': 0.2111801242236025, 'support': 93}</td>\n",
       "      <td>{'precision': 0.09090909090909091, 'recall': 0.058823529411764705, 'f1-score': 0.07142857142857142, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}</td>\n",
       "      <td>{'precision': 0.15625, 'recall': 0.07246376811594203, 'f1-score': 0.09900990099009901, 'support': 69}</td>\n",
       "      <td>{'precision': 0.20987654320987653, 'recall': 0.17894736842105263, 'f1-score': 0.19318181818181818, 'support': 95}</td>\n",
       "      <td>{'precision': 0.1724137931034483, 'recall': 0.1271186440677966, 'f1-score': 0.14634146341463414, 'support': 118}</td>\n",
       "      <td>{'precision': 0.08571428571428572, 'recall': 0.1, 'f1-score': 0.09230769230769231, 'support': 30}</td>\n",
       "      <td>{'precision': 0.41274238227146814, 'recall': 0.5457875457875457, 'f1-score': 0.47003154574132494, 'support': 273}</td>\n",
       "      <td>{'precision': 0.24596774193548387, 'recall': 0.2975609756097561, 'f1-score': 0.2693156732891832, 'support': 205}</td>\n",
       "      <td>0.275377</td>\n",
       "      <td>{'precision': 0.15047433491348627, 'recall': 0.1431882862583745, 'f1-score': 0.14331277594300468, 'support': 995}</td>\n",
       "      <td>{'precision': 0.2507872258943852, 'recall': 0.27537688442211056, 'f1-score': 0.25772451388535994, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.02702702702702703, 'recall': 0.023809523809523808, 'f1-score': 0.02531645569620253, 'support': 42}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2112676056338028, 'recall': 0.16129032258064516, 'f1-score': 0.18292682926829265, 'support': 93}</td>\n",
       "      <td>{'precision': 0.13793103448275862, 'recall': 0.0784313725490196, 'f1-score': 0.1, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}</td>\n",
       "      <td>{'precision': 0.1, 'recall': 0.057971014492753624, 'f1-score': 0.07339449541284403, 'support': 69}</td>\n",
       "      <td>{'precision': 0.3103448275862069, 'recall': 0.28421052631578947, 'f1-score': 0.2967032967032967, 'support': 95}</td>\n",
       "      <td>{'precision': 0.23404255319148937, 'recall': 0.1864406779661017, 'f1-score': 0.20754716981132076, 'support': 118}</td>\n",
       "      <td>{'precision': 0.07407407407407407, 'recall': 0.06666666666666667, 'f1-score': 0.07017543859649124, 'support': 30}</td>\n",
       "      <td>{'precision': 0.3974358974358974, 'recall': 0.5677655677655677, 'f1-score': 0.4675716440422323, 'support': 273}</td>\n",
       "      <td>{'precision': 0.2975609756097561, 'recall': 0.2975609756097561, 'f1-score': 0.2975609756097561, 'support': 205}</td>\n",
       "      <td>0.292462</td>\n",
       "      <td>{'precision': 0.14914033292008436, 'recall': 0.1436788873129853, 'f1-score': 0.1434330254283697, 'support': 995}</td>\n",
       "      <td>{'precision': 0.26486382646955486, 'recall': 0.29246231155778896, 'f1-score': 0.2730345805534182, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2716049382716049, 'recall': 0.23655913978494625, 'f1-score': 0.2528735632183908, 'support': 93}</td>\n",
       "      <td>{'precision': 0.038461538461538464, 'recall': 0.0196078431372549, 'f1-score': 0.025974025974025976, 'support': 51}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.3333333333333333, 'f1-score': 0.28571428571428575, 'support': 3}</td>\n",
       "      <td>{'precision': 0.1891891891891892, 'recall': 0.1, 'f1-score': 0.1308411214953271, 'support': 70}</td>\n",
       "      <td>{'precision': 0.19736842105263158, 'recall': 0.15789473684210525, 'f1-score': 0.17543859649122806, 'support': 95}</td>\n",
       "      <td>{'precision': 0.16279069767441862, 'recall': 0.11864406779661017, 'f1-score': 0.1372549019607843, 'support': 118}</td>\n",
       "      <td>{'precision': 0.25, 'recall': 0.1935483870967742, 'f1-score': 0.21818181818181817, 'support': 31}</td>\n",
       "      <td>{'precision': 0.37965260545905705, 'recall': 0.5604395604395604, 'f1-score': 0.45266272189349116, 'support': 273}</td>\n",
       "      <td>{'precision': 0.27232142857142855, 'recall': 0.29901960784313725, 'f1-score': 0.2850467289719626, 'support': 204}</td>\n",
       "      <td>0.281407</td>\n",
       "      <td>{'precision': 0.16761573488998902, 'recall': 0.16825388968947683, 'f1-score': 0.16366564699177613, 'support': 995}</td>\n",
       "      <td>{'precision': 0.24735887036031795, 'recall': 0.2814070351758794, 'f1-score': 0.2574982666479201, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.23529411764705882, 'recall': 0.17204301075268819, 'f1-score': 0.19875776397515527, 'support': 93}</td>\n",
       "      <td>{'precision': 0.06896551724137931, 'recall': 0.0392156862745098, 'f1-score': 0.05, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}</td>\n",
       "      <td>{'precision': 0.1282051282051282, 'recall': 0.07142857142857142, 'f1-score': 0.09174311926605504, 'support': 70}</td>\n",
       "      <td>{'precision': 0.17567567567567569, 'recall': 0.1368421052631579, 'f1-score': 0.15384615384615385, 'support': 95}</td>\n",
       "      <td>{'precision': 0.1411764705882353, 'recall': 0.1016949152542373, 'f1-score': 0.11822660098522167, 'support': 118}</td>\n",
       "      <td>{'precision': 0.038461538461538464, 'recall': 0.03225806451612903, 'f1-score': 0.03508771929824561, 'support': 31}</td>\n",
       "      <td>{'precision': 0.37532133676092544, 'recall': 0.5347985347985348, 'f1-score': 0.4410876132930513, 'support': 273}</td>\n",
       "      <td>{'precision': 0.2631578947368421, 'recall': 0.31862745098039214, 'f1-score': 0.28824833702882485, 'support': 204}</td>\n",
       "      <td>0.261307</td>\n",
       "      <td>{'precision': 0.11885480660973193, 'recall': 0.11724236160568503, 'f1-score': 0.11474977564105897, 'support': 995}</td>\n",
       "      <td>{'precision': 0.22619217001789232, 'recall': 0.2613065326633166, 'f1-score': 0.23751749991063614, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2676056338028169, 'recall': 0.20430107526881722, 'f1-score': 0.23170731707317072, 'support': 93}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.1, 'recall': 0.05714285714285714, 'f1-score': 0.07272727272727272, 'support': 70}</td>\n",
       "      <td>{'precision': 0.1506849315068493, 'recall': 0.11578947368421053, 'f1-score': 0.13095238095238096, 'support': 95}</td>\n",
       "      <td>{'precision': 0.11956521739130435, 'recall': 0.09243697478991597, 'f1-score': 0.1042654028436019, 'support': 119}</td>\n",
       "      <td>{'precision': 0.037037037037037035, 'recall': 0.03225806451612903, 'f1-score': 0.034482758620689655, 'support': 31}</td>\n",
       "      <td>{'precision': 0.3946078431372549, 'recall': 0.5897435897435898, 'f1-score': 0.47283406754772395, 'support': 273}</td>\n",
       "      <td>{'precision': 0.27111111111111114, 'recall': 0.29901960784313725, 'f1-score': 0.2843822843822844, 'support': 204}</td>\n",
       "      <td>0.269347</td>\n",
       "      <td>{'precision': 0.11171764783219779, 'recall': 0.11589097024905474, 'f1-score': 0.11094595701226036, 'support': 995}</td>\n",
       "      <td>{'precision': 0.225742119897149, 'recall': 0.2693467336683417, 'f1-score': 0.2408586941500853, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.03571428571428571, 'recall': 0.024390243902439025, 'f1-score': 0.028985507246376812, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2692307692307692, 'recall': 0.22580645161290322, 'f1-score': 0.2456140350877193, 'support': 93}</td>\n",
       "      <td>{'precision': 0.10526315789473684, 'recall': 0.0784313725490196, 'f1-score': 0.0898876404494382, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.1388888888888889, 'recall': 0.07142857142857142, 'f1-score': 0.09433962264150943, 'support': 70}</td>\n",
       "      <td>{'precision': 0.20987654320987653, 'recall': 0.17894736842105263, 'f1-score': 0.19318181818181818, 'support': 95}</td>\n",
       "      <td>{'precision': 0.13580246913580246, 'recall': 0.09243697478991597, 'f1-score': 0.11, 'support': 119}</td>\n",
       "      <td>{'precision': 0.16666666666666666, 'recall': 0.0967741935483871, 'f1-score': 0.12244897959183673, 'support': 31}</td>\n",
       "      <td>{'precision': 0.38734177215189874, 'recall': 0.5604395604395604, 'f1-score': 0.4580838323353293, 'support': 273}</td>\n",
       "      <td>{'precision': 0.25892857142857145, 'recall': 0.28431372549019607, 'f1-score': 0.27102803738317754, 'support': 204}</td>\n",
       "      <td>0.274372</td>\n",
       "      <td>{'precision': 0.14230942702679136, 'recall': 0.13441403851517045, 'f1-score': 0.13446412274310046, 'support': 995}</td>\n",
       "      <td>{'precision': 0.2426377437138326, 'recall': 0.2743718592964824, 'f1-score': 0.2520636696044414, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}</td>\n",
       "      <td>{'precision': 0.09523809523809523, 'recall': 0.04878048780487805, 'f1-score': 0.06451612903225808, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2857142857142857, 'recall': 0.21739130434782608, 'f1-score': 0.24691358024691357, 'support': 92}</td>\n",
       "      <td>{'precision': 0.038461538461538464, 'recall': 0.019230769230769232, 'f1-score': 0.025641025641025644, 'support': 52}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 70}</td>\n",
       "      <td>{'precision': 0.1323529411764706, 'recall': 0.09473684210526316, 'f1-score': 0.11042944785276074, 'support': 95}</td>\n",
       "      <td>{'precision': 0.1625, 'recall': 0.1092436974789916, 'f1-score': 0.13065326633165827, 'support': 119}</td>\n",
       "      <td>{'precision': 0.08, 'recall': 0.06451612903225806, 'f1-score': 0.07142857142857142, 'support': 31}</td>\n",
       "      <td>{'precision': 0.4, 'recall': 0.5934065934065934, 'f1-score': 0.4778761061946903, 'support': 273}</td>\n",
       "      <td>{'precision': 0.2869198312236287, 'recall': 0.3333333333333333, 'f1-score': 0.30839002267573695, 'support': 204}</td>\n",
       "      <td>0.278392</td>\n",
       "      <td>{'precision': 0.12343222431783489, 'recall': 0.12338659639499273, 'f1-score': 0.11965401245030126, 'support': 995}</td>\n",
       "      <td>{'precision': 0.2354906041928253, 'recall': 0.27839195979899495, 'f1-score': 0.24956694228858098, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}</td>\n",
       "      <td>{'precision': 0.03571428571428571, 'recall': 0.024390243902439025, 'f1-score': 0.028985507246376812, 'support': 41}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}</td>\n",
       "      <td>{'precision': 0.2441860465116279, 'recall': 0.22826086956521738, 'f1-score': 0.23595505617977527, 'support': 92}</td>\n",
       "      <td>{'precision': 0.08163265306122448, 'recall': 0.07692307692307693, 'f1-score': 0.07920792079207921, 'support': 52}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.11320754716981132, 'recall': 0.08571428571428572, 'f1-score': 0.0975609756097561, 'support': 70}</td>\n",
       "      <td>{'precision': 0.18292682926829268, 'recall': 0.15789473684210525, 'f1-score': 0.1694915254237288, 'support': 95}</td>\n",
       "      <td>{'precision': 0.1927710843373494, 'recall': 0.13445378151260504, 'f1-score': 0.15841584158415842, 'support': 119}</td>\n",
       "      <td>{'precision': 0.2, 'recall': 0.12903225806451613, 'f1-score': 0.1568627450980392, 'support': 31}</td>\n",
       "      <td>{'precision': 0.40691489361702127, 'recall': 0.5625, 'f1-score': 0.4722222222222222, 'support': 272}</td>\n",
       "      <td>{'precision': 0.27751196172248804, 'recall': 0.28431372549019607, 'f1-score': 0.28087167070217917, 'support': 204}</td>\n",
       "      <td>0.279397</td>\n",
       "      <td>{'precision': 0.14457210845017507, 'recall': 0.14029024816787014, 'f1-score': 0.1399644554048596, 'support': 995}</td>\n",
       "      <td>{'precision': 0.25116575610680975, 'recall': 0.2793969849246231, 'f1-score': 0.26070607192865236, 'support': 995}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'precision': 0.25, 'recall': 0.2, 'f1-score': 0.22222222222222224, 'support': 5}</td>\n",
       "      <td>{'precision': 0.13793103448275862, 'recall': 0.09523809523809523, 'f1-score': 0.11267605633802817, 'support': 42}</td>\n",
       "      <td>{'precision': 0.1, 'recall': 0.09090909090909091, 'f1-score': 0.09523809523809525, 'support': 11}</td>\n",
       "      <td>{'precision': 0.2564102564102564, 'recall': 0.21739130434782608, 'f1-score': 0.23529411764705882, 'support': 92}</td>\n",
       "      <td>{'precision': 0.08823529411764706, 'recall': 0.058823529411764705, 'f1-score': 0.07058823529411765, 'support': 51}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}</td>\n",
       "      <td>{'precision': 0.1509433962264151, 'recall': 0.11428571428571428, 'f1-score': 0.13008130081300812, 'support': 70}</td>\n",
       "      <td>{'precision': 0.2028985507246377, 'recall': 0.14736842105263157, 'f1-score': 0.17073170731707316, 'support': 95}</td>\n",
       "      <td>{'precision': 0.2465753424657534, 'recall': 0.15254237288135594, 'f1-score': 0.18848167539267016, 'support': 118}</td>\n",
       "      <td>{'precision': 0.17647058823529413, 'recall': 0.0967741935483871, 'f1-score': 0.125, 'support': 31}</td>\n",
       "      <td>{'precision': 0.3875, 'recall': 0.5677655677655677, 'f1-score': 0.4606240713224369, 'support': 273}</td>\n",
       "      <td>{'precision': 0.2920353982300885, 'recall': 0.3235294117647059, 'f1-score': 0.30697674418604654, 'support': 204}</td>\n",
       "      <td>0.294769</td>\n",
       "      <td>{'precision': 0.19074998840773758, 'recall': 0.17205230843376162, 'f1-score': 0.17649285214756308, 'support': 994}</td>\n",
       "      <td>{'precision': 0.26760910158742474, 'recall': 0.2947686116700201, 'f1-score': 0.2735944180903452, 'support': 994}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                   0  \\\n",
       "0  {'precision': 0.5, 'recall': 0.25, 'f1-score': 0.3333333333333333, 'support': 4}    \n",
       "1  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                    \n",
       "2  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                    \n",
       "3  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                    \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                    \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                    \n",
       "6  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                    \n",
       "7  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 4}                    \n",
       "8  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 5}                    \n",
       "9  {'precision': 0.25, 'recall': 0.2, 'f1-score': 0.22222222222222224, 'support': 5}   \n",
       "\n",
       "                                                                                                                     1  \\\n",
       "0  {'precision': 0.045454545454545456, 'recall': 0.023809523809523808, 'f1-score': 0.03125, 'support': 42}               \n",
       "1  {'precision': 0.09090909090909091, 'recall': 0.07142857142857142, 'f1-score': 0.08, 'support': 42}                    \n",
       "2  {'precision': 0.02702702702702703, 'recall': 0.023809523809523808, 'f1-score': 0.02531645569620253, 'support': 42}    \n",
       "3  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}                                                     \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}                                                     \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 41}                                                     \n",
       "6  {'precision': 0.03571428571428571, 'recall': 0.024390243902439025, 'f1-score': 0.028985507246376812, 'support': 41}   \n",
       "7  {'precision': 0.09523809523809523, 'recall': 0.04878048780487805, 'f1-score': 0.06451612903225808, 'support': 41}     \n",
       "8  {'precision': 0.03571428571428571, 'recall': 0.024390243902439025, 'f1-score': 0.028985507246376812, 'support': 41}   \n",
       "9  {'precision': 0.13793103448275862, 'recall': 0.09523809523809523, 'f1-score': 0.11267605633802817, 'support': 42}     \n",
       "\n",
       "                                                                                                                   2  \\\n",
       "0  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "1  {'precision': 0.09090909090909091, 'recall': 0.08333333333333333, 'f1-score': 0.08695652173913043, 'support': 12}   \n",
       "2  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "3  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "6  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "7  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "8  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 12}                                                   \n",
       "9  {'precision': 0.1, 'recall': 0.09090909090909091, 'f1-score': 0.09523809523809525, 'support': 11}                   \n",
       "\n",
       "                                                                                                                   3  \\\n",
       "0  {'precision': 0.23684210526315788, 'recall': 0.1935483870967742, 'f1-score': 0.21301775147928992, 'support': 93}    \n",
       "1  {'precision': 0.25, 'recall': 0.1827956989247312, 'f1-score': 0.2111801242236025, 'support': 93}                    \n",
       "2  {'precision': 0.2112676056338028, 'recall': 0.16129032258064516, 'f1-score': 0.18292682926829265, 'support': 93}    \n",
       "3  {'precision': 0.2716049382716049, 'recall': 0.23655913978494625, 'f1-score': 0.2528735632183908, 'support': 93}     \n",
       "4  {'precision': 0.23529411764705882, 'recall': 0.17204301075268819, 'f1-score': 0.19875776397515527, 'support': 93}   \n",
       "5  {'precision': 0.2676056338028169, 'recall': 0.20430107526881722, 'f1-score': 0.23170731707317072, 'support': 93}    \n",
       "6  {'precision': 0.2692307692307692, 'recall': 0.22580645161290322, 'f1-score': 0.2456140350877193, 'support': 93}     \n",
       "7  {'precision': 0.2857142857142857, 'recall': 0.21739130434782608, 'f1-score': 0.24691358024691357, 'support': 92}    \n",
       "8  {'precision': 0.2441860465116279, 'recall': 0.22826086956521738, 'f1-score': 0.23595505617977527, 'support': 92}    \n",
       "9  {'precision': 0.2564102564102564, 'recall': 0.21739130434782608, 'f1-score': 0.23529411764705882, 'support': 92}    \n",
       "\n",
       "                                                                                                                      4  \\\n",
       "0  {'precision': 0.02857142857142857, 'recall': 0.0196078431372549, 'f1-score': 0.023255813953488372, 'support': 51}      \n",
       "1  {'precision': 0.09090909090909091, 'recall': 0.058823529411764705, 'f1-score': 0.07142857142857142, 'support': 51}     \n",
       "2  {'precision': 0.13793103448275862, 'recall': 0.0784313725490196, 'f1-score': 0.1, 'support': 51}                       \n",
       "3  {'precision': 0.038461538461538464, 'recall': 0.0196078431372549, 'f1-score': 0.025974025974025976, 'support': 51}     \n",
       "4  {'precision': 0.06896551724137931, 'recall': 0.0392156862745098, 'f1-score': 0.05, 'support': 51}                      \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 51}                                                      \n",
       "6  {'precision': 0.10526315789473684, 'recall': 0.0784313725490196, 'f1-score': 0.0898876404494382, 'support': 51}        \n",
       "7  {'precision': 0.038461538461538464, 'recall': 0.019230769230769232, 'f1-score': 0.025641025641025644, 'support': 52}   \n",
       "8  {'precision': 0.08163265306122448, 'recall': 0.07692307692307693, 'f1-score': 0.07920792079207921, 'support': 52}      \n",
       "9  {'precision': 0.08823529411764706, 'recall': 0.058823529411764705, 'f1-score': 0.07058823529411765, 'support': 51}     \n",
       "\n",
       "                                                                                                  5  \\\n",
       "0  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "1  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}                                   \n",
       "2  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}                                   \n",
       "3  {'precision': 0.25, 'recall': 0.3333333333333333, 'f1-score': 0.28571428571428575, 'support': 3}   \n",
       "4  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 3}                                   \n",
       "5  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "6  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "7  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "8  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "9  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 2}                                   \n",
       "\n",
       "                                                                                                                  6  \\\n",
       "0  {'precision': 0.1891891891891892, 'recall': 0.10144927536231885, 'f1-score': 0.1320754716981132, 'support': 69}    \n",
       "1  {'precision': 0.15625, 'recall': 0.07246376811594203, 'f1-score': 0.09900990099009901, 'support': 69}              \n",
       "2  {'precision': 0.1, 'recall': 0.057971014492753624, 'f1-score': 0.07339449541284403, 'support': 69}                 \n",
       "3  {'precision': 0.1891891891891892, 'recall': 0.1, 'f1-score': 0.1308411214953271, 'support': 70}                    \n",
       "4  {'precision': 0.1282051282051282, 'recall': 0.07142857142857142, 'f1-score': 0.09174311926605504, 'support': 70}   \n",
       "5  {'precision': 0.1, 'recall': 0.05714285714285714, 'f1-score': 0.07272727272727272, 'support': 70}                  \n",
       "6  {'precision': 0.1388888888888889, 'recall': 0.07142857142857142, 'f1-score': 0.09433962264150943, 'support': 70}   \n",
       "7  {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 70}                                                  \n",
       "8  {'precision': 0.11320754716981132, 'recall': 0.08571428571428572, 'f1-score': 0.0975609756097561, 'support': 70}   \n",
       "9  {'precision': 0.1509433962264151, 'recall': 0.11428571428571428, 'f1-score': 0.13008130081300812, 'support': 70}   \n",
       "\n",
       "                                                                                                                   7  \\\n",
       "0  {'precision': 0.18840579710144928, 'recall': 0.1368421052631579, 'f1-score': 0.15853658536585363, 'support': 95}    \n",
       "1  {'precision': 0.20987654320987653, 'recall': 0.17894736842105263, 'f1-score': 0.19318181818181818, 'support': 95}   \n",
       "2  {'precision': 0.3103448275862069, 'recall': 0.28421052631578947, 'f1-score': 0.2967032967032967, 'support': 95}     \n",
       "3  {'precision': 0.19736842105263158, 'recall': 0.15789473684210525, 'f1-score': 0.17543859649122806, 'support': 95}   \n",
       "4  {'precision': 0.17567567567567569, 'recall': 0.1368421052631579, 'f1-score': 0.15384615384615385, 'support': 95}    \n",
       "5  {'precision': 0.1506849315068493, 'recall': 0.11578947368421053, 'f1-score': 0.13095238095238096, 'support': 95}    \n",
       "6  {'precision': 0.20987654320987653, 'recall': 0.17894736842105263, 'f1-score': 0.19318181818181818, 'support': 95}   \n",
       "7  {'precision': 0.1323529411764706, 'recall': 0.09473684210526316, 'f1-score': 0.11042944785276074, 'support': 95}    \n",
       "8  {'precision': 0.18292682926829268, 'recall': 0.15789473684210525, 'f1-score': 0.1694915254237288, 'support': 95}    \n",
       "9  {'precision': 0.2028985507246377, 'recall': 0.14736842105263157, 'f1-score': 0.17073170731707316, 'support': 95}    \n",
       "\n",
       "                                                                                                                   8  \\\n",
       "0  {'precision': 0.17894736842105263, 'recall': 0.1440677966101695, 'f1-score': 0.1596244131455399, 'support': 118}    \n",
       "1  {'precision': 0.1724137931034483, 'recall': 0.1271186440677966, 'f1-score': 0.14634146341463414, 'support': 118}    \n",
       "2  {'precision': 0.23404255319148937, 'recall': 0.1864406779661017, 'f1-score': 0.20754716981132076, 'support': 118}   \n",
       "3  {'precision': 0.16279069767441862, 'recall': 0.11864406779661017, 'f1-score': 0.1372549019607843, 'support': 118}   \n",
       "4  {'precision': 0.1411764705882353, 'recall': 0.1016949152542373, 'f1-score': 0.11822660098522167, 'support': 118}    \n",
       "5  {'precision': 0.11956521739130435, 'recall': 0.09243697478991597, 'f1-score': 0.1042654028436019, 'support': 119}   \n",
       "6  {'precision': 0.13580246913580246, 'recall': 0.09243697478991597, 'f1-score': 0.11, 'support': 119}                 \n",
       "7  {'precision': 0.1625, 'recall': 0.1092436974789916, 'f1-score': 0.13065326633165827, 'support': 119}                \n",
       "8  {'precision': 0.1927710843373494, 'recall': 0.13445378151260504, 'f1-score': 0.15841584158415842, 'support': 119}   \n",
       "9  {'precision': 0.2465753424657534, 'recall': 0.15254237288135594, 'f1-score': 0.18848167539267016, 'support': 118}   \n",
       "\n",
       "                                                                                                                     9  \\\n",
       "0  {'precision': 0.058823529411764705, 'recall': 0.06451612903225806, 'f1-score': 0.061538461538461535, 'support': 31}   \n",
       "1  {'precision': 0.08571428571428572, 'recall': 0.1, 'f1-score': 0.09230769230769231, 'support': 30}                     \n",
       "2  {'precision': 0.07407407407407407, 'recall': 0.06666666666666667, 'f1-score': 0.07017543859649124, 'support': 30}     \n",
       "3  {'precision': 0.25, 'recall': 0.1935483870967742, 'f1-score': 0.21818181818181817, 'support': 31}                     \n",
       "4  {'precision': 0.038461538461538464, 'recall': 0.03225806451612903, 'f1-score': 0.03508771929824561, 'support': 31}    \n",
       "5  {'precision': 0.037037037037037035, 'recall': 0.03225806451612903, 'f1-score': 0.034482758620689655, 'support': 31}   \n",
       "6  {'precision': 0.16666666666666666, 'recall': 0.0967741935483871, 'f1-score': 0.12244897959183673, 'support': 31}      \n",
       "7  {'precision': 0.08, 'recall': 0.06451612903225806, 'f1-score': 0.07142857142857142, 'support': 31}                    \n",
       "8  {'precision': 0.2, 'recall': 0.12903225806451613, 'f1-score': 0.1568627450980392, 'support': 31}                      \n",
       "9  {'precision': 0.17647058823529413, 'recall': 0.0967741935483871, 'f1-score': 0.125, 'support': 31}                    \n",
       "\n",
       "                                                                                                                  10  \\\n",
       "0  {'precision': 0.382051282051282, 'recall': 0.5457875457875457, 'f1-score': 0.44947209653092, 'support': 273}        \n",
       "1  {'precision': 0.41274238227146814, 'recall': 0.5457875457875457, 'f1-score': 0.47003154574132494, 'support': 273}   \n",
       "2  {'precision': 0.3974358974358974, 'recall': 0.5677655677655677, 'f1-score': 0.4675716440422323, 'support': 273}     \n",
       "3  {'precision': 0.37965260545905705, 'recall': 0.5604395604395604, 'f1-score': 0.45266272189349116, 'support': 273}   \n",
       "4  {'precision': 0.37532133676092544, 'recall': 0.5347985347985348, 'f1-score': 0.4410876132930513, 'support': 273}    \n",
       "5  {'precision': 0.3946078431372549, 'recall': 0.5897435897435898, 'f1-score': 0.47283406754772395, 'support': 273}    \n",
       "6  {'precision': 0.38734177215189874, 'recall': 0.5604395604395604, 'f1-score': 0.4580838323353293, 'support': 273}    \n",
       "7  {'precision': 0.4, 'recall': 0.5934065934065934, 'f1-score': 0.4778761061946903, 'support': 273}                    \n",
       "8  {'precision': 0.40691489361702127, 'recall': 0.5625, 'f1-score': 0.4722222222222222, 'support': 272}                \n",
       "9  {'precision': 0.3875, 'recall': 0.5677655677655677, 'f1-score': 0.4606240713224369, 'support': 273}                 \n",
       "\n",
       "                                                                                                                   11  \\\n",
       "0  {'precision': 0.24444444444444444, 'recall': 0.2682926829268293, 'f1-score': 0.2558139534883721, 'support': 205}     \n",
       "1  {'precision': 0.24596774193548387, 'recall': 0.2975609756097561, 'f1-score': 0.2693156732891832, 'support': 205}     \n",
       "2  {'precision': 0.2975609756097561, 'recall': 0.2975609756097561, 'f1-score': 0.2975609756097561, 'support': 205}      \n",
       "3  {'precision': 0.27232142857142855, 'recall': 0.29901960784313725, 'f1-score': 0.2850467289719626, 'support': 204}    \n",
       "4  {'precision': 0.2631578947368421, 'recall': 0.31862745098039214, 'f1-score': 0.28824833702882485, 'support': 204}    \n",
       "5  {'precision': 0.27111111111111114, 'recall': 0.29901960784313725, 'f1-score': 0.2843822843822844, 'support': 204}    \n",
       "6  {'precision': 0.25892857142857145, 'recall': 0.28431372549019607, 'f1-score': 0.27102803738317754, 'support': 204}   \n",
       "7  {'precision': 0.2869198312236287, 'recall': 0.3333333333333333, 'f1-score': 0.30839002267573695, 'support': 204}     \n",
       "8  {'precision': 0.27751196172248804, 'recall': 0.28431372549019607, 'f1-score': 0.28087167070217917, 'support': 204}   \n",
       "9  {'precision': 0.2920353982300885, 'recall': 0.3235294117647059, 'f1-score': 0.30697674418604654, 'support': 204}     \n",
       "\n",
       "   accuracy  \\\n",
       "0  0.265327   \n",
       "1  0.275377   \n",
       "2  0.292462   \n",
       "3  0.281407   \n",
       "4  0.261307   \n",
       "5  0.269347   \n",
       "6  0.274372   \n",
       "7  0.278392   \n",
       "8  0.279397   \n",
       "9  0.294769   \n",
       "\n",
       "                                                                                                            macro avg  \\\n",
       "0  {'precision': 0.1710608074923595, 'recall': 0.14566010741881935, 'f1-score': 0.15149315671111432, 'support': 995}    \n",
       "1  {'precision': 0.15047433491348627, 'recall': 0.1431882862583745, 'f1-score': 0.14331277594300468, 'support': 995}    \n",
       "2  {'precision': 0.14914033292008436, 'recall': 0.1436788873129853, 'f1-score': 0.1434330254283697, 'support': 995}     \n",
       "3  {'precision': 0.16761573488998902, 'recall': 0.16825388968947683, 'f1-score': 0.16366564699177613, 'support': 995}   \n",
       "4  {'precision': 0.11885480660973193, 'recall': 0.11724236160568503, 'f1-score': 0.11474977564105897, 'support': 995}   \n",
       "5  {'precision': 0.11171764783219779, 'recall': 0.11589097024905474, 'f1-score': 0.11094595701226036, 'support': 995}   \n",
       "6  {'precision': 0.14230942702679136, 'recall': 0.13441403851517045, 'f1-score': 0.13446412274310046, 'support': 995}   \n",
       "7  {'precision': 0.12343222431783489, 'recall': 0.12338659639499273, 'f1-score': 0.11965401245030126, 'support': 995}   \n",
       "8  {'precision': 0.14457210845017507, 'recall': 0.14029024816787014, 'f1-score': 0.1399644554048596, 'support': 995}    \n",
       "9  {'precision': 0.19074998840773758, 'recall': 0.17205230843376162, 'f1-score': 0.17649285214756308, 'support': 994}   \n",
       "\n",
       "                                                                                                        weighted avg  \n",
       "0  {'precision': 0.23687998425222032, 'recall': 0.26532663316582916, 'f1-score': 0.2449324922275222, 'support': 995}  \n",
       "1  {'precision': 0.2507872258943852, 'recall': 0.27537688442211056, 'f1-score': 0.25772451388535994, 'support': 995}  \n",
       "2  {'precision': 0.26486382646955486, 'recall': 0.29246231155778896, 'f1-score': 0.2730345805534182, 'support': 995}  \n",
       "3  {'precision': 0.24735887036031795, 'recall': 0.2814070351758794, 'f1-score': 0.2574982666479201, 'support': 995}   \n",
       "4  {'precision': 0.22619217001789232, 'recall': 0.2613065326633166, 'f1-score': 0.23751749991063614, 'support': 995}  \n",
       "5  {'precision': 0.225742119897149, 'recall': 0.2693467336683417, 'f1-score': 0.2408586941500853, 'support': 995}     \n",
       "6  {'precision': 0.2426377437138326, 'recall': 0.2743718592964824, 'f1-score': 0.2520636696044414, 'support': 995}    \n",
       "7  {'precision': 0.2354906041928253, 'recall': 0.27839195979899495, 'f1-score': 0.24956694228858098, 'support': 995}  \n",
       "8  {'precision': 0.25116575610680975, 'recall': 0.2793969849246231, 'f1-score': 0.26070607192865236, 'support': 995}  \n",
       "9  {'precision': 0.26760910158742474, 'recall': 0.2947686116700201, 'f1-score': 0.2735944180903452, 'support': 994}   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_reports_df = pd.DataFrame(classification_reports)\n",
    "classification_reports_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>avg_support</th>\n",
       "      <th>avg_precision</th>\n",
       "      <th>avg_recall</th>\n",
       "      <th>avg_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>41.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>92.7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>51.2</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>118.4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>272.9</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>204.3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>994.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>weighted avg</td>\n",
       "      <td>994.9</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class  avg_support  avg_precision  avg_recall  avg_f1_score\n",
       "0   0             4.2          0.08           0.04        0.06        \n",
       "1   1             41.4         0.05           0.03        0.04        \n",
       "2   2             11.9         0.02           0.02        0.02        \n",
       "3   3             92.7         0.25           0.20        0.23        \n",
       "4   4             51.2         0.07           0.04        0.05        \n",
       "5   5             2.4          0.02           0.03        0.03        \n",
       "6   6             69.7         0.13           0.07        0.09        \n",
       "7   7             95.0         0.20           0.16        0.18        \n",
       "8   8             118.4        0.17           0.13        0.15        \n",
       "9   9             30.8         0.12           0.09        0.10        \n",
       "10  10            272.9        0.39           0.56        0.46        \n",
       "11  11            204.3        0.27           0.30        0.28        \n",
       "12  macro avg     994.9        0.15           0.14        0.14        \n",
       "13  weighted avg  994.9        0.24           0.28        0.25        "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_reports_df_wa = classification_reports_df.drop(columns='accuracy')\n",
    "\n",
    "\n",
    "averages_stage2 = {}\n",
    "\n",
    "\n",
    "for class_label, dicts in classification_reports_df_wa.items():\n",
    "    metric_sums = {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0}\n",
    "    \n",
    "    for metric_dict in dicts:\n",
    "        metric_sums['precision'] += metric_dict['precision']\n",
    "        metric_sums['recall'] += metric_dict['recall']\n",
    "        metric_sums['f1-score'] += metric_dict['f1-score']\n",
    "        metric_sums['support'] += metric_dict['support']\n",
    "    \n",
    "    averages_stage2[class_label] = {\n",
    "        'avg_support': metric_sums['support'] / len(dicts),\n",
    "        'avg_precision': metric_sums['precision'] / len(dicts),\n",
    "        'avg_recall': metric_sums['recall'] / len(dicts),\n",
    "        'avg_f1_score': metric_sums['f1-score'] / len(dicts)\n",
    "    }\n",
    "averages__stage2_df = pd.DataFrame(averages_stage2).T\n",
    "\n",
    "averages__stage2_df['avg_precision'] = averages__stage2_df['avg_precision'].round(2)\n",
    "averages__stage2_df['avg_recall'] = averages__stage2_df['avg_recall'].round(2)\n",
    "averages__stage2_df['avg_f1_score'] = averages__stage2_df['avg_f1_score'].round(2)\n",
    "averages__stage2_df['avg_support'] = averages__stage2_df['avg_support'].round(2)\n",
    "\n",
    "\n",
    "averages__stage2_df.reset_index(inplace=True)\n",
    "averages__stage2_df.rename(columns={'index': 'class'}, inplace=True)\n",
    "\n",
    "averages__stage2_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m1_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
